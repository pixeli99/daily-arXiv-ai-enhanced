<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 67]
- [cs.CL](#cs.CL) [Total: 54]
- [cs.AI](#cs.AI) [Total: 37]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Heatmap Regression without Soft-Argmax for Facial Landmark Detection](https://arxiv.org/abs/2508.14929)
*Chiao-An Yang,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 该论文提出了一种基于经典结构化预测框架的替代训练目标，用于面部关键点检测，避免了对Soft-argmax的依赖，实现了更快的收敛速度和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 面部关键点检测是计算机视觉中的一项重要任务，而基于热图回归的方法通常使用Soft-argmax进行端到端训练。然而，Soft-argmax是一种不可微的近似方法，本文旨在重新审视这一长期以来的选择。

Method: 本文提出了一种基于经典结构化预测框架的替代训练目标，以取代传统的Soft-argmax方法。

Result: 该方法在WFLW、COFW和300W三个面部关键点基准上取得了最先进的性能，训练收敛速度加快了2.2倍，同时保持了更好或具有竞争力的准确性。

Conclusion: Soft-argmax并非实现强大性能的唯一途径，基于经典结构化预测框架的替代训练目标可以为面部关键点检测任务带来更优异的表现，包括更快的收敛速度和更高的精度。

Abstract: Facial landmark detection is an important task in computer vision with
numerous applications, such as head pose estimation, expression analysis, face
swapping, etc. Heatmap regression-based methods have been widely used to
achieve state-of-the-art results in this task. These methods involve computing
the argmax over the heatmaps to predict a landmark. Since argmax is not
differentiable, these methods use a differentiable approximation, Soft-argmax,
to enable end-to-end training on deep-nets. In this work, we revisit this
long-standing choice of using Soft-argmax and demonstrate that it is not the
only way to achieve strong performance. Instead, we propose an alternative
training objective based on the classic structured prediction framework.
Empirically, our method achieves state-of-the-art performance on three facial
landmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during
training while maintaining better/competitive accuracy. Our code is available
here: https://github.com/ca-joe-yang/regression-without-softarg.

</details>


### [2] [Fast Graph Neural Network for Image Classification](https://arxiv.org/abs/2508.14958)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 本文提出了一种将图卷积网络（GCNs）与Voronoi图结合的新方法，通过将图像表示为图并利用Delaunay三角剖分进行优化，从而提高了图像分类的效率和准确性，超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 图像分类的快速发展得益于图卷积网络（GCNs）的应用，但仍需一个鲁棒的框架来处理复杂数据。本文旨在通过结合GCNs和Voronoi图来增强图像分类，以有效建模关系数据。

Method: 本研究提出了一种将GCNs与Voronoi图相结合的新方法。具体做法是将图像表示为图，其中像素或区域作为顶点，然后使用Delaunay三角剖分对这些图进行优化。

Result: 该模型在预处理效率和分类准确性方面均取得了显著提升，在各种基准数据集上超越了最先进的方法，尤其在涉及复杂场景和细粒度类别的挑战性场景中表现突出。

Conclusion: 实验结果通过交叉验证证实了GCNs与Voronoi图结合在推进图像分类方面的有效性。这项研究不仅为图像分类提供了一个新颖的视角，也拓展了图学习范式在计算机视觉和非结构化数据分析中的潜在应用。

Abstract: The rapid progress in image classification has been largely driven by the
adoption of Graph Convolutional Networks (GCNs), which offer a robust framework
for handling complex data structures. This study introduces a novel approach
that integrates GCNs with Voronoi diagrams to enhance image classification by
leveraging their ability to effectively model relational data. Unlike
conventional convolutional neural networks (CNNs), our method represents images
as graphs, where pixels or regions function as vertices. These graphs are then
refined using corresponding Delaunay triangulations, optimizing their
representation. The proposed model achieves significant improvements in both
preprocessing efficiency and classification accuracy across various benchmark
datasets, surpassing state-of-the-art approaches, particularly in challenging
scenarios involving intricate scenes and fine-grained categories. Experimental
results, validated through cross-validation, underscore the effectiveness of
combining GCNs with Voronoi diagrams for advancing image classification. This
research not only presents a novel perspective on image classification but also
expands the potential applications of graph-based learning paradigms in
computer vision and unstructured data analysis.

</details>


### [3] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: YOPO：一种单阶段、纯RGB的统一目标检测和9自由度姿态估计框架，在多个基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的从单张RGB图像中恢复未见实例的9自由度姿态方法，通常依赖伪深度、CAD模型或多阶段级联，且将2D检测与姿态估计分离。本文旨在寻找一种更简单、仅依赖RGB且能直接进行类别级学习的替代方案，并探讨是否能在不增加额外数据的情况下，高性能地统一目标检测和9自由度姿态估计。

Method: 本文提出了YOPO，一个单阶段、基于查询的框架，将类别级9自由度估计视为2D检测的自然延伸。YOPO在Transformer检测器基础上，增加了轻量级姿态头部、边界框条件翻译模块和6D感知匈牙利匹配成本。模型仅使用RGB图像和类别级姿态标签进行端到端训练。

Result: 尽管设计极简，YOPO在三个基准测试中均达到了新的SOTA。在REAL275数据集上，它在$IoU_{50}$指标下达到79.6%，在$10^\circ10cm$指标下达到54.1%，超越了之前的纯RGB方法，并显著缩小了与RGB-D系统的差距。

Conclusion: 本文证明了在不依赖额外数据的情况下，可以高性能地统一目标检测和9自由度姿态估计。YOPO方法以其简洁的设计，在纯RGB单阶段的设定下，实现了业界领先的性能，解决了现有方法的复杂性与数据依赖问题。

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


### [4] [Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection](https://arxiv.org/abs/2508.14980)
*Andrei Balykin,Anvar Ganiev,Denis Kondranin,Kirill Polevoda,Nikolai Liudkevich,Artem Petrov*

Main category: cs.CV

TL;DR: 提出了一种统一的配对采样对比框架，用于检测人脸识别系统中的物理和数字欺骗攻击，该框架性能优越、轻量且训练快，可有效应对传统方法的复杂性和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 现代人脸识别系统容易受到物理攻击和数字伪造攻击。传统方法使用单独的模型处理这两种攻击，增加了系统复杂性和推理延迟，并且无法应对组合攻击。

Method: 提出了“配对采样对比框架”（Paired-Sampling Contrastive Framework），这是一种统一的训练方法，利用自动匹配的真实和攻击自拍对来学习与模态无关的活体线索。

Result: 在第6届人脸防欺骗挑战赛统一物理-数字攻击检测基准测试中，该方法实现了2.10%的平均分类错误率（ACER），优于现有解决方案。框架轻量级（4.46 GFLOPs），训练时间不到一小时。

Conclusion: 该框架轻量级且训练时间短，适用于实际部署。

Abstract: Modern face recognition systems remain vulnerable to spoofing attempts,
including both physical presentation attacks and digital forgeries.
Traditionally, these two attack vectors have been handled by separate models,
each targeting its own artifacts and modalities. However, maintaining distinct
detectors increases system complexity and inference latency and leaves systems
exposed to combined attack vectors. We propose the Paired-Sampling Contrastive
Framework, a unified training approach that leverages automatically matched
pairs of genuine and attack selfies to learn modality-agnostic liveness cues.
Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital
Attack Detection benchmark, our method achieves an average classification error
rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is
lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for
real-world deployment. Code and pretrained models are available at
https://github.com/xPONYx/iccv2025_deepfake_challenge.

</details>


### [5] [TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](https://arxiv.org/abs/2508.15020)
*Susim Roy,Anubhooti Jain,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: TAIGen是一种高效的无训练黑盒对抗性攻击方法，它利用扩散模型在3-20个采样步骤内生成高质量对抗样本，比现有方法快10倍，并能有效攻击目标模型。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型对抗性攻击图像质量低且计算资源消耗大；扩散模型虽能生成高质量图像，但需要数百个采样步骤才能生成对抗样本。

Method: TAIGen是一种无训练的黑盒方法，它利用无条件扩散模型，仅需3-20个采样步骤。关键在于在混合步骤区间注入扰动，并采用选择性RGB通道策略，对红色通道应用注意力图，对绿色和蓝色通道使用GradCAM引导的扰动。

Result: TAIGen在所有测试数据集中保持了30 dB以上的视觉质量（PSNR）。在ImageNet上，对VGGNet作为源模型，TAIGen对ResNet攻击成功率70.6%，对MNASNet攻击成功率80.8%，对ShuffleNet攻击成功率97.8%。该方法比现有基于扩散的攻击快10倍，并达到了最低的鲁棒准确率。

Conclusion: TAIGen是一种高效、高质量且具有显著攻击效果的黑盒对抗性图像生成方法，显著提高了生成速度并保持了图像质量，证明了其作为最有效攻击机制的潜力。

Abstract: Adversarial attacks from generative models often produce low-quality images
and require substantial computational resources. Diffusion models, though
capable of high-quality generation, typically need hundreds of sampling steps
for adversarial generation. This paper introduces TAIGen, a training-free
black-box method for efficient adversarial image generation. TAIGen produces
adversarial examples using only 3-20 sampling steps from unconditional
diffusion models. Our key finding is that perturbations injected during the
mixing step interval achieve comparable attack effectiveness without processing
all timesteps. We develop a selective RGB channel strategy that applies
attention maps to the red channel while using GradCAM-guided perturbations on
green and blue channels. This design preserves image structure while maximizing
misclassification in target models. TAIGen maintains visual quality with PSNR
above 30 dB across all tested datasets. On ImageNet with VGGNet as source,
TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%
against ShuffleNet. The method generates adversarial examples 10x faster than
existing diffusion-based attacks. Our method achieves the lowest robust
accuracy, indicating it is the most impactful attack as the defense mechanism
is least successful in purifying the images generated by TAIGen.

</details>


### [6] [Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement](https://arxiv.org/abs/2508.15027)
*Chunming He,Fengyang Xiao,Rihan Zhang,Chengyu Fang,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: RUN++是一个新的可逆展开网络，通过在掩码和RGB域同时应用可逆建模并结合高效的扩散模型，显著提升了隐蔽视觉感知任务的性能，减少了误报和漏报。


<details>
  <summary>Details</summary>
Motivation: 现有隐蔽视觉感知（CVP）方法主要局限于掩码域的可逆策略，忽略了RGB域的潜力，导致不确定性降低不充分。

Method: 提出了RUN++，一个具有生成式细化的可逆展开网络。该网络将CVP任务公式化为数学优化问题，并将其迭代解展开为多阶段深度网络。它在掩码和RGB域应用可逆建模，并利用扩散模型解决不确定性。每个阶段包含三个模块：CORE（在掩码域提取核心目标区域）、CARE（在RGB域增强前景-背景分离）和FINE（使用有针对性的伯努利扩散模型细化不确定区域）。该方法还引入了一种构建在真实世界退化下依然有效的鲁棒CVP系统的新范式，并将其扩展到更广泛的双层优化框架。

Result: RUN++能够高效地将焦点引导至模糊区域，显著减少了假阳性和假阴性，实现了更好的前景-背景分离。

Conclusion: RUN++提供了一种在掩码和RGB域应用可逆建模的原则性方法，并结合扩散模型有效解决不确定性，从而构建了在真实世界退化下更鲁棒的CVP系统。

Abstract: Existing methods for concealed visual perception (CVP) often leverage
reversible strategies to decrease uncertainty, yet these are typically confined
to the mask domain, leaving the potential of the RGB domain underexplored. To
address this, we propose a reversible unfolding network with generative
refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as
a mathematical optimization problem and unfolds the iterative solution into a
multi-stage deep network. This approach provides a principled way to apply
reversible modeling across both mask and RGB domains while leveraging a
diffusion model to resolve the resulting uncertainty. Each stage of the network
integrates three purpose-driven modules: a Concealed Object Region Extraction
(CORE) module applies reversible modeling to the mask domain to identify core
object regions; a Context-Aware Region Enhancement (CARE) module extends this
principle to the RGB domain to foster better foreground-background separation;
and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a
final refinement. The FINE module introduces a targeted Bernoulli diffusion
model that refines only the uncertain regions of the segmentation mask,
harnessing the generative power of diffusion for fine-detail restoration
without the prohibitive computational cost of a full-image process. This unique
synergy, where the unfolding network provides a strong uncertainty prior for
the diffusion model, allows RUN++ to efficiently direct its focus toward
ambiguous areas, significantly mitigating false positives and negatives.
Furthermore, we introduce a new paradigm for building robust CVP systems that
remain effective under real-world degradations and extend this concept into a
broader bi-level optimization framework.

</details>


### [7] [GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging](https://arxiv.org/abs/2508.15057)
*Toqi Tahamid Sarker,Mohamed Embaby,Taminul Islam,Amer AbuGhazaleh,Khaled R Ahmed*

Main category: cs.CV

TL;DR: GasTwinFormer是一种高效的新型混合视觉Transformer，用于实时牲畜甲烷排放分割和饮食分类，在新数据集上实现了高精度。


<details>
  <summary>Details</summary>
Motivation: 牲畜甲烷排放占人为甲烷排放的32%，因此自动化监测对于气候缓解策略至关重要。

Method: 本文提出了GasTwinFormer，这是一种混合视觉Transformer，通过新颖的Mix Twin编码器（交替使用空间缩减的全局注意力和局部分组注意力机制）实现实时甲烷排放分割和饮食分类。它还包含一个轻量级LR-ASPP解码器，用于多尺度特征聚合，并贡献了首个综合性肉牛甲烷排放数据集。

Result: GasTwinFormer在分割方面实现了74.47%的mIoU和83.63%的mF1，同时保持了卓越的效率（3.348M参数、3.428G FLOPs和114.9 FPS推理速度）。此外，该方法实现了100%的饮食分类准确率。

Conclusion: GasTwinFormer被确立为实时牲畜排放监测的实用解决方案。

Abstract: Livestock methane emissions represent 32% of human-caused methane production,
making automated monitoring critical for climate mitigation strategies. We
introduce GasTwinFormer, a hybrid vision transformer for real-time methane
emission segmentation and dietary classification in optical gas imaging through
a novel Mix Twin encoder alternating between spatially-reduced global attention
and locally-grouped attention mechanisms. Our architecture incorporates a
lightweight LR-ASPP decoder for multi-scale feature aggregation and enables
simultaneous methane segmentation and dietary classification in a unified
framework. We contribute the first comprehensive beef cattle methane emission
dataset using OGI, containing 11,694 annotated frames across three dietary
treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation
while maintaining exceptional efficiency with only 3.348M parameters, 3.428G
FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect
dietary classification accuracy (100%), demonstrating the effectiveness of
leveraging diet-emission correlations. Extensive ablation studies validate each
architectural component, establishing GasTwinFormer as a practical solution for
real-time livestock emission monitoring. Please see our project page at
gastwinformer.github.io.

</details>


### [8] [CurveFlow: Curvature-Guided Flow Matching for Image Generation](https://arxiv.org/abs/2508.15093)
*Yan Luo,Drake Du,Hao Huang,Yi Fang,Mengyu Wang*

Main category: cs.CV

TL;DR: CurveFlow引入了曲率引导来学习平滑的非线性轨迹，从而在文本到图像生成中实现了最先进的性能，并显著提高了语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有整流流模型基于线性轨迹，可能导致图像生成经过低概率区域，且轨迹曲率与生成图像和标题之间的语义对齐关系未被充分探索。

Method: 本文引入了CurveFlow，这是一种新颖的流匹配框架，通过将曲率引导直接纳入流路径来学习平滑的非线性轨迹。该方法采用鲁棒的曲率正则化技术，惩罚轨迹固有动力学的突然变化。

Result: 在MS COCO 2014和2017上的大量实验表明，CurveFlow在文本到图像生成中达到了最先进的性能，显著优于标准整流流变体和其他非线性基线。在BLEU、METEOR、ROUGE和CLAIR等语义一致性指标上，改进尤为明显。

Conclusion: 曲率感知建模显著增强了模型忠实遵循复杂指令的能力，同时保持了高图像质量。

Abstract: Existing rectified flow models are based on linear trajectories between data
and noise distributions. This linearity enforces zero curvature, which can
inadvertently force the image generation process through low-probability
regions of the data manifold. A key question remains underexplored: how does
the curvature of these trajectories correlate with the semantic alignment
between generated images and their corresponding captions, i.e., instructional
compliance? To address this, we introduce CurveFlow, a novel flow matching
framework designed to learn smooth, non-linear trajectories by directly
incorporating curvature guidance into the flow path. Our method features a
robust curvature regularization technique that penalizes abrupt changes in the
trajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017
demonstrate that CurveFlow achieves state-of-the-art performance in
text-to-image generation, significantly outperforming both standard rectified
flow variants and other non-linear baselines like Rectified Diffusion. The
improvements are especially evident in semantic consistency metrics such as
BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling
substantially enhances the model's ability to faithfully follow complex
instructions while simultaneously maintaining high image quality. The code is
made publicly available at
https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.

</details>


### [9] [HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment](https://arxiv.org/abs/2508.15130)
*Vaishnav Ramesh,Haining Wang,Md Jahidul Islam*

Main category: cs.CV

TL;DR: HiRQA是一个自监督、无偏见的图像质量评估框架，通过分层排序和对比学习解决数据集偏差问题。它在真实失真上表现出色，达到SOTA性能，并具有轻量级版本HiRQA-S。


<details>
  <summary>Details</summary>
Motivation: 尽管在无参考图像质量评估（NR-IQA）方面取得了显著进展，但数据集偏差和对主观标签的依赖持续阻碍其泛化性能。

Method: 本文提出了HiRQA（分层排序和质量对齐），一个自监督、无主观意见的框架，通过结合排序和对比学习提供分层的、质量感知的嵌入。它引入了一种新颖的高阶排序损失来监督通过失真对之间的关系排序进行的质量预测，以及一种嵌入距离损失来强制特征距离和感知差异之间的一致性。通过结构化文本提示引导的训练时对比对齐损失进一步增强了学习到的表示。在推理时，HiRQA仅使用输入图像预测质量分数。同时，为了实时部署，引入了轻量级变体HiRQA-S。

Result: HiRQA在仅通过合成失真训练的情况下，能有效地泛化到真实的图像退化，并在各种失真（如镜头眩光、雾霾、运动模糊和低光照条件）下进行了评估。HiRQA-S的推理时间仅为每张图像3.5毫秒。广泛的实验验证了HiRQA在合成和真实基准上的最先进（SOTA）性能、强大的泛化能力和可扩展性。

Conclusion: HiRQA框架展示了最先进的性能、强大的泛化能力和可扩展性，成功解决了无参考图像质量评估中数据集偏差和对主观标签依赖的问题，即使仅在合成失真上训练也能有效泛化。

Abstract: Despite significant progress in no-reference image quality assessment
(NR-IQA), dataset biases and reliance on subjective labels continue to hinder
their generalization performance. We propose HiRQA, Hierarchical Ranking and
Quality Alignment), a self-supervised, opinion-unaware framework that offers a
hierarchical, quality-aware embedding through a combination of ranking and
contrastive learning. Unlike prior approaches that depend on pristine
references or auxiliary modalities at inference time, HiRQA predicts quality
scores using only the input image. We introduce a novel higher-order ranking
loss that supervises quality predictions through relational ordering across
distortion pairs, along with an embedding distance loss that enforces
consistency between feature distances and perceptual differences. A
training-time contrastive alignment loss, guided by structured textual prompts,
further enhances the learned representation. Trained only on synthetic
distortions, HiRQA generalizes effectively to authentic degradations, as
demonstrated through evaluation on various distortions such as lens flare,
haze, motion blur, and low-light conditions. For real-time deployment, we
introduce \textbf{HiRQA-S}, a lightweight variant with an inference time of
only 3.5 ms per image. Extensive experiments across synthetic and authentic
benchmarks validate HiRQA's state-of-the-art (SOTA) performance, strong
generalization ability, and scalability.

</details>


### [10] [Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments](https://arxiv.org/abs/2508.15158)
*Md. Nurul Absur,Abhinav Kumar,Swastik Brahma,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 本文提出了一种基于投资组合理论的边缘资源管理策略，以在存在时空相关中断的情况下，实现可靠的多视图3D重建。


<details>
  <summary>Details</summary>
Motivation: 在应急响应、战术场景和公共安全等多视图3D重建应用中，边缘环境的动态性和操作逆境可能导致时空相关中断，从而影响摄像头操作并持续降低重建质量。

Method: 本文提出了一种受投资组合理论启发的边缘资源管理策略，用于在系统可能中断的情况下进行可靠的多视图3D重建。该方法利用遗传算法解决投资组合理论优化问题，以确保即使在摄像头易受时空相关中断影响时也能满足重建质量。

Result: 通过使用公开和自定义的3D数据集，证明了所提出的相机选择策略在保证可靠3D重建方面的优势，优于传统的基线策略，尤其是在存在时空中断的情况下。

Conclusion: 所提出的相机选择策略在时空中断下，相比传统基线策略，能有效保证可靠的3D重建。

Abstract: Multi-view 3D reconstruction applications are revolutionizing critical use
cases that require rapid situational-awareness, such as emergency response,
tactical scenarios, and public safety. In many cases, their near-real-time
latency requirements and ad-hoc needs for compute resources necessitate
adoption of `Just-in-time' edge environments where the system is set up on the
fly to support the applications during the mission lifetime. However,
reliability issues can arise from the inherent dynamism and operational
adversities of such edge environments, resulting in spatiotemporally correlated
disruptions that impact the camera operations, which can lead to sustained
degradation of reconstruction quality. In this paper, we propose a novel
portfolio theory inspired edge resource management strategy for reliable
multi-view 3D reconstruction against possible system disruptions. Our proposed
methodology can guarantee reconstruction quality satisfaction even when the
cameras are prone to spatiotemporally correlated disruptions. The portfolio
theoretic optimization problem is solved using a genetic algorithm that
converges quickly for realistic system settings. Using publicly available and
customized 3D datasets, we demonstrate the proposed camera selection strategy's
benefits in guaranteeing reliable 3D reconstruction against traditional
baseline strategies, under spatiotemporal disruptions.

</details>


### [11] [XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2508.15168)
*Masato Ito,Kaito Tanaka,Keisuke Matsuda,Aya Nakayama*

Main category: cs.CV

TL;DR: XDR-LVLM是一种基于视觉-语言大模型的糖尿病视网膜病变（DR）诊断框架，它不仅能高精度诊断DR，还能生成自然语言解释，弥合了AI诊断与临床需求之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是全球失明的主要原因，而现有的深度学习DR诊断模型因缺乏透明度和可解释性，阻碍了临床应用。

Method: 本文提出了XDR-LVLM框架，该框架利用视觉-语言大模型（LVLMs）进行高精度DR诊断并提供自然语言解释。它集成了专门的医学视觉编码器和LVLM核心，并采用多任务提示工程和多阶段微调，以生成包含DR严重程度分级、关键病理概念识别及详细解释的诊断报告。

Result: XDR-LVLM在DDR数据集上取得了最先进的性能：疾病诊断的平衡准确率为84.55%，F1分数为79.92%；概念检测结果更优（平衡准确率77.95%，F1分数66.88%）。人类评估也证实了其生成解释的高流畅性、准确性和临床实用性。

Conclusion: XDR-LVLM通过提供可靠且可解释的诊断见解，成功弥合了自动化诊断与临床需求之间的差距，展现了其重要的临床实用价值。

Abstract: Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating
early and accurate diagnosis. While deep learning models have shown promise in
DR detection, their black-box nature often hinders clinical adoption due to a
lack of transparency and interpretability. To address this, we propose XDR-LVLM
(eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that
leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis
coupled with natural language-based explanations. XDR-LVLM integrates a
specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt
Engineering and Multi-stage Fine-tuning to deeply understand pathological
features within fundus images and generate comprehensive diagnostic reports.
These reports explicitly include DR severity grading, identification of key
pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and
detailed explanations linking observed features to the diagnosis. Extensive
experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM
achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and
an F1 Score of 79.92% for disease diagnosis, and superior results for concept
detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the
high fluency, accuracy, and clinical utility of the generated explanations,
showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and
clinical needs by providing robust and interpretable insights.

</details>


### [12] [MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion](https://arxiv.org/abs/2508.15169)
*Xuyang Chen,Zhijun Zhai,Kaixuan Zhou,Zengmao Wang,Jianan He,Dong Wang,Yanfeng Zhang,mingwei Sun,Rüdiger Westermann,Konrad Schindler,Liqiu Meng*

Main category: cs.CV

TL;DR: 针对城市网格模型纹理不足问题，提出MeSS方法，利用扩散模型和3DGS生成高质量、风格一致的室外场景，提升了在几何对齐和生成质量方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的城市网格模型缺乏真实纹理，限制了它们在虚拟城市导航和自动驾驶中的应用。

Method: 论文提出了MeSS（Meshbased Scene Synthesis）方法，以城市网格模型为几何先验，生成高质量、风格一致的室外场景。该方法分三阶段：首先，使用Cascaded Outpainting ControlNets生成几何一致的稀疏视图；其次，通过AGInpaint组件传播更密集的中间视图；最后，使用GCAlign模块消除全局视觉不一致性。同时，通过在网格表面初始化高斯球来重建3D高斯Splatting (3DGS) 场景。

Result: MeSS方法在几何对齐和生成质量方面均优于现有方法。合成后的场景可以通过重打光和风格迁移技术以不同风格渲染。

Conclusion: 本文提出的MeSS方法有效解决了城市网格模型纹理不足的问题，为虚拟城市导航和自动驾驶提供了更真实、高质量的场景。

Abstract: Mesh models have become increasingly accessible for numerous cities; however,
the lack of realistic textures restricts their application in virtual urban
navigation and autonomous driving. To address this, this paper proposes MeSS
(Meshbased Scene Synthesis) for generating high-quality, styleconsistent
outdoor scenes with city mesh models serving as the geometric prior. While
image and video diffusion models can leverage spatial layouts (such as depth
maps or HD maps) as control conditions to generate street-level perspective
views, they are not directly applicable to 3D scene generation. Video diffusion
models excel at synthesizing consistent view sequences that depict scenes but
often struggle to adhere to predefined camera paths or align accurately with
rendered control videos. In contrast, image diffusion models, though unable to
guarantee cross-view visual consistency, can produce more geometry-aligned
results when combined with ControlNet. Building on this insight, our approach
enhances image diffusion models by improving cross-view consistency. The
pipeline comprises three key stages: first, we generate geometrically
consistent sparse views using Cascaded Outpainting ControlNets; second, we
propagate denser intermediate views via a component dubbed AGInpaint; and
third, we globally eliminate visual inconsistencies (e.g., varying exposure)
using the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting
(3DGS) scene is reconstructed by initializing Gaussian balls on the mesh
surface. Our method outperforms existing approaches in both geometric alignment
and generation quality. Once synthesized, the scene can be rendered in diverse
styles through relighting and style transfer techniques.

</details>


### [13] [SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis](https://arxiv.org/abs/2508.15189)
*Jiahao Xu,Changchang Yin,Odysseas Chatzipanagiotou,Diamantis Tsilimigras,Kevin Clear,Bingsheng Yao,Dakuo Wang,Timothy Pawlik,Ping Zhang*

Main category: cs.CV

TL;DR: 本文提出了首个开源外科伤口数据集SurgWound和三阶段学习框架WoundQwen，用于外科伤口诊断，旨在通过分析伤口特征并提供指导，改善个性化伤口护理和患者预后。


<details>
  <summary>Details</summary>
Motivation: 手术部位感染 (SSI) 是最常见和代价高昂的医疗相关感染之一，目前的深度学习方法在外科伤口筛查方面受到数据隐私和专家标注成本高昂的限制。目前缺乏涵盖各种类型外科伤口的公开数据集或基准测试工具。

Method: 1. 构建了SurgWound，首个包含697张外科伤口图像（由3位专业外科医生标注8种细粒度临床属性）的开源数据集。2. 基于SurgWound，建立了首个外科伤口诊断基准，包括视觉问答 (VQA) 和报告生成任务。3. 提出了三阶段学习框架WoundQwen：第一阶段，五个独立的MLLM预测伤口特征；第二阶段，这些预测作为额外知识输入到两个MLLM中，用于诊断感染风险和指导干预；第三阶段，一个MLLM整合前两阶段结果生成综合报告。

Result: 所提出的三阶段框架能够分析详细的外科伤口特征，并根据手术图像为患者提供后续指导。

Conclusion: 该框架为个性化伤口护理、及时干预和改善患者预后铺平了道路。

Abstract: Surgical site infection (SSI) is one of the most common and costly
healthcare-associated infections and and surgical wound care remains a
significant clinical challenge in preventing SSIs and improving patient
outcomes. While recent studies have explored the use of deep learning for
preliminary surgical wound screening, progress has been hindered by concerns
over data privacy and the high costs associated with expert annotation.
Currently, no publicly available dataset or benchmark encompasses various types
of surgical wounds, resulting in the absence of an open-source Surgical-Wound
screening tool. To address this gap: (1) we present SurgWound, the first
open-source dataset featuring a diverse array of surgical wound types. It
contains 697 surgical wound images annotated by 3 professional surgeons with
eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce
the first benchmark for surgical wound diagnosis, which includes visual
question answering (VQA) and report generation tasks to comprehensively
evaluate model performance. (3) Furthermore, we propose a three-stage learning
framework, WoundQwen, for surgical wound diagnosis. In the first stage, we
employ five independent MLLMs to accurately predict specific surgical wound
characteristics. In the second stage, these predictions serve as additional
knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess
infection risk and guide subsequent interventions. In the third stage, we train
a MLLM that integrates the diagnostic results from the previous two stages to
produce a comprehensive report. This three-stage framework can analyze detailed
surgical wound characteristics and provide subsequent instructions to patients
based on surgical images, paving the way for personalized wound care, timely
intervention, and improved patient outcomes.

</details>


### [14] [Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning](https://arxiv.org/abs/2508.15207)
*Arjun Srinivasan,Anubhav Paras,Aniket Bera*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的方法，用于为强化学习中的基于规则的智能体生成对抗性行为，以揭示故障场景并在安全关键应用中降低累积奖励。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在与基于规则的周围智能体交互的环境中训练智能体学习期望的最佳行为。在自动驾驶等安全关键应用中，对基于规则的智能体进行适当建模至关重要。目前使用多种行为建模策略和IDM模型来建模周围智能体。本文旨在为基于规则的智能体推导出对抗性行为，以导致故障场景。

Method: 提出了一种基于学习的方法，用于推导基于规则的智能体的对抗性行为，以引发故障场景。

Result: 我们的对抗性智能体在对抗所有基于规则的智能体时，累积奖励有所下降。

Conclusion: 所提出的基于学习的方法可以为基于规则的智能体推导出对抗性行为，从而导致故障场景并降低累积奖励。

Abstract: Existing approaches in reinforcement learning train an agent to learn desired
optimal behavior in an environment with rule based surrounding agents. In
safety critical applications such as autonomous driving it is crucial that the
rule based agents are modelled properly. Several behavior modelling strategies
and IDM models are used currently to model the surrounding agents. We present a
learning based method to derive the adversarial behavior for the rule based
agents to cause failure scenarios. We evaluate our adversarial agent against
all the rule based agents and show the decrease in cumulative reward.

</details>


### [15] [DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology](https://arxiv.org/abs/2508.15208)
*Leiyue Zhao,Yuechen Yang,Yanfan Zhu,Haichun Yang,Yuankai Huo,Paul D. Simonson,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: DyMorph-B2I是一种动态的、形态引导的二进制到实例分割管道，它集成了多种经典技术，并通过自适应几何细化和可定制的超参数调整，实现了肾脏病理学中实例级分割的更高精度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的肾脏病理学功能单元形态学量化方法主要提供二值（语义）掩膜，限制了下游分析的精确性。尽管传统后处理技术被用于实例分离，但其在肾脏组织复杂多样的形态和连接性面前效果有限。

Method: 我们提出了DyMorph-B2I，一个动态的、形态引导的二进制到实例分割流程，专为肾脏病理学设计。该方法将分水岭、骨架化和形态学操作整合在一个统一框架中，并辅以自适应几何精修和针对每类功能单元的可定制超参数调整。

Result: 实验结果表明，我们的方法优于单独的经典方法和简单的组合，实现了卓越的实例分离，并促进了肾脏病理工作流程中更准确的形态测量分析。

Conclusion: DyMorph-B2I显著提高了肾脏病理学中实例分离的准确性，从而能够进行更精确的形态测量分析。

Abstract: Accurate morphological quantification of renal pathology functional units
relies on instance-level segmentation, yet most existing datasets and automated
methods provide only binary (semantic) masks, limiting the precision of
downstream analyses. Although classical post-processing techniques such as
watershed, morphological operations, and skeletonization, are often used to
separate semantic masks into instances, their individual effectiveness is
constrained by the diverse morphologies and complex connectivity found in renal
tissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided
binary-to-instance segmentation pipeline tailored for renal pathology. Our
approach integrates watershed, skeletonization, and morphological operations
within a unified framework, complemented by adaptive geometric refinement and
customizable hyperparameter tuning for each class of functional unit. Through
systematic parameter optimization, DyMorph-B2I robustly separates adherent and
heterogeneous structures present in binary masks. Experimental results
demonstrate that our method outperforms individual classical approaches and
na\"ive combinations, enabling superior instance separation and facilitating
more accurate morphometric analysis in renal pathology workflows. The pipeline
is publicly available at: https://github.com/ddrrnn123/DyMorph-B2I.

</details>


### [16] [STAGNet: A Spatio-Temporal Graph and LSTM Framework for Accident Anticipation](https://arxiv.org/abs/2508.15216)
*Vipooshan Vipulananthan,Kumudu Mohottala,Kavindu Chinthana,Nimsara Paramulla,Charith D Chitraranjan*

Main category: cs.CV

TL;DR: STAGNet 模型利用时空特征和循环网络，显著提高了从行车记录仪视频中预测事故的准确性。


<details>
  <summary>Details</summary>
Motivation: 事故预测和及时预警对提高道路安全至关重要。仅依靠行车记录仪视频进行预测，尽管具有挑战性，但成本效益高且易于部署。

Method: 本文通过结合更好的时空特征，并通过循环网络聚合这些特征，改进了现有最先进的图神经网络，以实现从行车记录仪视频中预测事故。提出的模型名为 STAGNet。

Result: 在三个公开数据集中进行的实验表明，我们提出的 STAGNet 模型在平均精度和平均碰撞时间值方面均优于现有方法，无论是在给定数据集上进行交叉验证，还是在不同数据集上进行训练和测试。

Conclusion: 提出的 STAGNet 模型通过结合改进的时空特征和循环网络，显著提升了从行车记录仪视频中预测事故的性能。

Abstract: Accident prediction and timely warnings play a key role in improving road
safety by reducing the risk of injury to road users and minimizing property
damage. Advanced Driver Assistance Systems (ADAS) are designed to support human
drivers and are especially useful when they can anticipate potential accidents
before they happen. While many existing systems depend on a range of sensors
such as LiDAR, radar, and GPS, relying solely on dash-cam video input presents
a more challenging but a more cost-effective and easily deployable solution. In
this work, we incorporate better spatio-temporal features and aggregate them
through a recurrent network to improve upon state-of-the-art graph neural
networks for predicting accidents from dash-cam videos. Experiments using three
publicly available datasets show that our proposed STAGNet model achieves
higher average precision and mean time-to-collision values than previous
methods, both when cross-validated on a given dataset and when trained and
tested on different datasets.

</details>


### [17] [Collaborative Multi-Modal Coding for High-Quality 3D Generation](https://arxiv.org/abs/2508.15228)
*Ziang Cao,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: TriMM是一个利用多模态（RGB、RGBD、点云）数据进行3D资产生成的前馈模型。它通过协同多模态编码和辅助监督，使用三平面潜在扩散模型生成高质量的3D资产，即使在小型数据集上也能达到与大型数据集训练模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D原生生成架构大多在单一模态范式下运行，忽视了多模态数据的互补优势，或者仅限于3D结构，限制了可用训练数据集的范围。

Method: 1. 引入协同多模态编码，整合模态特定特征并保留其独特的表示优势。2. 引入辅助2D和3D监督，提高多模态编码的鲁棒性和性能。3. 基于嵌入的多模态代码，TriMM采用三平面潜在扩散模型生成高质量3D资产。

Result: TriMM在多个知名数据集上表现出有竞争力的性能，即使使用少量训练数据，也能与在大型数据集上训练的模型相媲美。它增强了纹理和几何细节。此外，它验证了将其他多模态数据集（如RGB-D）整合到3D生成中的可行性。

Conclusion: TriMM是首个前馈3D原生生成模型，它能够全面利用多模态（如RGB、RGBD和点云）进行3D建模，生成高质量的3D资产，并在有限的训练数据下达到与大型数据集模型相当的性能。

Abstract: 3D content inherently encompasses multi-modal characteristics and can be
projected into different modalities (e.g., RGB images, RGBD, and point clouds).
Each modality exhibits distinct advantages in 3D asset modeling: RGB images
contain vivid 3D textures, whereas point clouds define fine-grained 3D
geometries. However, most existing 3D-native generative architectures either
operate predominantly within single-modality paradigms-thus overlooking the
complementary benefits of multi-modality data-or restrict themselves to 3D
structures, thereby limiting the scope of available training datasets. To
holistically harness multi-modalities for 3D modeling, we present TriMM, the
first feed-forward 3D-native generative model that learns from basic
multi-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM
first introduces collaborative multi-modal coding, which integrates
modality-specific features while preserving their unique representational
strengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to
raise the robustness and performance of multi-modal coding. 3) Based on the
embedded multi-modal code, TriMM employs a triplane latent diffusion model to
generate 3D assets of superior quality, enhancing both the texture and the
geometric detail. Extensive experiments on multiple well-known datasets
demonstrate that TriMM, by effectively leveraging multi-modality, achieves
competitive performance with models trained on large-scale datasets, despite
utilizing a small amount of training data. Furthermore, we conduct additional
experiments on recent RGB-D datasets, verifying the feasibility of
incorporating other multi-modal datasets into 3D generation.

</details>


### [18] [Center-Oriented Prototype Contrastive Clustering](https://arxiv.org/abs/2508.15231)
*Shihao Dong,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 本文提出了一个名为CPCC的对比聚类新框架，通过软原型对比和双重一致性学习，有效解决了类间冲突和原型偏差问题，并在实验中超越了SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习聚类方法在解决类间冲突问题上效率不高，且硬原型计算与真实聚类中心存在偏差。

Method: 本文提出了一种面向中心的原型对比聚类框架（CPCC），包含软原型对比模块和双重一致性学习模块。软原型对比模块利用样本属于聚类中心的概率作为权重计算类别原型，避免类间冲突并减少原型漂移。双重一致性学习模块对齐同一样本的不同变换和不同样本的邻域，确保特征具有变换不变的语义信息和紧凑的类内分布，并为原型计算提供可靠保障。

Result: 在五个数据集上的大量实验表明，所提出的方法与现有最先进（SOTA）方法相比是有效的。

Conclusion: 所提出的面向中心的原型对比聚类框架有效地解决了类间冲突和原型偏差问题，提升了聚类性能。

Abstract: Contrastive learning is widely used in clustering tasks due to its
discriminative representation. However, the conflict problem between classes is
difficult to solve effectively. Existing methods try to solve this problem
through prototype contrast, but there is a deviation between the calculation of
hard prototypes and the true cluster center. To address this problem, we
propose a center-oriented prototype contrastive clustering framework, which
consists of a soft prototype contrastive module and a dual consistency learning
module. In short, the soft prototype contrastive module uses the probability
that the sample belongs to the cluster center as a weight to calculate the
prototype of each category, while avoiding inter-class conflicts and reducing
prototype drift. The dual consistency learning module aligns different
transformations of the same sample and the neighborhoods of different samples
respectively, ensuring that the features have transformation-invariant semantic
information and compact intra-cluster distribution, while providing reliable
guarantees for the calculation of prototypes. Extensive experiments on five
datasets show that the proposed method is effective compared to the SOTA. Our
code is published on https://github.com/LouisDong95/CPCC.

</details>


### [19] [AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation](https://arxiv.org/abs/2508.15232)
*Ruipu Wu,Yige Zhang,Jinyu Chen,Linjiang Huang,Shifeng Zhang,Xu Zhou,Liang Wang,Si Liu*

Main category: cs.CV

TL;DR: 引入了一种双高度无人机协作视觉语言导航（DuAl-VLN）的新任务和框架（AeroDuo），通过高空和低空无人机协作，以提高导航效率和泛化能力，并构建了HaL-13k数据集来支持。


<details>
  <summary>Details</summary>
Motivation: 现有的空中视觉语言导航（VLN）任务因无人机轨迹长、机动复杂而面临挑战，常需人工干预或过度详细的指令。目标是利用无人机的高机动性提供多粒度视角，同时保持可控的运动空间。

Method: 提出了双高度无人机协作VLN（DuAl-VLN）任务，高空无人机负责环境推理，低空无人机负责精确导航。构建了HaL-13k数据集，包含13,838条高低空无人机协作轨迹和目标导向语言指令。提出了AeroDuo框架，高空无人机集成多模态大语言模型（Pilot-LLM）进行目标推理，低空无人机采用轻量级多阶段策略进行导航和目标定位，两无人机仅交换少量坐标信息。

Result: HaL-13k数据集包含未见地图和未见目标验证集，用于系统评估模型在新环境和不熟悉目标上的泛化能力。提出的AeroDuo框架通过两无人机协作和最小化的信息交换确保了效率。

Conclusion: 论文引入了DuAl-VLN这一新任务，并提出了AeroDuo协作框架，辅以HaL-13k数据集，通过双高度无人机克服了空中VLN的挑战，实现了多粒度视角和高效导航，旨在提高泛化能力。

Abstract: Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables
Unmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural
language instructions and visual cues. However, due to the extended
trajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN
performance is challenging and often requires human intervention or overly
detailed instructions. To harness the advantages of UAVs' high mobility, which
could provide multi-grained perspectives, while maintaining a manageable motion
space for learning, we introduce a novel task called Dual-Altitude UAV
Collaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct
altitudes: a high-altitude UAV responsible for broad environmental reasoning,
and a low-altitude UAV tasked with precise navigation. To support the training
and evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising
13,838 collaborative high-low UAV demonstration trajectories, each paired with
target-oriented language instructions. This dataset includes both unseen maps
and an unseen object validation set to systematically evaluate the model's
generalization capabilities across novel environments and unfamiliar targets.
To consolidate their complementary strengths, we propose a dual-UAV
collaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a
multimodal large language model (Pilot-LLM) for target reasoning, while the
low-altitude UAV employs a lightweight multi-stage policy for navigation and
target grounding. The two UAVs work collaboratively and only exchange minimal
coordinate information to ensure efficiency.

</details>


### [20] [Pretrained Diffusion Models Are Inherently Skipped-Step Samplers](https://arxiv.org/abs/2508.15233)
*Wenju Xu*

Main category: cs.CV

TL;DR: 我们提出了一种名为“跳步采样”的马尔可夫采样方法，可以显著加速扩散模型的生成过程，同时保持高质量输出，并且可以与现有方法（如DDIM）结合使用。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然性能卓越，但其顺序生成过程效率低下。现有加速方法通常依赖非马尔可夫过程，因此本文旨在探究原始马尔可夫扩散过程是否也能在不引入非马尔可夫特性下实现高效采样。

Method: 本文提出“跳步采样”机制，通过跳过迭代生成过程中的多个中间去噪步骤来实现加速，这与传统的逐步细化不同。我们证明这种机制源于标准扩散模型的相同训练目标，表明马尔可夫方式的加速采样是预训练扩散模型的内在属性。此外，我们还提出了一种将加速采样技术与DDIM相结合的增强生成方法。

Result: 在包括OpenAI ADM、Stable Diffusion和Open Sora在内的流行预训练扩散模型上进行了广泛实验，结果表明我们的方法在显著减少采样步骤的同时，仍能实现高质量的生成。

Conclusion: 我们证实了通过马尔可夫方式的跳步采样加速是预训练扩散模型的内在属性。本文提出的跳步采样机制，特别是与DDIM结合时，能够有效地减少采样步骤，同时保持高生成质量。

Abstract: Diffusion models have been achieving state-of-the-art results across various
generation tasks. However, a notable drawback is their sequential generation
process, requiring long-sequence step-by-step generation. Existing methods,
such as DDIM, attempt to reduce sampling steps by constructing a class of
non-Markovian diffusion processes that maintain the same training objective.
However, there remains a gap in understanding whether the original diffusion
process can achieve the same efficiency without resorting to non-Markovian
processes. In this paper, we provide a confirmative answer and introduce
skipped-step sampling, a mechanism that bypasses multiple intermediate
denoising steps in the iterative generation process, in contrast with the
traditional step-by-step refinement of standard diffusion inference. Crucially,
we demonstrate that this skipped-step sampling mechanism is derived from the
same training objective as the standard diffusion model, indicating that
accelerated sampling via skipped-step sampling via a Markovian way is an
intrinsic property of pretrained diffusion models. Additionally, we propose an
enhanced generation method by integrating our accelerated sampling technique
with DDIM. Extensive experiments on popular pretrained diffusion models,
including the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our
method achieves high-quality generation with significantly reduced sampling
steps.

</details>


### [21] [Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent](https://arxiv.org/abs/2508.15243)
*Yixin Gao,Xin Li,Xiaohan Pan,Runsen Feng,Bingchen Li,Yunpeng Qi,Yiting Lu,Zhengxue Cheng,Zhibo Chen,Jörn Ostermann*

Main category: cs.CV

TL;DR: Comp-X是首个由大型语言模型（LLM）驱动的智能交互式图像压缩范式，通过统一多功能编码框架、交互式编码代理和专用基准IIC-bench，解决了传统图像编解码器模式受限且对非专业用户不友好的问题。它能有效理解编码请求，实现出色的文本交互能力，并保持可比的压缩性能，为图像压缩领域的人工通用智能（AGI）提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编解码器编码模式有限，且依赖工程师手动选择模式，对非专业用户不友好。

Method: 本文提出了Comp-X，通过三大创新：1. 多功能编码框架，统一了多种客观/需求的编码模式（人机感知、可变编码、空间比特分配）。2. 交互式编码代理，采用增强型上下文学习结合编码专家反馈，教会LLM代理理解编码请求、模式选择和工具使用。3. IIC-bench，首个用于智能交互式图像压缩评估的专用基准，包含多样化的用户请求和专家注释。

Result: 实验结果表明，Comp-X能有效理解编码请求，实现令人印象深刻的文本交互能力，同时在单一编码框架下仍能保持可比的压缩性能。

Conclusion: Comp-X为图像压缩领域的人工通用智能（AGI）提供了一个有前景的途径。

Abstract: We present Comp-X, the first intelligently interactive image compression
paradigm empowered by the impressive reasoning capability of large language
model (LLM) agent. Notably, commonly used image codecs usually suffer from
limited coding modes and rely on manual mode selection by engineers, making
them unfriendly for unprofessional users. To overcome this, we advance the
evolution of image coding paradigm by introducing three key innovations: (i)
multi-functional coding framework, which unifies different coding modes of
various objective/requirements, including human-machine perception, variable
coding, and spatial bit allocation, into one framework. (ii) interactive coding
agent, where we propose an augmented in-context learning method with coding
expert feedback to teach the LLM agent how to understand the coding request,
mode selection, and the use of the coding tools. (iii) IIC-bench, the first
dedicated benchmark comprising diverse user requests and the corresponding
annotations from coding experts, which is systematically designed for
intelligently interactive image compression evaluation. Extensive experimental
results demonstrate that our proposed Comp-X can understand the coding requests
efficiently and achieve impressive textual interaction capability. Meanwhile,
it can maintain comparable compression performance even with a single coding
framework, providing a promising avenue for artificial general intelligence
(AGI) in image compression.

</details>


### [22] [Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images](https://arxiv.org/abs/2508.15256)
*Jinsol Song,Jiamu Wang,Anh Tien Nguyen,Keunho Byeon,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak*

Main category: cs.CV

TL;DR: Ano-NAViLa是一种用于计算病理学异常检测的视觉-语言模型，它通过结合正常和异常病理学知识来解决现有方法的局限性，并在淋巴结数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的异常检测旨在识别罕见且稀缺的异常，但疾病相关数据通常有限或缺失。现有的异常检测方法主要为工业环境设计，在病理学中面临计算限制、组织结构多样性和缺乏可解释性等问题。

Method: 我们提出了Ano-NAViLa，一个基于预训练视觉-语言模型和轻量级可训练MLP的正常和异常病理学知识增强型视觉-语言模型。它通过结合正常和异常病理学知识，提高对病理图像变异性的准确性和鲁棒性，并通过图像-文本关联提供可解释性。

Result: 在来自不同器官的两个淋巴结数据集上进行评估，Ano-NAViLa在异常检测和定位方面实现了最先进的性能，优于竞争模型。

Conclusion: Ano-NAViLa通过融合正常和异常病理学知识，有效解决了计算病理学中异常检测的挑战，并在准确性、鲁棒性和可解释性方面表现出色，达到了最先进的水平。

Abstract: Anomaly detection in computational pathology aims to identify rare and scarce
anomalies where disease-related data are often limited or missing. Existing
anomaly detection methods, primarily designed for industrial settings, face
limitations in pathology due to computational constraints, diverse tissue
structures, and lack of interpretability. To address these challenges, we
propose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented
Vision-Language model for Anomaly detection in pathology images. Ano-NAViLa is
built on a pre-trained vision-language model with a lightweight trainable MLP.
By incorporating both normal and abnormal pathology knowledge, Ano-NAViLa
enhances accuracy and robustness to variability in pathology images and
provides interpretability through image-text associations. Evaluated on two
lymph node datasets from different organs, Ano-NAViLa achieves the
state-of-the-art performance in anomaly detection and localization,
outperforming competing models.

</details>


### [23] [RATopo: Improving Lane Topology Reasoning via Redundancy Assignment](https://arxiv.org/abs/2508.15272)
*Han Li,Shaofei Huang,Longfei Xu,Yulu Gao,Beipeng Mu,Si Liu*

Main category: cs.CV

TL;DR: RATopo通过冗余分配策略和Transformer解码器重构，提升了车道拓扑推理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的车道拓扑推理方法因监督范围有限导致性能不佳。

Method: 本文提出了RATopo，一种用于车道拓扑推理的冗余分配策略。通过重构Transformer解码器，交换交叉注意和自注意层，并实例化多个并行的交叉注意块，实现数量丰富和几何多样性的拓扑监督。

Result: 在OpenLane-V2上的大量实验表明，RATopo策略与模型无关，可以无缝集成到现有框架中，持续提高车道-车道和车道-交通拓扑性能。

Conclusion: RATopo通过冗余分配策略，解决了现有方法监督范围有限的问题，显著提升了车道拓扑推理的性能。

Abstract: Lane topology reasoning plays a critical role in autonomous driving by
modeling the connections among lanes and the topological relationships between
lanes and traffic elements. Most existing methods adopt a
first-detect-then-reason paradigm, where topological relationships are
supervised based on the one-to-one assignment results obtained during the
detection stage. This supervision strategy results in suboptimal topology
reasoning performance due to the limited range of valid supervision. In this
paper, we propose RATopo, a Redundancy Assignment strategy for lane Topology
reasoning that enables quantity-rich and geometry-diverse topology supervision.
Specifically, we restructure the Transformer decoder by swapping the
cross-attention and self-attention layers. This allows redundant lane
predictions to be retained before suppression, enabling effective one-to-many
assignment. We also instantiate multiple parallel cross-attention blocks with
independent parameters, which further enhances the diversity of detected lanes.
Extensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is
model-agnostic and can be seamlessly integrated into existing topology
reasoning frameworks, consistently improving both lane-lane and lane-traffic
topology performance.

</details>


### [24] [DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding](https://arxiv.org/abs/2508.15297)
*Zhu Wang,Homaira Huda Shomee,Sathya N. Ravi,Sourav Medya*

Main category: cs.CV

TL;DR: DesignCLIP是一个统一的框架，它利用CLIP模型和多模态方法，通过类别感知分类、对比学习和详细图像描述，改进了设计专利分析，并在专利分类和检索任务上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统设计专利分析中，专利图像缺乏全面的视觉上下文和语义信息，导致评估模糊。最近的视觉-语言模型（如CLIP）为更可靠、准确的AI驱动专利分析提供了机会。

Method: 本文利用CLIP模型开发了一个统一框架DesignCLIP，用于设计专利应用。该框架通过类别感知分类和对比学习，结合生成的专利图像详细描述和多视图图像学习，来处理专利数据的独特特性。

Result: DesignCLIP在专利分类和专利检索等各种下游任务中，持续优于专利领域的基线模型和SOTA模型。此外，它还探索了多模态专利检索，这有可能通过提供更多样化的灵感来源来增强设计的创造性和创新性。

Conclusion: 多模态方法在推进专利分析方面前景广阔。

Abstract: In the field of design patent analysis, traditional tasks such as patent
classification and patent image retrieval heavily depend on the image data.
However, patent images -- typically consisting of sketches with abstract and
structural elements of an invention -- often fall short in conveying
comprehensive visual context and semantic information. This inadequacy can lead
to ambiguities in evaluation during prior art searches. Recent advancements in
vision-language models, such as CLIP, offer promising opportunities for more
reliable and accurate AI-driven patent analysis. In this work, we leverage CLIP
models to develop a unified framework DesignCLIP for design patent applications
with a large-scale dataset of U.S. design patents. To address the unique
characteristics of patent data, DesignCLIP incorporates class-aware
classification and contrastive learning, utilizing generated detailed captions
for patent images and multi-views image learning. We validate the effectiveness
of DesignCLIP across various downstream tasks, including patent classification
and patent retrieval. Additionally, we explore multimodal patent retrieval,
which provides the potential to enhance creativity and innovation in design by
offering more diverse sources of inspiration. Our experiments show that
DesignCLIP consistently outperforms baseline and SOTA models in the patent
domain on all tasks. Our findings underscore the promise of multimodal
approaches in advancing patent analysis. The codebase is available here:
https://anonymous.4open.science/r/PATENTCLIP-4661/README.md.

</details>


### [25] [TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification](https://arxiv.org/abs/2508.15298)
*Darya Taratynova,Alya Almsouti,Beknur Kalmakhanbet,Numan Saeed,Mohammad Yaqub*

Main category: cs.CV

TL;DR: TPA是一种用于胎儿先天性心脏病（CHD）超声视频分类的新方法，通过整合时间建模、提示感知对比学习和不确定性量化，实现了最先进的性能和更好的校准。


<details>
  <summary>Details</summary>
Motivation: 在超声视频中检测先天性心脏缺陷（CHD）受到图像噪声和探头定位变异性的阻碍。当前的机器学习方法通常忽略时间信息，局限于二元分类，并且不考虑预测校准。

Method: 我们提出了时间提示对齐（TPA）方法，该方法利用基础图像-文本模型和提示感知对比学习来对心脏超声视频中的胎儿CHD进行分类。TPA从视频子片段的每一帧中提取特征，使用可训练的时间提取器进行聚合以捕获心脏运动，并通过边际铰链对比损失将视频表示与类别特定的文本提示对齐。为了增强临床可靠性，我们引入了条件变分自编码器风格调制（CVAESM）模块。

Result: 在CHD检测的私有数据集和用于收缩功能障碍的大型公共数据集EchoNet-Dynamic上进行评估，TPA在CHD诊断方面达到了85.40%的最先进宏观F1分数，同时将预期校准误差降低了5.38%，将自适应ECE降低了6.8%。在EchoNet-Dynamic的三分类任务上，它将宏观F1提高了4.73%（从53.89%到58.62%）。

Conclusion: 时间提示对齐（TPA）是一个用于超声视频中胎儿先天性心脏缺陷（CHD）分类的框架，它集成了时间建模、提示感知对比学习和不确定性量化。

Abstract: Congenital heart defect (CHD) detection in ultrasound videos is hindered by
image noise and probe positioning variability. While automated methods can
reduce operator dependence, current machine learning approaches often neglect
temporal information, limit themselves to binary classification, and do not
account for prediction calibration. We propose Temporal Prompt Alignment (TPA),
a method leveraging foundation image-text model and prompt-aware contrastive
learning to classify fetal CHD on cardiac ultrasound videos. TPA extracts
features from each frame of video subclips using an image encoder, aggregates
them with a trainable temporal extractor to capture heart motion, and aligns
the video representation with class-specific text prompts via a margin-hinge
contrastive loss. To enhance calibration for clinical reliability, we introduce
a Conditional Variational Autoencoder Style Modulation (CVAESM) module, which
learns a latent style vector to modulate embeddings and quantifies
classification uncertainty. Evaluated on a private dataset for CHD detection
and on a large public dataset, EchoNet-Dynamic, for systolic dysfunction, TPA
achieves state-of-the-art macro F1 scores of 85.40% for CHD diagnosis, while
also reducing expected calibration error by 5.38% and adaptive ECE by 6.8%. On
EchoNet-Dynamic's three-class task, it boosts macro F1 by 4.73% (from 53.89% to
58.62%). Temporal Prompt Alignment (TPA) is a framework for fetal congenital
heart defect (CHD) classification in ultrasound videos that integrates temporal
modeling, prompt-aware contrastive learning, and uncertainty quantification.

</details>


### [26] [BasketLiDAR: The First LiDAR-Camera Multimodal Dataset for Professional Basketball MOT](https://arxiv.org/abs/2508.15299)
*Ryunosuke Hayashi,Kohei Torimi,Rokuto Nagata,Kazuma Ikeda,Ozora Sako,Taichi Nakamura,Masaki Tani,Yoshimitsu Aoki,Kentaro Yoshioka*

Main category: cs.CV

TL;DR: 本研究构建了BasketLiDAR数据集，这是体育MOT领域首个结合LiDAR点云与多视角相机镜头的多模态数据集。在此基础上，提出了一种新颖的MOT框架，利用LiDAR高精度的3D空间信息，实现了在专业篮球环境中实时、高精度的3D球员轨迹跟踪，即使在遮挡条件下也表现出色。


<details>
  <summary>Details</summary>
Motivation: 体育运动中实时3D球员轨迹跟踪对于战术分析、表现评估和提升观赛体验至关重要。然而，传统的多摄像头系统受限于视频数据的二维性及复杂的三维重建处理，难以实现实时分析。篮球运动因球员快速复杂移动、场地限制及频繁遮挡，是多目标跟踪（MOT）领域中最困难的场景之一。

Method: 本论文构建了BasketLiDAR，这是体育MOT领域首个结合LiDAR点云与同步多视角相机镜头的多模态数据集。该数据集包含4,445帧和3,105个球员ID，记录了专业篮球运动员的5对5和3对3比赛数据，提供完整的3D位置信息和ID注释。在此基础上，提出了一种新颖的MOT算法，该算法利用LiDAR高精度的3D空间信息，包括一个单独使用LiDAR的实时跟踪管道和一个融合LiDAR和相机数据的多模态跟踪管道。

Result: 实验结果表明，该方法实现了实时操作，并在遮挡条件下取得了优越的跟踪性能，这在传统仅使用摄像头的方法中是难以实现的。

Conclusion: 本研究通过引入首个结合LiDAR和相机数据的多模态数据集BasketLiDAR以及新颖的多目标跟踪框架，成功解决了篮球运动中实时3D球员轨迹跟踪的挑战，显著提升了跟踪精度并降低了计算成本。

Abstract: Real-time 3D trajectory player tracking in sports plays a crucial role in
tactical analysis, performance evaluation, and enhancing spectator experience.
Traditional systems rely on multi-camera setups, but are constrained by the
inherently two-dimensional nature of video data and the need for complex 3D
reconstruction processing, making real-time analysis challenging. Basketball,
in particular, represents one of the most difficult scenarios in the MOT field,
as ten players move rapidly and complexly within a confined court space, with
frequent occlusions caused by intense physical contact.
  To address these challenges, this paper constructs BasketLiDAR, the first
multimodal dataset in the sports MOT field that combines LiDAR point clouds
with synchronized multi-view camera footage in a professional basketball
environment, and proposes a novel MOT framework that simultaneously achieves
improved tracking accuracy and reduced computational cost. The BasketLiDAR
dataset contains a total of 4,445 frames and 3,105 player IDs, with fully
synchronized IDs between three LiDAR sensors and three multi-view cameras. We
recorded 5-on-5 and 3-on-3 game data from actual professional basketball
players, providing complete 3D positional information and ID annotations for
each player. Based on this dataset, we developed a novel MOT algorithm that
leverages LiDAR's high-precision 3D spatial information. The proposed method
consists of a real-time tracking pipeline using LiDAR alone and a multimodal
tracking pipeline that fuses LiDAR and camera data. Experimental results
demonstrate that our approach achieves real-time operation, which was difficult
with conventional camera-only methods, while achieving superior tracking
performance even under occlusion conditions. The dataset is available upon
request at: https://sites.google.com/keio.jp/keio-csg/projects/basket-lidar

</details>


### [27] [First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection](https://arxiv.org/abs/2508.15313)
*Wutao Liu,YiDan Wang,Pan Gao*

Main category: cs.CV

TL;DR: RAG-SEG是一种无需训练的伪装物体检测方法，它结合了检索增强生成（RAG）和SAM进行分割，实现了与SOTA方法相当或超越的性能，并具有高计算效率。


<details>
  <summary>Details</summary>
Motivation: 伪装物体检测（COD）因物体与背景的高度相似性而极具挑战。现有方法通常需要大量训练和计算资源。基础模型（如SAM）在未经微调的情况下难以处理COD任务，并且需要高质量、昂贵的手动提示才能表现良好。

Method: 我们提出了“First RAG, Second SEG (RAG-SEG)”范式，它无需训练，将COD解耦为两个阶段：首先是检索增强生成（RAG）用于生成粗略掩码作为提示，然后是基于SAM的分割（SEG）进行细化。RAG-SEG通过无监督聚类构建紧凑的检索数据库，实现快速有效的特征检索。在推理过程中，检索到的特征生成伪标签，指导SAM2进行精确的掩码生成。

Result: 该方法无需传统训练，同时保持了具有竞争力的性能。在基准COD数据集上进行的广泛实验表明，RAG-SEG的性能与最先进的方法相当或超越。所有实验均在个人笔记本电脑上进行，突显了我们方法的计算效率和实用性。

Conclusion: RAG-SEG是一种无需训练、计算高效且实用的伪装物体检测方法，它通过两阶段的检索与分割策略，在COD任务上取得了与或超越现有先进方法的表现。

Abstract: Camouflaged object detection (COD) poses a significant challenge in computer
vision due to the high similarity between objects and their backgrounds.
Existing approaches often rely on heavy training and large computational
resources. While foundation models such as the Segment Anything Model (SAM)
offer strong generalization, they still struggle to handle COD tasks without
fine-tuning and require high-quality prompts to yield good performance.
However, generating such prompts manually is costly and inefficient. To address
these challenges, we propose \textbf{First RAG, Second SEG (RAG-SEG)}, a
training-free paradigm that decouples COD into two stages: Retrieval-Augmented
Generation (RAG) for generating coarse masks as prompts, followed by SAM-based
segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval
database via unsupervised clustering, enabling fast and effective feature
retrieval. During inference, the retrieved features produce pseudo-labels that
guide precise mask generation using SAM2. Our method eliminates the need for
conventional training while maintaining competitive performance. Extensive
experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par
with or surpasses state-of-the-art methods. Notably, all experiments are
conducted on a \textbf{personal laptop}, highlighting the computational
efficiency and practicality of our approach. We present further analysis in the
Appendix, covering limitations, salient object detection extension, and
possible improvements.

</details>


### [28] [VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.15314)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Zhi Chen,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CV

TL;DR: VideoEraser是一个免训练框架，通过两阶段过程防止文本到视频（T2V）扩散模型生成不良内容，并在多项任务中表现出最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 文本到视频（T2V）扩散模型的快速发展引发了隐私、版权和安全方面的担忧，因为它们可能被滥用以生成有害或误导性内容。这些模型通常在包含未经授权的个人身份、艺术创作和有害材料的众多数据集上进行训练，这可能导致此类内容的失控生产和分发。

Method: 我们提出了VideoEraser，一个免训练的框架，通过一个两阶段过程（选择性提示嵌入调整SPEA和对抗性弹性噪声引导ARNG），作为一个即插即用的模块与T2V扩散模型无缝集成，阻止T2V扩散模型生成具有不良概念的视频，即使明确提示这些概念。

Result: 在对象擦除、艺术风格擦除、名人擦除和明确内容擦除等四项任务中进行了广泛评估。实验结果表明，VideoEraser在功效、完整性、保真度、鲁棒性和泛化性方面始终优于现有方法。值得注意的是，VideoEraser在抑制T2V生成过程中的不良内容方面取得了最先进的性能，与基线相比，在四项任务中平均减少了46%。

Conclusion: VideoEraser能够有效地抑制T2V生成过程中的不良内容，实现了最先进的性能。

Abstract: The rapid growth of text-to-video (T2V) diffusion models has raised concerns
about privacy, copyright, and safety due to their potential misuse in
generating harmful or misleading content. These models are often trained on
numerous datasets, including unauthorized personal identities, artistic
creations, and harmful materials, which can lead to uncontrolled production and
distribution of such content. To address this, we propose VideoEraser, a
training-free framework that prevents T2V diffusion models from generating
videos with undesirable concepts, even when explicitly prompted with those
concepts. Designed as a plug-and-play module, VideoEraser can seamlessly
integrate with representative T2V diffusion models via a two-stage process:
Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise
Guidance (ARNG). We conduct extensive evaluations across four tasks, including
object erasure, artistic style erasure, celebrity erasure, and explicit content
erasure. Experimental results show that VideoEraser consistently outperforms
prior methods regarding efficacy, integrity, fidelity, robustness, and
generalizability. Notably, VideoEraser achieves state-of-the-art performance in
suppressing undesirable content during T2V generation, reducing it by 46% on
average across four tasks compared to baselines.

</details>


### [29] [Predicting Road Crossing Behaviour using Pose Detection and Sequence Modelling](https://arxiv.org/abs/2508.15336)
*Subhasis Dasgupta,Preetam Saha,Agniva Roy,Jaydip Sen*

Main category: cs.CV

TL;DR: 本研究旨在预测行人过马路意图，利用深度学习模型，发现1D CNN速度最快，GRU预测优于LSTM。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要远距离预测行人是否会过马路。

Method: 本研究采用深度学习模型进行姿态预测和序列建模（GRU、LSTM、1D CNN）进行时间预测，涉及视频分析。

Result: GRU在意图预测方面优于LSTM，但1D CNN在速度方面表现最佳。

Conclusion: 本研究开发了一个端到端的深度学习框架，通过整合姿态检测和序列建模来预测行人过马路意图。

Abstract: The world is constantly moving towards AI based systems and autonomous
vehicles are now reality in different parts of the world. These vehicles
require sensors and cameras to detect objects and maneuver according to that.
It becomes important to for such vehicles to also predict from a distant if a
person is about to cross a road or not. The current study focused on predicting
the intent of crossing the road by pedestrians in an experimental setup. The
study involved working with deep learning models to predict poses and sequence
modelling for temporal predictions. The study analysed three different sequence
modelling to understand the prediction behaviour and it was found out that GRU
was better in predicting the intent compared to LSTM model but 1D CNN was the
best model in terms of speed. The study involved video analysis, and the output
of pose detection model was integrated later on to sequence modelling
techniques for an end-to-end deep learning framework for predicting road
crossing intents.

</details>


### [30] [RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features](https://arxiv.org/abs/2508.15353)
*Olga Matykina,Dmitry Yudin*

Main category: cs.CV

TL;DR: RCDINO是一种多模态transformer模型，通过融合DINOv2的语义信息来增强雷达-相机3D目标检测，在nuScenes数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 三维目标检测对于自动驾驶和机器人技术至关重要，它依赖于相机和雷达多模态数据的有效融合。

Method: 本文提出了RCDINO，一种多模态transformer模型，通过将视觉主干特征与预训练的DINOv2基础模型的语义丰富表示融合来增强视觉特征，从而提高模型的检测性能并保持与基线架构的兼容性。

Result: 在nuScenes数据集上的实验表明，RCDINO在雷达-相机模型中达到了最先进的性能，NDS为56.4，mAP为48.1。

Conclusion: RCDINO通过有效融合雷达和相机数据，并利用DINOv2的语义表示，显著提升了三维目标检测的性能，达到了当前最优水平。

Abstract: Three-dimensional object detection is essential for autonomous driving and
robotics, relying on effective fusion of multimodal data from cameras and
radar. This work proposes RCDINO, a multimodal transformer-based model that
enhances visual backbone features by fusing them with semantically rich
representations from the pretrained DINOv2 foundation model. This approach
enriches visual representations and improves the model's detection performance
while preserving compatibility with the baseline architecture. Experiments on
the nuScenes dataset demonstrate that RCDINO achieves state-of-the-art
performance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our
implementation is available at https://github.com/OlgaMatykina/RCDINO.

</details>


### [31] [An Empirical Study on How Video-LLMs Answer Video Questions](https://arxiv.org/abs/2508.15360)
*Chenhui Gou,Ziyu Ma,Zicheng Duan,Haoyu He,Feng Chen,Akide Liu,Bohan Zhuang,Jianfei Cai,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 本研究系统地探究了视频大型语言模型（Video-LLMs）的内部工作机制，发现视频信息提取主要在早期层完成，某些中间层影响巨大，且语言引导的检索比自注意力更关键，这些发现有助于提高模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注提高视频大型语言模型（Video-LLMs）的性能，但对其内部机制的理解有限。本文旨在通过系统的实证研究弥补这一空白。

Method: 本文采用注意力敲除作为主要分析工具，设计了三种变体：视频时间敲除、视频空间敲除和语言到视频敲除。这些敲除应用于不同层数的窗口，并在全局和细粒度两种设置下进行。

Result: 1. 在全局设置下，视频信息提取主要发生在早期层，形成两阶段过程：低层侧重感知编码，高层处理抽象推理。2. 在细粒度设置下，某些中间层对视频问答有显著影响，而大多数其他层贡献微乎其微。3. 在两种设置下，时空建模更依赖语言引导的检索，而非视频tokens之间的帧内和帧间自注意力。

Conclusion: 这些发现有助于理解Video-LLMs如何内部处理视频内容，并可用于减少注意力计算，为未来研究提供了可解释性和效率的视角。

Abstract: Taking advantage of large-scale data and pretrained language models, Video
Large Language Models (Video-LLMs) have shown strong capabilities in answering
video questions. However, most existing efforts focus on improving performance,
with limited attention to understanding their internal mechanisms. This paper
aims to bridge this gap through a systematic empirical study. To interpret
existing VideoLLMs, we adopt attention knockouts as our primary analytical tool
and design three variants: Video Temporal Knockout, Video Spatial Knockout, and
Language-to-Video Knockout. Then, we apply these three knockouts on different
numbers of layers (window of layers). By carefully controlling the window of
layers and types of knockouts, we provide two settings: a global setting and a
fine-grained setting. Our study reveals three key findings: (1) Global setting
indicates Video information extraction primarily occurs in early layers,
forming a clear two-stage process -- lower layers focus on perceptual encoding,
while higher layers handle abstract reasoning; (2) In the fine-grained setting,
certain intermediate layers exert an outsized impact on video question
answering, acting as critical outliers, whereas most other layers contribute
minimally; (3) In both settings, we observe that spatial-temporal modeling
relies more on language-guided retrieval than on intra- and inter-frame
self-attention among video tokens, despite the latter's high computational
cost. Finally, we demonstrate that these insights can be leveraged to reduce
attention computation in Video-LLMs. To our knowledge, this is the first work
to systematically uncover how Video-LLMs internally process and understand
video content, offering interpretability and efficiency perspectives for future
research.

</details>


### [32] [Transfer learning optimization based on evolutionary selective fine tuning](https://arxiv.org/abs/2508.15367)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune利用进化算法选择性地微调深度学习模型，通过减少计算成本和避免过拟合，使迁移学习比传统方法更高效、更准确。


<details>
  <summary>Details</summary>
Motivation: 大型模型的计算需求和传统微调方法（更新所有参数）可能导致过拟合和高计算成本。

Method: 本文提出BioTune，一种进化自适应微调技术，通过进化算法选择性地微调模型层，以提高迁移学习效率。

Result: BioTune在九个图像分类数据集上表现出与现有微调方法（如AutoRGN和LoRA）相比具有竞争力或更高的准确性和效率，同时通过集中微调减少了可训练参数数量，降低了计算成本。

Conclusion: BioTune通过选择性地微调相关层，有效提升了迁移学习的效率和准确性，并显著降低了计算成本。

Abstract: Deep learning has shown substantial progress in image analysis. However, the
computational demands of large, fully trained models remain a consideration.
Transfer learning offers a strategy for adapting pre-trained models to new
tasks. Traditional fine-tuning often involves updating all model parameters,
which can potentially lead to overfitting and higher computational costs. This
paper introduces BioTune, an evolutionary adaptive fine-tuning technique that
selectively fine-tunes layers to enhance transfer learning efficiency. BioTune
employs an evolutionary algorithm to identify a focused set of layers for
fine-tuning, aiming to optimize model performance on a given target task.
Evaluation across nine image classification datasets from various domains
indicates that BioTune achieves competitive or improved accuracy and efficiency
compared to existing fine-tuning methods such as AutoRGN and LoRA. By
concentrating the fine-tuning process on a subset of relevant layers, BioTune
reduces the number of trainable parameters, potentially leading to decreased
computational cost and facilitating more efficient transfer learning across
diverse data characteristics and distributions.

</details>


### [33] [Image-Conditioned 3D Gaussian Splat Quantization](https://arxiv.org/abs/2508.15372)
*Xinshuang Liu,Runfa Blark Li,Keito Suzuki,Truong Nguyen*

Main category: cs.CV

TL;DR: ICGS-Quantizer 是一种新的3DGS压缩方法，能将场景压缩至千字节级别，并支持存档后场景更新，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS压缩方法存在两个局限性：1) 压缩中等规模场景仍停留在兆字节范围，不适用于大规模场景或大量场景集合；2) 缺乏长期存档后适应场景变化的机制。

Method: 本文提出了一种图像条件高斯斑点量化器（ICGS-Quantizer）。该方法通过联合利用高斯间和属性间相关性，并使用跨所有训练场景的共享码本，来提高量化效率。此外，它通过在解码时基于捕获的图像来解码场景，从而实现对存档后场景变化的适应性。编码、量化和解码过程是联合训练的。

Result: ICGS-Quantizer 将3DGS的存储需求降低到千字节范围，同时保持视觉保真度。实验结果表明，该方法在压缩效率和场景变化适应性方面始终优于现有先进方法。

Conclusion: ICGS-Quantizer 有效解决了现有3DGS压缩方法的局限性，在压缩效率和适应场景变化方面表现出色，使其适用于3D场景的长期存档和更新。

Abstract: 3D Gaussian Splatting (3DGS) has attracted considerable attention for
enabling high-quality real-time rendering. Although 3DGS compression methods
have been proposed for deployment on storage-constrained devices, two
limitations hinder archival use: (1) they compress medium-scale scenes only to
the megabyte range, which remains impractical for large-scale scenes or
extensive scene collections; and (2) they lack mechanisms to accommodate scene
changes after long-term archival. To address these limitations, we propose an
Image-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially
enhances compression efficiency and provides adaptability to scene changes
after archiving. ICGS-Quantizer improves quantization efficiency by jointly
exploiting inter-Gaussian and inter-attribute correlations and by using shared
codebooks across all training scenes, which are then fixed and applied to
previously unseen test scenes, eliminating the overhead of per-scene codebooks.
This approach effectively reduces the storage requirements for 3DGS to the
kilobyte range while preserving visual fidelity. To enable adaptability to
post-archival scene changes, ICGS-Quantizer conditions scene decoding on images
captured at decoding time. The encoding, quantization, and decoding processes
are trained jointly, ensuring that the codes, which are quantized
representations of the scene, are effective for conditional decoding. We
evaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.
Experimental results show that ICGS-Quantizer consistently outperforms
state-of-the-art methods in compression efficiency and adaptability to scene
changes. Our code, model, and data will be publicly available on GitHub.

</details>


### [34] [DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians](https://arxiv.org/abs/2508.15376)
*Cong Wang,Xianda Guo,Wenbo Xu,Wei Tian,Ruiqi Song,Chenming Zhang,Lingxi Li,Long Chen*

Main category: cs.CV

TL;DR: DriveSplat是一种新的驾驶场景3D高斯Splatting方法，通过动态-静态解耦、区域体素初始化、可变形高斯以及深度/法线先验，提高了驾驶场景下新颖视角合成的几何准确性和鲁棒性，并在Waymo和KITTI数据集上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 针对驾驶场景中快速移动的车辆、行人以及大规模静态背景带来的3D场景重建挑战。现有的3D高斯Splatting方法通过解耦动态和静态组件来解决运动模糊问题，但这些方法忽略了背景优化中的几何关系，并且仅通过添加高斯来拟合每个训练视图，导致在新视角渲染时鲁棒性有限，且缺乏准确的几何表示。

Method: 提出DriveSplat，一种基于神经高斯表示和动态-静态解耦的驾驶场景高质量重建方法。采用区域体素初始化方案，将场景划分为近、中、远三个区域，以适应驾驶视角的线性运动模式并增强近距离细节表示。引入可变形神经高斯来建模非刚性动态物体，其参数通过可学习的形变网络进行时间调整。整个框架还通过预训练模型的深度和法线先验进行监督，以提高几何结构的准确性。

Result: 在Waymo和KITTI数据集上进行了严格评估，在新颖视角合成方面达到了最先进的性能。

Conclusion: DriveSplat有效解决了现有3D高斯Splatting方法在驾驶场景中存在的局限性，实现了高质量的3D场景重建，并在新颖视角合成方面提高了鲁棒性和几何准确性。

Abstract: In the realm of driving scenarios, the presence of rapidly moving vehicles,
pedestrians in motion, and large-scale static backgrounds poses significant
challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian
Splatting address the motion blur problem by decoupling dynamic and static
components within the scene. However, these decoupling strategies overlook
background optimization with adequate geometry relationships and rely solely on
fitting each training view by adding Gaussians. Therefore, these models exhibit
limited robustness in rendering novel views and lack an accurate geometric
representation. To address the above issues, we introduce DriveSplat, a
high-quality reconstruction method for driving scenarios based on neural
Gaussian representations with dynamic-static decoupling. To better accommodate
the predominantly linear motion patterns of driving viewpoints, a region-wise
voxel initialization scheme is employed, which partitions the scene into near,
middle, and far regions to enhance close-range detail representation.
Deformable neural Gaussians are introduced to model non-rigid dynamic actors,
whose parameters are temporally adjusted by a learnable deformation network.
The entire framework is further supervised by depth and normal priors from
pre-trained models, improving the accuracy of geometric structures. Our method
has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating
state-of-the-art performance in novel-view synthesis for driving scenarios.

</details>


### [35] [DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability](https://arxiv.org/abs/2508.15387)
*Ruizhuo Song,Beiming Yuan*

Main category: cs.CV

TL;DR: 本文旨在通过解决拉文渐进矩阵 (RPM) 问题来提升深度学习模型的抽象推理能力。论文采用因果链建模方法分析 RPM 任务，并设计了基线模型 DIO。然而，DIO 在捕获人类推理逻辑方面存在局限，因此本文将提出三种改进方法。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型表现出色，但在抽象推理方面仍存在根本性瓶颈。学术界引入拉文渐进矩阵 (RPM) 作为评估抽象推理能力的权威基准。因此，本文旨在解决 RPM 问题，以增强机器智能的抽象推理能力。

Method: 本文首先采用“因果链建模”视角，系统分析 RPM 任务的完整因果链（图像→抽象属性→渐进属性模式→模式一致性→正确答案）。基于此分析，设计了基线模型 DIO 的网络架构。为克服 DIO 的局限性，论文将逐步提出三种改进方法。

Result: 实验表明，为 DIO 制定的优化目标（最大化上下文与正确选项之间互信息的变分下界）未能使模型真正习得预定义的人类推理逻辑。主要原因在于下界的紧密性严重影响互信息最大化的有效性，且互信息作为统计量无法捕捉主体与客体之间的因果关系。

Conclusion: 为克服当前模型在抽象推理和因果关系建模方面的局限性，并真正提升机器智能的抽象推理能力，本文将提出并探索三种改进方法。

Abstract: Despite the outstanding performance of current deep learning models across
various domains, their fundamental bottleneck in abstract reasoning remains
unresolved. To address this challenge, the academic community has introduced
Raven's Progressive Matrices (RPM) problems as an authoritative benchmark for
evaluating the abstract reasoning capabilities of deep learning algorithms,
with a focus on core intelligence dimensions such as abstract reasoning,
pattern recognition, and complex problem-solving. Therefore, this paper centers
on solving RPM problems, aiming to contribute to enhancing the abstract
reasoning abilities of machine intelligence. Firstly, this paper adopts a
``causal chain modeling'' perspective to systematically analyze the complete
causal chain in RPM tasks: image $\rightarrow$ abstract attributes
$\rightarrow$ progressive attribute patterns $\rightarrow$ pattern consistency
$\rightarrow$ correct answer. Based on this analysis, the network architecture
of the baseline model DIO is designed. However, experiments reveal that the
optimization objective formulated for DIO, namely maximizing the variational
lower bound of mutual information between the context and the correct option,
fails to enable the model to genuinely acquire the predefined human reasoning
logic. This is attributed to two main reasons: the tightness of the lower bound
significantly impacts the effectiveness of mutual information maximization, and
mutual information, as a statistical measure, does not capture the causal
relationship between subjects and objects. To overcome these limitations, this
paper progressively proposes three improvement methods:

</details>


### [36] [Spiking Variational Graph Representation Inference for Video Summarization](https://arxiv.org/abs/2508.15389)
*Wenrui Li,Wei Han,Liang-Jian Deng,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: SpiVG网络通过结合脉冲神经网络、动态聚合图推理器和变分推理重建模块，有效解决了视频摘要中全局时间依赖和语义连贯性问题，并在多个数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频摘要方法难以捕捉全局时间依赖和保持语义连贯性，并且在多通道特征融合过程中易受噪声影响。

Method: 我们提出了一个SpiVG（Spiking Variational Graph）网络，包含基于脉冲神经网络（SNN）的关键帧提取器、动态聚合图推理器（解耦上下文对象一致性和语义视角连贯性），以及变分推理重建模块（通过ELBO和后验分布正则化处理多通道特征融合中的不确定性和噪声）。

Result: SpiVG在SumMe、TVSum、VideoXum和QFVS等多个数据集上超越了现有方法。

Conclusion: SpiVG网络通过增强信息密度和降低计算复杂性，有效解决了视频摘要的挑战，并取得了优于现有方法的性能。

Abstract: With the rise of short video content, efficient video summarization
techniques for extracting key information have become crucial. However,
existing methods struggle to capture the global temporal dependencies and
maintain the semantic coherence of video content. Additionally, these methods
are also influenced by noise during multi-channel feature fusion. We propose a
Spiking Variational Graph (SpiVG) Network, which enhances information density
and reduces computational complexity. First, we design a keyframe extractor
based on Spiking Neural Networks (SNN), leveraging the event-driven computation
mechanism of SNNs to learn keyframe features autonomously. To enable
fine-grained and adaptable reasoning across video frames, we introduce a
Dynamic Aggregation Graph Reasoner, which decouples contextual object
consistency from semantic perspective coherence. We present a Variational
Inference Reconstruction Module to address uncertainty and noise arising during
multi-channel feature fusion. In this module, we employ Evidence Lower Bound
Optimization (ELBO) to capture the latent structure of multi-channel feature
distributions, using posterior distribution regularization to reduce
overfitting. Experimental results show that SpiVG surpasses existing methods
across multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes
and pre-trained models are available at https://github.com/liwrui/SpiVG.

</details>


### [37] [From Linearity to Non-Linearity: How Masked Autoencoders Capture Spatial Correlations](https://arxiv.org/abs/2508.15404)
*Anthony Bisulco,Rahul Ramesh,Randall Balestriero,Pratik Chaudhari*

Main category: cs.CV

TL;DR: 本文分析了MAE超参数（掩蔽率和补丁大小）如何影响模型学习空间相关性，并为实践中的超参数选择提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管MAEs在视觉基础模型中表现出色，但应用于新数据集时需要大量的超参数调整（掩蔽率、补丁大小、编码器/解码器层），且超参数与下游任务性能之间的关系尚未充分探索。

Method: 本文研究了MAEs如何学习输入图像中的空间相关性。我们分析推导了线性MAE学习到的特征，并将分析扩展到非线性MAE。

Result: 掩蔽率和补丁大小可以用于选择捕获短程和长程空间相关性的特征。MAE表示能够适应数据集中超越二阶统计的空间相关性。

Conclusion: 本文讨论了在实践中如何选择MAE超参数的一些见解。

Abstract: Masked Autoencoders (MAEs) have emerged as a powerful pretraining technique
for vision foundation models. Despite their effectiveness, they require
extensive hyperparameter tuning (masking ratio, patch size, encoder/decoder
layers) when applied to novel datasets. While prior theoretical works have
analyzed MAEs in terms of their attention patterns and hierarchical latent
variable models, the connection between MAE hyperparameters and performance on
downstream tasks is relatively unexplored. This work investigates how MAEs
learn spatial correlations in the input image. We analytically derive the
features learned by a linear MAE and show that masking ratio and patch size can
be used to select for features that capture short- and long-range spatial
correlations. We extend this analysis to non-linear MAEs to show that MAE
representations adapt to spatial correlations in the dataset, beyond
second-order statistics. Finally, we discuss some insights on how to select MAE
hyper-parameters in practice.

</details>


### [38] [Bidirectional Temporal Information Propagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2508.15415)
*Dengyan Luo,Yanping Xiang,Hu Wang,Luping Ji. Shuai Li,Mao Ye*

Main category: cs.CV

TL;DR: 本文提出BIRD方法，通过双向时间信息传播策略，结合局部和全局时间信息，以解决现有红外小目标检测方法在处理视频时缺乏全局优化的不足。BIRD在实现最先进性能的同时，也表现出快速的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的多帧红外小目标检测方法主要采用滑动窗口方式聚合信息，但这种方法未考虑整个视频片段的联合优化，忽略了滑动窗口之外的全局时间信息，导致计算冗余和次优性能。

Method: 本文提出BIRD（Bidirectional temporal information propagation method for moving InfraRed small target Detection）方法。该方法采用双向传播策略，递归地利用相邻帧的局部时间信息以及过去和未来帧的全局时间信息。具体而言，在前向和后向传播分支中，设计了局部时间运动融合（LTMF）模块来建模目标帧与其相邻两帧之间的局部时空依赖性；然后，开发了全局时间运动融合（GTMF）模块来进一步聚合全局传播特征与局部融合特征。最后，将双向聚合的特征融合并输入检测头进行检测。此外，通过传统检测损失和附加的时空融合（STF）损失对整个视频片段进行联合优化。

Result: 广泛的实验表明，所提出的BIRD方法不仅达到了最先进的性能，而且还展示了快速的推理速度。

Conclusion: BIRD方法通过双向时间信息传播和联合优化，有效解决了现有方法的局限性，实现了红外小目标检测领域的领先性能和高效率。

Abstract: Moving infrared small target detection is broadly adopted in infrared search
and track systems, and has attracted considerable research focus in recent
years. The existing learning-based multi-frame methods mainly aggregate the
information of adjacent frames in a sliding window fashion to assist the
detection of the current frame. However, the sliding-window-based methods do
not consider joint optimization of the entire video clip and ignore the global
temporal information outside the sliding window, resulting in redundant
computation and sub-optimal performance. In this paper, we propose a
Bidirectional temporal information propagation method for moving InfraRed small
target Detection, dubbed BIRD. The bidirectional propagation strategy
simultaneously utilizes local temporal information of adjacent frames and
global temporal information of past and future frames in a recursive fashion.
Specifically, in the forward and backward propagation branches, we first design
a Local Temporal Motion Fusion (LTMF) module to model local spatio-temporal
dependency between a target frame and its two adjacent frames. Then, a Global
Temporal Motion Fusion (GTMF) module is developed to further aggregate the
global propagation feature with the local fusion feature. Finally, the
bidirectional aggregated features are fused and input into the detection head
for detection. In addition, the entire video clip is jointly optimized by the
traditional detection loss and the additional Spatio-Temporal Fusion (STF)
loss. Extensive experiments demonstrate that the proposed BIRD method not only
achieves the state-of-the-art performance but also shows a fast inference
speed.

</details>


### [39] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
*Ahmet Can Ömercikoğlu,Mustafa Mansur Yönügül,Pakize Erdoğmuş*

Main category: cs.CV

TL;DR: 本文比较了YOLOv11、YOLOv12和MTCNN三种人脸检测器在不同分辨率下的性能，发现YOLOv11在准确性上表现最佳，尤其是在高分辨率下，而YOLOv12召回率略高。


<details>
  <summary>Details</summary>
Motivation: 人脸检测是许多AI应用的关键组成部分，但低分辨率图像等真实世界条件会严重降低检测性能，因此需要系统性研究输入分辨率对人脸检测器性能的影响。

Method: 本研究系统地调查了输入分辨率对YOLOv11、YOLOv12和MTCNN三种深度学习人脸检测器准确性和鲁棒性的影响。使用WIDER FACE数据集，在160x160、320x320和640x640等多种图像分辨率下进行了广泛评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标评估了每个模型的性能。

Result: 结果表明，YOLOv11在检测准确性方面优于YOLOv12和MTCNN，特别是在更高分辨率下；YOLOv12的召回率略好；MTCNN在实时推理速度方面表现滞后。

Conclusion: 本研究结果为根据不同的操作限制选择适合分辨率的人脸检测模型提供了可操作的见解。

Abstract: Face detection is a crucial component in many AI-driven applications such as
surveillance, biometric authentication, and human-computer interaction.
However, real-world conditions like low-resolution imagery present significant
challenges that degrade detection performance. In this study, we systematically
investigate the impact of input resolution on the accuracy and robustness of
three prominent deep learning-based face detectors: YOLOv11, YOLOv12, and
MTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across
multiple image resolutions (160x160, 320x320, and 640x640) and assess each
model's performance using metrics such as precision, recall, mAP50, mAP50-95,
and inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN
in terms of detection accuracy, especially at higher resolutions, while YOLOv12
exhibits slightly better recall. MTCNN, although competitive in landmark
localization, lags in real-time inference speed. Our findings provide
actionable insights for selecting resolution-aware face detection models
suitable for varying operational constraints.

</details>


### [40] [A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles](https://arxiv.org/abs/2508.15431)
*Danish Zia Baig,Mohsin Kamal*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv8m-t42深度学习模型的汽车微小凹痕自动检测方案，该方案具有高精度，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 传统的汽车损伤检测方法劳动密集、手动操作且经常遗漏微小的表面缺陷（如微观凹痕），因此需要更快、更精确的检测方法。

Method: 本研究使用YOLOv8目标识别框架，特别是YOLOv8m及其定制变体YOLOv8m-t4和YOLOv8m-t42模型，构建了一个基于深度学习的解决方案。为此，创建了一个包含不同光照、角度和纹理下汽车表面带注释图像的定制数据集，并采用实时数据增强技术进行模型训练。

Result: 实验结果表明，该技术具有出色的检测精度和低推理延迟。其中，YOLOv8m-t42模型表现最佳，其精度为0.86，召回率为0.84，F1-分数为0.85，mAP@0.5稳定在0.60，PR曲线面积为0.88，优于YOLOv8m-t4模型。

Conclusion: YOLOv8m-t42模型具有更高的准确性，更适用于实际的凹痕检测应用，尽管其收敛速度较慢。

Abstract: Conventional car damage inspection techniques are labor-intensive, manual,
and frequently overlook tiny surface imperfections like microscopic dents.
Machine learning provides an innovative solution to the increasing demand for
quicker and more precise inspection methods. The paper uses the YOLOv8 object
recognition framework to provide a deep learning-based solution for
automatically detecting microscopic surface flaws, notably tiny dents, on car
exteriors. Traditional automotive damage inspection procedures are manual,
time-consuming, and frequently unreliable at detecting tiny flaws. To solve
this, a bespoke dataset containing annotated photos of car surfaces under
various lighting circumstances, angles, and textures was created. To improve
robustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and
YOLOv8m-t42, were trained employing real-time data augmentation approaches.
Experimental results show that the technique has excellent detection accuracy
and low inference latency, making it suited for real-time applications such as
automated insurance evaluations and automobile inspections. Evaluation
parameters such as mean Average Precision (mAP), precision, recall, and
F1-score verified the model's efficacy. With a precision of 0.86, recall of
0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4
model (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying
microscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the
mAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve
area was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82).
YOLOv8m-t42 has greater accuracy and is more appropriate for practical dent
detection applications, even though its convergence is slower.

</details>


### [41] [Aligning Moments in Time using Video Queries](https://arxiv.org/abs/2508.15439)
*Yogesh Kumar,Uday Agarwal,Manish Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: MATR是一个基于Transformer的模型，用于视频到视频精彩片段检索。它通过双阶段序列对齐和自监督预训练，在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 视频到视频精彩片段检索（Vid2VidMR）任务面临挑战，因为它需要语义帧级对齐以及建模查询视频和目标视频之间复杂依赖关系。

Method: 本文引入了MATR（Moment Alignment TRansformer），一个基于Transformer的模型。它通过双阶段序列对齐来捕获语义上下文和时间细节，利用查询视频特征来调整目标视频表示。MATR还使用前景/背景分类和边界预测头。此外，还提出了一种自监督预训练技术，用于为MATR提供强大的任务特定初始化。

Result: MATR在ActivityNet-VRL数据集上，与现有最先进方法相比，R@1提高了13.1%，mIoU提高了8.1%。在新的SportsMoments数据集上，MATR在R@1上提高了14.7%，在mIoU上提高了14.4%。

Conclusion: MATR通过捕获语义上下文和时间细节，有效解决了视频到视频精彩片段检索的挑战，并在流行的ActivityNet-VRL和新提出的SportsMoments数据集上实现了显著优于现有最先进方法的性能提升。

Abstract: Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen
events or moments in a target video using a query video. This task poses
several challenges, such as the need for semantic frame-level alignment and
modeling complex dependencies between query and target videos. To tackle this
challenging problem, we introduce MATR (Moment Alignment TRansformer), a
transformer-based model designed to capture semantic context as well as the
temporal details necessary for precise moment localization. MATR conditions
target video representations on query video features using dual-stage sequence
alignment that encodes the required correlations and dependencies. These
representations are then used to guide foreground/background classification and
boundary prediction heads, enabling the model to accurately identify moments in
the target video that semantically match with the query video. Additionally, to
provide a strong task-specific initialization for MATR, we propose a
self-supervised pre-training technique that involves training the model to
localize random clips within videos. Extensive experiments demonstrate that
MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU
on an absolute scale compared to state-of-the-art methods on the popular
ActivityNet-VRL dataset. Additionally, on our newly proposed dataset,
SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an
absolute scale over strong baselines.

</details>


### [42] [Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework](https://arxiv.org/abs/2508.15457)
*Zongqi He,Hanmin Li,Kin-Chung Chan,Yushen Zuo,Hao Xie,Zhe Xiao,Jun Xiao,Kin-Man Lam*

Main category: cs.CV

TL;DR: 本文提出了一种无需SfM的3DGS方法，用于从极稀疏视角输入中重建3D场景并合成新视图。它通过密集立体模块进行初始化，使用连贯视图插值生成额外监督，并引入多尺度拉普拉斯一致和自适应空间感知多尺度几何正则化来提高几何和渲染质量。实验表明，该方法在极稀疏视图条件下显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D Gaussian Splatting (3DGS) 方法在处理稀疏视图输入时表现不佳，因为其依赖的Structure-from-Motion (SfM) 方法无法准确重建场景的3D几何结构，导致渲染质量下降。

Method: 本文提出了一种无需SfM的3DGS方法，该方法共同估计相机姿态并从极稀疏视图输入中重建3D场景。具体而言，它使用一个密集立体模块逐步估计相机姿态信息并重建全局密集点云进行初始化。为了解决信息稀缺问题，提出了一种连贯视图插值模块，通过训练视图对插值相机姿态并生成视角一致的内容作为额外的监督信号。此外，引入了多尺度拉普拉斯一致正则化和自适应空间感知多尺度几何正则化来增强几何结构和渲染内容的质量。

Result: 该方法在极稀疏视图条件下（仅使用2个训练视图）实现了2.75dB的PSNR显著提升，合成图像失真最小，同时保留了丰富的高频细节，与现有技术相比具有卓越的视觉质量。

Conclusion: 本文提出的方法显著优于其他最先进的基于3DGS的方法，实现了卓越的视觉质量和更高的重建精度。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated remarkable real-time
performance in novel view synthesis, yet its effectiveness relies heavily on
dense multi-view inputs with precisely known camera poses, which are rarely
available in real-world scenarios. When input views become extremely sparse,
the Structure-from-Motion (SfM) method that 3DGS depends on for initialization
fails to accurately reconstruct the 3D geometric structures of scenes,
resulting in degraded rendering quality. In this paper, we propose a novel
SfM-free 3DGS-based method that jointly estimates camera poses and reconstructs
3D scenes from extremely sparse-view inputs. Specifically, instead of SfM, we
propose a dense stereo module to progressively estimates camera pose
information and reconstructs a global dense point cloud for initialization. To
address the inherent problem of information scarcity in extremely sparse-view
settings, we propose a coherent view interpolation module that interpolates
camera poses based on training view pairs and generates viewpoint-consistent
content as additional supervision signals for training. Furthermore, we
introduce multi-scale Laplacian consistent regularization and adaptive
spatial-aware multi-scale geometry regularization to enhance the quality of
geometrical structures and rendered content. Experiments show that our method
significantly outperforms other state-of-the-art 3DGS-based approaches,
achieving a remarkable 2.75dB improvement in PSNR under extremely sparse-view
conditions (using only 2 training views). The images synthesized by our method
exhibit minimal distortion while preserving rich high-frequency details,
resulting in superior visual quality compared to existing techniques.

</details>


### [43] [LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion](https://arxiv.org/abs/2508.15476)
*Chengqi Dong,Fenghe Tang,Rongge Mao,Xinpei Gao,S. Kevin Zhou*

Main category: cs.CV

TL;DR: LGMSNet是一种新型轻量级医学图像分割模型，通过局部和全局双重多尺度方法（异构层内核和稀疏Transformer-卷积混合分支）解决了现有模型的性能、效率和泛化性问题，在资源受限的医疗场景中表现出卓越的性能和零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的临床环境中，医学图像分割对疾病诊断和治疗规划至关重要，亟需轻量级且泛化能力强的模型。然而，现有轻量级模型通常以牺牲性能为代价，并且很少采用计算成本高的注意力机制，限制了其全局上下文感知能力。此外，当前架构忽略了医学成像中相同卷积核下的通道冗余问题，阻碍了有效的特征提取。

Method: 提出了LGMSNet，一个基于局部和全局双重多尺度的轻量级框架。LGMSNet利用异构层内核提取局部高频信息并减少通道冗余。同时，模型集成了稀疏Transformer-卷积混合分支以捕获低频全局信息。

Result: 在六个公共数据集上的大量实验表明，LGMSNet优于现有最先进的方法。特别是在四个未见过的数据集上的零样本泛化测试中，LGMSNet保持了卓越的性能。

Conclusion: LGMSNet作为一种新颖的轻量级框架，在最小计算开销下实现了最先进的性能，并在资源有限的医疗场景中展现出在医学图像分割领域实际部署的巨大潜力。

Abstract: Medical image segmentation plays a pivotal role in disease diagnosis and
treatment planning, particularly in resource-constrained clinical settings
where lightweight and generalizable models are urgently needed. However,
existing lightweight models often compromise performance for efficiency and
rarely adopt computationally expensive attention mechanisms, severely
restricting their global contextual perception capabilities. Additionally,
current architectures neglect the channel redundancy issue under the same
convolutional kernels in medical imaging, which hinders effective feature
extraction. To address these challenges, we propose LGMSNet, a novel
lightweight framework based on local and global dual multiscale that achieves
state-of-the-art performance with minimal computational overhead. LGMSNet
employs heterogeneous intra-layer kernels to extract local high-frequency
information while mitigating channel redundancy. In addition, the model
integrates sparse transformer-convolutional hybrid branches to capture
low-frequency global information. Extensive experiments across six public
datasets demonstrate LGMSNet's superiority over existing state-of-the-art
methods. In particular, LGMSNet maintains exceptional performance in zero-shot
generalization tests on four unseen datasets, underscoring its potential for
real-world deployment in resource-limited medical scenarios. The whole project
code is in https://github.com/cq-dong/LGMSNet.

</details>


### [44] [MExECON: Multi-view Extended Explicit Clothed humans Optimized via Normal integration](https://arxiv.org/abs/2508.15500)
*Fulden Ece Uğur,Rafael Redondo,Albert Barreiro,Stefan Hristov,Roger Marí*

Main category: cs.CV

TL;DR: MExECON是一个从稀疏多视图RGB图像重建穿衣人体3D模型的新方法，通过联合多视图身体优化和法线贴图集成，在不重新训练网络的情况下，提高了重建保真度，并具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是利用稀疏多视图RGB图像实现穿衣人体3D模型的重建，并通过多视角信息改进几何和身体姿态估计，克服单视角方法的局限性。

Method: 该论文提出了MExECON，一个用于从稀疏多视图RGB图像重建穿衣人体3D模型的新型管线。它基于单视图方法ECON，并扩展其能力以利用多个视角。核心是联合多视图身体优化（JMBO）算法，该算法将单个SMPL-X身体模型联合拟合到所有输入视图中，强制执行多视图一致性。优化后的身体模型作为低频先验，指导后续的表面重建，通过法线贴图集成添加几何细节，包括来自前后视图的法线贴图以捕捉衣物褶皱和发型等精细细节。所有多视图的提升都在不进行任何网络重新训练的情况下实现。

Result: 实验结果表明，MExECON在保真度上始终优于单视图基线，并且与现代少样本3D重建方法相比，取得了具有竞争力的性能。

Conclusion: MExECON是一个有效且新颖的管线，用于从稀疏多视图RGB图像中重建穿衣人体3D模型。它通过联合多视图优化和法线贴图集成，在不重新训练网络的情况下，显著提升了重建的保真度，并达到了与现有先进方法相当的水平。

Abstract: This work presents MExECON, a novel pipeline for 3D reconstruction of clothed
human avatars from sparse multi-view RGB images. Building on the single-view
method ECON, MExECON extends its capabilities to leverage multiple viewpoints,
improving geometry and body pose estimation. At the core of the pipeline is the
proposed Joint Multi-view Body Optimization (JMBO) algorithm, which fits a
single SMPL-X body model jointly across all input views, enforcing multi-view
consistency. The optimized body model serves as a low-frequency prior that
guides the subsequent surface reconstruction, where geometric details are added
via normal map integration. MExECON integrates normal maps from both front and
back views to accurately capture fine-grained surface details such as clothing
folds and hairstyles. All multi-view gains are achieved without requiring any
network re-training. Experimental results show that MExECON consistently
improves fidelity over the single-view baseline and achieves competitive
performance compared to modern few-shot 3D reconstruction methods.

</details>


### [45] [Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion](https://arxiv.org/abs/2508.15505)
*Mengyu Wang,Zhenyu Liu,Kun Li,Yu Wang,Yuwei Wang,Yanyan Wei,Fei Wang*

Main category: cs.CV

TL;DR: AdaSFFuse框架通过自适应小波变换和时空频率Mamba块，解决了多模态图像融合中的未对齐和细节丢失问题，实现了高效、泛化的图像融合，并在多种任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多模态图像融合（MMIF）旨在整合来自不同成像模态的互补信息，以克服单个传感器的局限性，提高图像质量并促进下游应用。然而，现有MMIF方法仍面临模态未对齐、高频细节破坏和任务特定限制等挑战。

Method: 我们提出了AdaSFFuse，一个通过自适应跨域协同融合学习实现任务泛化MMIF的新颖框架。AdaSFFuse引入了AdaWAT（用于频率解耦）和时空频率Mamba块（用于高效多模态融合）。AdaWAT自适应地分离图像的高频和低频分量，时空频率Mamba块则促进空间和频率域的跨域融合。

Result: AdaSFFuse在红外-可见光图像融合（IVF）、多焦点图像融合（MFF）、多曝光图像融合（MEF）和医学图像融合（MIF）四种MMIF任务上展现出卓越的融合性能，同时实现了低计算成本和紧凑的网络，在性能和效率之间取得了良好平衡。

Conclusion: AdaSFFuse通过其创新的AdaWAT和时空频率Mamba块，有效解决了多模态图像融合中的关键挑战，实现了在多种融合任务上的优越性能、高效率和泛化能力。

Abstract: Multimodal Image Fusion (MMIF) aims to integrate complementary information
from different imaging modalities to overcome the limitations of individual
sensors. It enhances image quality and facilitates downstream applications such
as remote sensing, medical diagnostics, and robotics. Despite significant
advancements, current MMIF methods still face challenges such as modality
misalignment, high-frequency detail destruction, and task-specific limitations.
To address these challenges, we propose AdaSFFuse, a novel framework for
task-generalized MMIF through adaptive cross-domain co-fusion learning.
AdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet
Transform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba
Blocks for efficient multimodal fusion. AdaWAT adaptively separates the high-
and low-frequency components of multimodal images from different scenes,
enabling fine-grained extraction and alignment of distinct frequency
characteristics for each modality. The Spatial-Frequency Mamba Blocks
facilitate cross-domain fusion in both spatial and frequency domains, enhancing
this process. These blocks dynamically adjust through learnable mappings to
ensure robust fusion across diverse modalities. By combining these components,
AdaSFFuse improves the alignment and integration of multimodal features,
reduces frequency loss, and preserves critical details. Extensive experiments
on four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image
Fusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF)
-- demonstrate AdaSFFuse's superior fusion performance, ensuring both low
computational cost and a compact network, offering a strong balance between
performance and efficiency. The code will be publicly available at
https://github.com/Zhen-yu-Liu/AdaSFFuse.

</details>


### [46] [ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors](https://arxiv.org/abs/2508.15529)
*Kaiyuan Tan,Yingying Shen,Haohui Zhu,Zhiwei Zhan,Shan Zhao,Mingfei Tu,Hongcheng Luo,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye*

Main category: cs.CV

TL;DR: ExtraGS通过结合几何和生成先验，提出了一种新的轨迹外推框架，解决了自动驾驶场景中外推视图的几何一致性和真实感问题。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶车辆模拟驾驶场景时，从记录的驾驶日志中合成外推视图至关重要，但现有方法常导致几何一致性差和渲染过于平滑。

Method: 我们提出了ExtraGS框架，它结合了几何和生成先验，核心是一个新的基于高斯-SDF的道路表面高斯（RSG）表示和用于处理远距离物体的远场高斯（FFG）。此外，开发了一种基于球谐函数的自监督不确定性估计框架。

Result: ExtraGS显著增强了外推视图的真实感和几何一致性，同时沿原始轨迹保持了高保真度。

Conclusion: ExtraGS有效解决了外推视图的合成挑战，获得了更真实、几何上更一致的结果。

Abstract: Synthesizing extrapolated views from recorded driving logs is critical for
simulating driving scenes for autonomous driving vehicles, yet it remains a
challenging task. Recent methods leverage generative priors as pseudo ground
truth, but often lead to poor geometric consistency and over-smoothed
renderings. To address these limitations, we propose ExtraGS, a holistic
framework for trajectory extrapolation that integrates both geometric and
generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG)
representation based on a hybrid Gaussian-Signed Distance Function (SDF)
design, and Far Field Gaussians (FFG) that use learnable scaling factors to
efficiently handle distant objects. Furthermore, we develop a self-supervised
uncertainty estimation framework based on spherical harmonics that enables
selective integration of generative priors only where extrapolation artifacts
occur. Extensive experiments on multiple datasets, diverse multi-camera setups,
and various generative priors demonstrate that ExtraGS significantly enhances
the realism and geometric consistency of extrapolated views, while preserving
high fidelity along the original trajectory.

</details>


### [47] [Multi-Object Sketch Animation with Grouping and Motion Trajectory Priors](https://arxiv.org/abs/2508.15535)
*Guotao Liang,Juncheng Hu,Ximing Xing,Jing Zhang,Qian Yu*

Main category: cs.CV

TL;DR: GroupSketch 是一种新颖的矢量草图动画方法，通过两阶段管道和基于组的位移网络（GDN）有效处理多对象交互和复杂运动，生成高质量、时间一致的动画，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在矢量草图动画中难以处理多对象交互和复杂运动，要么局限于单对象情况，要么存在时间不一致和泛化能力差的问题。

Method: 本文提出了GroupSketch，一个两阶段管道：第一阶段是运动初始化，将输入草图交互式地划分为语义组并定义关键帧，通过插值生成粗略动画；第二阶段是运动细化，提出了一种基于组的位移网络（GDN），通过预测特定组的位移场来细化粗略动画，并利用文本到视频模型的先验知识，GDN还包含上下文条件特征增强（CCFE）模块以提高时间一致性。

Result: 我们的方法在为复杂多对象草图生成高质量、时间一致的动画方面显著优于现有方法。

Conclusion: GroupSketch 扩展了草图动画的实际应用。

Abstract: We introduce GroupSketch, a novel method for vector sketch animation that
effectively handles multi-object interactions and complex motions. Existing
approaches struggle with these scenarios, either being limited to single-object
cases or suffering from temporal inconsistency and poor generalization. To
address these limitations, our method adopts a two-stage pipeline comprising
Motion Initialization and Motion Refinement. In the first stage, the input
sketch is interactively divided into semantic groups and key frames are
defined, enabling the generation of a coarse animation via interpolation. In
the second stage, we propose a Group-based Displacement Network (GDN), which
refines the coarse animation by predicting group-specific displacement fields,
leveraging priors from a text-to-video model. GDN further incorporates
specialized modules, such as Context-conditioned Feature Enhancement (CCFE), to
improve temporal consistency. Extensive experiments demonstrate that our
approach significantly outperforms existing methods in generating high-quality,
temporally consistent animations for complex, multi-object sketches, thus
expanding the practical applications of sketch animation.

</details>


### [48] [D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems](https://arxiv.org/abs/2508.15537)
*Chang Liu,Yang Xu,Tamas Sziranyi*

Main category: cs.CV

TL;DR: D3FNet是一种新的神经网络，通过差分注意力、双流解码和多尺度膨胀策略，显著提高了遥感图像中窄小道路的提取精度。


<details>
  <summary>Details</summary>
Motivation: 由于狭窄道路宽度有限、拓扑结构碎片化以及频繁遮挡，从高分辨率遥感图像中提取它们仍然是一个重大挑战。

Method: 提出了D3FNet，一个膨胀双流差分注意力融合网络，用于遥感系统中细粒度道路结构分割。D3FNet基于D-LinkNet的编码器-解码器骨干网络，并引入了三项关键创新：1）差分注意力膨胀提取（DADE）模块，在瓶颈处增强细微道路特征并抑制背景噪声；2）双流解码融合机制（DDFM），整合原始特征和注意力调制特征，以平衡空间精度与语义上下文；3）多尺度膨胀策略（膨胀率1, 3, 5, 9），减轻网格伪影并提高窄小道路预测的连续性。

Result: 在DeepGlobe和CHN6-CUG基准测试上，D3FNet在挑战性道路区域实现了卓越的IoU和召回率，优于现有的最先进基线模型。消融研究进一步验证了注意力引导编码和双路径解码的互补协同作用。

Conclusion: D3FNet被证实是复杂遥感和协同感知场景中细粒度窄小道路提取的稳健解决方案。

Abstract: Extracting narrow roads from high-resolution remote sensing imagery remains a
significant challenge due to their limited width, fragmented topology, and
frequent occlusions. To address these issues, we propose D3FNet, a Dilated
Dual-Stream Differential Attention Fusion Network designed for fine-grained
road structure segmentation in remote perception systems. Built upon the
encoder-decoder backbone of D-LinkNet, D3FNet introduces three key
innovations:(1) a Differential Attention Dilation Extraction (DADE) module that
enhances subtle road features while suppressing background noise at the
bottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates
original and attention-modulated features to balance spatial precision with
semantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9)
that mitigates gridding artifacts and improves continuity in narrow road
prediction. Unlike conventional models that overfit to generic road widths,
D3FNet specifically targets fine-grained, occluded, and low-contrast road
segments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show
that D3FNet achieves superior IoU and recall on challenging road regions,
outperforming state-of-the-art baselines. Ablation studies further verify the
complementary synergy of attention-guided encoding and dual-path decoding.
These results confirm D3FNet as a robust solution for fine-grained narrow road
extraction in complex remote and cooperative perception scenarios.

</details>


### [49] [Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment](https://arxiv.org/abs/2508.15568)
*Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong*

Main category: cs.CV

TL;DR: ADAPT是一种先进的、无需反向传播的测试时自适应方法，通过高斯概率推断和轻量级正则化来解决可扩展性和类别条件分布建模问题，在各种分布偏移下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管测试时自适应（TTA）取得了显著进展，但其广泛应用仍受限于：1）多数方法依赖反向传播或迭代优化，导致可扩展性差，难以实时部署；2）缺乏对类别条件特征分布的显式建模，这对于可靠的决策边界和校准预测至关重要，但由于缺乏源数据和测试时监督而未被充分探索。

Method: 我们提出了ADAPT（Advanced Distribution-Aware and backPropagation-free Test-time adaptation），将TTA重新定义为高斯概率推断任务。通过逐渐更新的类别均值和共享协方差矩阵来建模类别条件似然，实现了封闭形式、无需训练的推断。此外，引入由CLIP先验和历史知识库引导的轻量级正则化，以纠正潜在的似然偏差。ADAPT不需要源数据、梯度更新或完全访问目标数据，支持在线和转导设置。

Result: 在各种基准上的广泛实验表明，我们的方法在广泛的分布偏移下实现了最先进的性能，并具有卓越的可扩展性和鲁棒性。

Conclusion: ADAPT是一种无需反向传播且无需源数据的先进TTA方法，通过高斯概率推断和轻量级正则化有效解决了现有方法的局限性，实现了SOTA性能、高可扩展性和鲁棒性。

Abstract: Test-time adaptation (TTA) enhances the zero-shot robustness under
distribution shifts by leveraging unlabeled test data during inference. Despite
notable advances, several challenges still limit its broader applicability.
First, most methods rely on backpropagation or iterative optimization, which
limits scalability and hinders real-time deployment. Second, they lack explicit
modeling of class-conditional feature distributions. This modeling is crucial
for producing reliable decision boundaries and calibrated predictions, but it
remains underexplored due to the lack of both source data and supervision at
test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and
backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian
probabilistic inference task by modeling class-conditional likelihoods using
gradually updated class means and a shared covariance matrix. This enables
closed-form, training-free inference. To correct potential likelihood bias, we
introduce lightweight regularization guided by CLIP priors and a historical
knowledge bank. ADAPT requires no source data, no gradient updates, and no full
access to target data, supporting both online and transductive settings.
Extensive experiments across diverse benchmarks demonstrate that our method
achieves state-of-the-art performance under a wide range of distribution shifts
with superior scalability and robustness.

</details>


### [50] [High-Frequency First: A Two-Stage Approach for Improving Image INR](https://arxiv.org/abs/2508.15582)
*Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong*

Main category: cs.CV

TL;DR: 隐式神经表示（INR）在处理高频细节时存在谱偏差问题。本文提出了一种两阶段训练策略，通过邻居感知软掩码在早期训练中优先处理高频分量，从而提高了重建质量并减轻了谱偏差。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INR）存在谱偏差问题，倾向于低频分量，难以捕捉高频细节（如锐利边缘和精细纹理）。

Method: 提出了一种两阶段训练策略：首先，使用邻居感知软掩码自适应地为具有强局部变化的像素分配更高的权重，以鼓励早期关注精细细节；然后，模型过渡到全图像训练。

Result: 实验结果表明，该方法持续改善了重建质量，并补充了现有的INR方法。

Conclusion: 作为首次尝试在图像INR中为像素分配频率感知重要性的工作，本研究为减轻谱偏差问题提供了一条新途径。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful alternative
to traditional pixel-based formats by modeling images as continuous functions
over spatial coordinates. A key challenge, however, lies in the spectral bias
of neural networks, which tend to favor low-frequency components while
struggling to capture high-frequency (HF) details such as sharp edges and fine
textures. While prior approaches have addressed this limitation through
architectural modifications or specialized activation functions, we propose an
orthogonal direction by directly guiding the training process. Specifically, we
introduce a two-stage training strategy where a neighbor-aware soft mask
adaptively assigns higher weights to pixels with strong local variations,
encouraging early focus on fine details. The model then transitions to
full-image training. Experimental results show that our approach consistently
improves reconstruction quality and complements existing INR methods. As a
pioneering attempt to assign frequency-aware importance to pixels in image INR,
our work offers a new avenue for mitigating the spectral bias problem.

</details>


### [51] [Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis](https://arxiv.org/abs/2508.15613)
*Ivo Ivanov,Carsten Markgraf*

Main category: cs.CV

TL;DR: 提出了一种新的线性时间凸松弛方法和加速BnB的承包商方法，实现仅旋转TLS点云配准的全局最优性，速度比现有方法快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有使用截断最小二乘（TLS）的点云配准方法在面对高达95%的离群值率时虽然表现稳健，但求解全局最优解的计算成本高昂，例如SDP松弛法对100个点需要数百秒。

Method: 本文提出了一种新颖的线性时间凸松弛方法，并结合承包商方法（contractor method）来加速分支定界（Branch and Bound, BnB）算法。

Result: 当提供旋转轴时，该求解器可以在不到半秒的时间内实现100个点的两个3D点云的全局最优配准。在解决仅旋转的TLS问题时，其速度比最先进的SDP求解器STRIDE快两个数量级。

Conclusion: 本文为全局最优性提供了正式证明，并通过在接近全局最小值的局部最小值对抗性实例上进行实验，提供了全局最优性的经验证据，显著提升了特定点云配准问题的求解效率。

Abstract: Recent results showed that point cloud registration with given
correspondences can be made robust to outlier rates of up to 95\% using the
truncated least squares (TLS) formulation. However, solving this combinatorial
optimization problem to global optimality is challenging. Provably globally
optimal approaches using semidefinite programming (SDP) relaxations take
hundreds of seconds for 100 points. In this paper, we propose a novel linear
time convex relaxation as well as a contractor method to speed up Branch and
Bound (BnB). Our solver can register two 3D point clouds with 100 points to
provable global optimality in less than half a second when the axis of rotation
is provided. Although it currently cannot solve the full 6DoF problem, it is
two orders of magnitude faster than the state-of-the-art SDP solver STRIDE when
solving the rotation-only TLS problem. In addition to providing a formal proof
for global optimality, we present empirical evidence of global optimality using
adversarial instances with local minimas close to the global minimum.

</details>


### [52] [Multi-perspective monitoring of wildlife and human activities from camera traps and drones with deep learning models](https://arxiv.org/abs/2508.15629)
*Hao Chen,Fang Qiu,Li An,Douglas Stow,Eve Bohnett,Haitao Lyu,Shuang Tian*

Main category: cs.CV

TL;DR: 该研究通过结合相机陷阱和无人机图像，利用深度学习和空间模式分析，在奇特旺国家公园识别了野生动物和人类活动的热点区域及潜在冲突区，并提出了一种多视角集成监测方法以加强野生动物监测和景观管理。


<details>
  <summary>Details</summary>
Motivation: 理解野生动物和人类活动的空间分布对于评估人与野生动物的互动以及制定有效的保护计划至关重要，旨在识别它们的活动区域重叠并评估人与野生动物冲突的程度。

Method: 本研究结合了可见光和近红外相机陷阱以及热红外无人机图像进行多视角监测。利用深度学习模型（YOLOv11s用于相机陷阱图像，增强型Faster RCNN用于无人机热成像图像）自动识别野生动物和人类活动。随后进行空间模式分析以识别动物和居民活动热点及划定潜在的人与野生动物冲突区。

Result: YOLOv11s在相机陷阱图像检测中表现最佳（精确度96.2%，召回率92.3%，mAP50 96.7%）。无人机热成像图像提供了补充性的空中视角。空间模式分析识别出野生动物和人类活动的明显热点及其在奇特旺国家公园及其缓冲区内某些区域的重叠模式，表明存在潜在冲突。

Conclusion: 本研究揭示了保护区内的人与野生动物冲突。整合多视角监测与自动化目标检测技术，能够有效提升野生动物监测和景观管理水平。

Abstract: Wildlife and human activities are key components of landscape systems.
Understanding their spatial distribution is essential for evaluating human
wildlife interactions and informing effective conservation planning.
Multiperspective monitoring of wildlife and human activities by combining
camera traps and drone imagery. Capturing the spatial patterns of their
distributions, which allows the identification of the overlap of their activity
zones and the assessment of the degree of human wildlife conflict. The study
was conducted in Chitwan National Park (CNP), Nepal, and adjacent regions.
Images collected by visible and nearinfrared camera traps and thermal infrared
drones from February to July 2022 were processed to create training and testing
datasets, which were used to build deep learning models to automatic identify
wildlife and human activities. Drone collected thermal imagery was used for
detecting targets to provide a multiple monitoring perspective. Spatial pattern
analysis was performed to identify animal and resident activity hotspots and
delineation potential human wildlife conflict zones. Among the deep learning
models tested, YOLOv11s achieved the highest performance with a precision of
96.2%, recall of 92.3%, mAP50 of 96.7%, and mAP50 of 81.3%, making it the most
effective for detecting objects in camera trap imagery. Drone based thermal
imagery, analyzed with an enhanced Faster RCNN model, added a complementary
aerial viewpoint for camera trap detections. Spatial pattern analysis
identified clear hotspots for both wildlife and human activities and their
overlapping patterns within certain areas in the CNP and buffer zones
indicating potential conflict. This study reveals human wildlife conflicts
within the conserved landscape. Integrating multiperspective monitoring with
automated object detection enhances wildlife surveillance and landscape
management.

</details>


### [53] [When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](https://arxiv.org/abs/2508.15641)
*Pengcheng Fang,Yuxia Chen,Rui Guo*

Main category: cs.CV

TL;DR: Grounded VideoDiT通过新的编码器、接地表示和时间token，显著提升了视频LLM的时间感知和实体接地能力，并在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在时间感知上表现粗糙，难以精确识别事件发生时间和实体交互，且存在时间戳编码不明确、帧级特征弱、语言视觉对齐漂移等问题。

Method: 本文提出了Grounded VideoDiT，通过引入三项创新解决上述问题：1. 扩散时间潜在（DTL）编码器增强边界敏感性和时间一致性；2. 对象接地表示明确绑定查询实体到局部视觉证据；3. 混合token方案，包含离散时间token，提供明确的时间戳建模，实现细粒度时间推理。

Result: Grounded VideoDiT在Charades STA、NExT GQA和多个VideoQA基准测试中取得了最先进（SOTA）的结果。

Conclusion: Grounded VideoDiT通过其创新的设计，显著提升了视频理解中的时间感知和实体接地能力，解决了现有模型在这些方面的局限性。

Abstract: Understanding videos requires more than answering open ended questions, it
demands the ability to pinpoint when events occur and how entities interact
across time. While recent Video LLMs have achieved remarkable progress in
holistic reasoning, they remain coarse in temporal perception: timestamps are
encoded only implicitly, frame level features are weak in capturing continuity,
and language vision alignment often drifts from the entities of interest. In
this paper, we present Grounded VideoDiT, a Video LLM designed to overcome
these limitations by introducing three key innovations. First, a Diffusion
Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains
temporal consistency. Second, object grounded representations explicitly bind
query entities to localized visual evidence, strengthening alignment. Third, a
mixed token scheme with discrete temporal tokens provides explicit timestamp
modeling, enabling fine grained temporal reasoning. Together, these designs
equip Grounded VideoDiT with robust grounding capabilities, as validated by
state of the art results on Charades STA, NExT GQA, and multiple VideoQA
benchmarks.

</details>


### [54] [Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds](https://arxiv.org/abs/2508.15646)
*Swann Emilien Céleste Destouches,Jesse Lahaye,Laurent Valentin Jospin,Jan Skaloud*

Main category: cs.CV

TL;DR: 该研究提出了一种弱监督方法，通过人类操作员对初步分割结果进行质量评估来训练评分模型，并利用该模型反馈微调分割模型，从而显著提高航空激光扫描数据的树木实例分割精度，同时减少非树木实例的预测。


<details>
  <summary>Details</summary>
Motivation: 机载激光扫描（ALS）数据的树木实例分割对于森林监测至关重要，但由于数据变化和精确标记数据的高成本而面临挑战。

Method: 提出了一种弱监督方法。首先，人类操作员对非微调模型或封闭形式算法获得的初始分割结果进行质量评级。然后，利用这些评级数据训练一个评分模型。最后，根据评分模型的反馈对分割模型进行微调。

Result: 该方法将原始分割模型在正确识别树木实例方面的性能提高了34%，同时显著减少了非树木实例的预测数量。

Conclusion: 该方法在树木实例分割方面取得了显著改进，但在稀疏森林区域或包含灌木、巨石等复杂环境中，小型树木（小于两米）的数据处理仍面临挑战，性能有所下降。

Abstract: Tree instance segmentation of airborne laser scanning (ALS) data is of utmost
importance for forest monitoring, but remains challenging due to variations in
the data caused by factors such as sensor resolution, vegetation state at
acquisition time, terrain characteristics, etc. Moreover, obtaining a
sufficient amount of precisely labeled data to train fully supervised instance
segmentation methods is expensive. To address these challenges, we propose a
weakly supervised approach where labels of an initial segmentation result
obtained either by a non-finetuned model or a closed form algorithm are
provided as a quality rating by a human operator. The labels produced during
the quality assessment are then used to train a rating model, whose task is to
classify a segmentation output into the same classes as specified by the human
operator. Finally, the segmentation model is finetuned using feedback from the
rating model. This in turn improves the original segmentation model by 34\% in
terms of correctly identified tree instances while considerably reducing the
number of non-tree instances predicted. Challenges still remain in data over
sparsely forested regions characterized by small trees (less than two meters in
height) or within complex surroundings containing shrubs, boulders, etc. which
can be confused as trees where the performance of the proposed method is
reduced.

</details>


### [55] [Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance](https://arxiv.org/abs/2508.15650)
*Shuchao Pang,Zhenghan Chen,Shen Zhang,Liming Lu,Siyuan Liang,Anan Du,Yongbin Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CFG的迁移式黑盒攻击方法，旨在提高3D点云对抗样本的迁移性，通过破坏关键特征并确保不可感知性，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对3D点云深度神经网络的对抗性攻击通常需要目标模型的私有信息，这在实际应用中难以获得。本文旨在开发一种不依赖目标模型信息的迁移式黑盒攻击方法，其动机基于不同DNN架构中用于点云分类的关键特征具有一致性的观察。

Method: 本文提出了一种名为CFG（Critical Feature Guidance）的迁移式黑盒攻击方法。该方法通过计算提取特征的重要性来规范对抗性点云的搜索，优先破坏可能被不同架构采用的关键特征。此外，通过在损失函数中显式约束生成对抗性点云的最大偏差程度，以确保其不可感知性。

Result: 在ModelNet40和ScanObjectNN基准数据集上进行的广泛实验表明，所提出的CFG方法在性能上显著优于最先进的攻击方法。

Conclusion: CFG通过利用关键特征指导，提出了一种有效的迁移式黑盒攻击方法，在不获取目标模型信息的情况下，实现了对3D点云的高迁移性和不可感知性攻击。

Abstract: Deep neural networks for 3D point clouds have been demonstrated to be
vulnerable to adversarial examples. Previous 3D adversarial attack methods
often exploit certain information about the target models, such as model
parameters or outputs, to generate adversarial point clouds. However, in
realistic scenarios, it is challenging to obtain any information about the
target models under conditions of absolute security. Therefore, we focus on
transfer-based attacks, where generating adversarial point clouds does not
require any information about the target models. Based on our observation that
the critical features used for point cloud classification are consistent across
different DNN architectures, we propose CFG, a novel transfer-based black-box
attack method that improves the transferability of adversarial point clouds via
the proposed Critical Feature Guidance. Specifically, our method regularizes
the search of adversarial point clouds by computing the importance of the
extracted features, prioritizing the corruption of critical features that are
likely to be adopted by diverse architectures. Further, we explicitly constrain
the maximum deviation extent of the generated adversarial point clouds in the
loss function to ensure their imperceptibility. Extensive experiments conducted
on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the
proposed CFG outperforms the state-of-the-art attack methods by a large margin.

</details>


### [56] [MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction](https://arxiv.org/abs/2508.15653)
*Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu*

Main category: cs.CV

TL;DR: MapKD是一种多级跨模态知识蒸馏框架，采用教师-教练-学生范式，将知识从多模态模型转移到轻量级视觉中心学生模型，解决了现有在线高清地图构建方法的局限性，显著提高了学生模型的性能和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的在线高清地图构建方法依赖于过时的离线地图和多模态传感器套件，导致推理时产生不必要的计算开销。本文旨在解决这些局限性。

Method: 本文提出了MapKD，一个新颖的多级跨模态知识蒸馏框架，采用创新的教师-教练-学生（TCS）范式。该框架包括：1）一个带有SD/HD地图先验的相机-激光雷达融合模型作为教师；2）一个带有先验知识和模拟激光雷达的视觉中心教练模型，用于弥合跨模态知识转移的鸿沟；3）一个轻量级基于视觉的学生模型。此外，还引入了两种有针对性的知识蒸馏策略：Token-Guided 2D Patch Distillation（TGPD）用于鸟瞰图特征对齐，以及Masked Semantic Response Distillation（MSRD）用于语义学习指导。

Result: 在nuScenes数据集上进行的广泛实验表明，MapKD使学生模型的mIoU提高了+6.68，mAP提高了+10.94，同时加快了推理速度。

Conclusion: MapKD通过多级跨模态知识蒸馏和创新的TCS范式，有效地将知识从多模态模型转移到高效、低成本、以视觉为中心的学生模型，显著提高了学生模型的性能并加速了推理速度，解决了在线高清地图构建的现有挑战。

Abstract: Online HD map construction is a fundamental task in autonomous driving
systems, aiming to acquire semantic information of map elements around the ego
vehicle based on real-time sensor inputs. Recently, several approaches have
achieved promising results by incorporating offline priors such as SD maps and
HD maps or by fusing multi-modal data. However, these methods depend on stale
offline maps and multi-modal sensor suites, resulting in avoidable
computational overhead at inference. To address these limitations, we employ a
knowledge distillation strategy to transfer knowledge from multimodal models
with prior knowledge to an efficient, low-cost, and vision-centric student
model. Specifically, we propose MapKD, a novel multi-level cross-modal
knowledge distillation framework with an innovative Teacher-Coach-Student (TCS)
paradigm. This framework consists of: (1) a camera-LiDAR fusion model with
SD/HD map priors serving as the teacher; (2) a vision-centric coach model with
prior knowledge and simulated LiDAR to bridge the cross-modal knowledge
transfer gap; and (3) a lightweight vision-based student model. Additionally,
we introduce two targeted knowledge distillation strategies: Token-Guided 2D
Patch Distillation (TGPD) for bird's eye view feature alignment and Masked
Semantic Response Distillation (MSRD) for semantic learning guidance. Extensive
experiments on the challenging nuScenes dataset demonstrate that MapKD improves
the student model by +6.68 mIoU and +10.94 mAP while simultaneously
accelerating inference speed. The code is available
at:https://github.com/2004yan/MapKD2026.

</details>


### [57] [CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps](https://arxiv.org/abs/2508.15672)
*Franz Hanke,Antonia Bieringer,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: 本文提出了一种名为CM2LoD3的新方法，利用冲突图和纹理融合来自动化LoD3级详细建筑模型的重建，解决了传统手动建模的挑战，并实现了61%的精度。


<details>
  <summary>Details</summary>
Motivation: 详细的3D建筑模型对于城市规划、数字孪生和灾害管理至关重要，但传统上LoD3模型的生成需要手动建模，这使得大规模应用充满挑战。

Method: 提出了一种名为CM2LoD3的新方法，利用从光线到模型先验分析中获得的冲突图（CMs）来重建LoD3建筑模型。该方法专注于使用自主开发的语义冲突图生成器（SCMG）生成的合成CMs对真实世界CMs进行语义分割。此外，通过置信度分数将纹理模型的额外分割与CMs融合，以提高分割性能和3D重建精度。

Result: 实验结果表明，CM2LoD3方法在分割和重建建筑开口方面是有效的，通过对分割的建筑纹理进行不确定性感知融合，性能达到61%。

Conclusion: 这项研究促进了自动化LoD3模型重建的进步，为可扩展和高效的3D城市建模铺平了道路。

Abstract: Detailed 3D building models are crucial for urban planning, digital twins,
and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2
building models are widely available, they lack detailed facade elements
essential for advanced urban analysis. In contrast, LoD3 models address this
limitation by incorporating facade elements such as windows, doors, and
underpasses. However, their generation has traditionally required manual
modeling, making large-scale adoption challenging. In this contribution,
CM2LoD3, we present a novel method for reconstructing LoD3 building models
leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis.
Unlike previous works, we concentrate on semantically segmenting real-world CMs
with synthetically generated CMs from our developed Semantic Conflict Map
Generator (SCMG). We also observe that additional segmentation of textured
models can be fused with CMs using confidence scores to further increase
segmentation performance and thus increase 3D reconstruction accuracy.
Experimental results demonstrate the effectiveness of our CM2LoD3 method in
segmenting and reconstructing building openings, with the 61% performance with
uncertainty-aware fusion of segmented building textures. This research
contributes to the advancement of automated LoD3 model reconstruction, paving
the way for scalable and efficient 3D city modeling. Our project is available:
https://github.com/InFraHank/CM2LoD3

</details>


### [58] [LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions](https://arxiv.org/abs/2508.15688)
*Yongju Jia,Jiarui Ma,Xiangxian Li,Baiqiao Zhang,Xianhui Cao,Juan Liu,Yulong Bian*

Main category: cs.CV

TL;DR: MDPR通过多维知识库和动态提示路由解决VLM微调中的类别不平衡问题，在长尾基准上取得了SOTA结果，且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉-语言模型（VLMs）在类不平衡场景中微调时存在偏差，而现有方法忽略了VLMs预训练中固有的类不平衡，导致偏差累积。

Method: 本文提出了一个多维动态提示路由（MDPR）框架。MDPR构建了一个跨越五个视觉语义维度的综合知识库，并在微调过程中通过动态路由机制对齐全局视觉类、检索最佳提示并平衡细粒度语义，通过logits融合产生稳定预测。

Result: 在CIFAR-LT、ImageNet-LT和Places-LT等长尾基准测试中，MDPR取得了与当前SOTA方法相当的结果。消融研究证实了其语义库对尾部类别的有效性，并表明动态路由的计算开销极小。

Conclusion: MDPR是一种灵活高效的增强型VLM微调方法，适用于数据不平衡的情况。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
impressive capability in visual tasks, but their fine-tuning often suffers from
bias in class-imbalanced scene. Recent works have introduced large language
models (LLMs) to enhance VLM fine-tuning with supplementing semantic
information. However, they often overlook inherent class imbalance in VLMs'
pre-training, which may lead to bias accumulation in downstream tasks. To
address this problem, this paper proposes a Multi-dimensional Dynamic Prompt
Routing (MDPR) framework. MDPR constructs a comprehensive knowledge base for
classes, spanning five visual-semantic dimensions. During fine-tuning, the
dynamic routing mechanism aligns global visual classes, retrieves optimal
prompts, and balances fine-grained semantics, yielding stable predictions
through logits fusion. Extensive experiments on long-tailed benchmarks,
including CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves
comparable results with current SOTA methods. Ablation studies further confirm
the effectiveness of our semantic library for tail classes, and show that our
dynamic routing incurs minimal computational overhead, making MDPR a flexible
and efficient enhancement for VLM fine-tuning under data imbalance.

</details>


### [59] [StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding](https://arxiv.org/abs/2508.15717)
*Yanlai Yang,Zhuokai Zhao,Satya Narayan Shukla,Aashu Singh,Shlok Kumar Mishra,Lizhu Zhang,Mengye Ren*

Main category: cs.CV

TL;DR: StreamMem是一种针对流式视频理解的查询无关KV缓存记忆机制，它通过流式编码和注意力分数压缩KV缓存，以固定大小的内存高效处理长视频，并在长视频理解和流式QA任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在处理长视频时，其键值（KV）缓存会产生大量的内存和计算开销，而现有的视觉压缩方法不适用于长视频理解和多轮对话场景。

Method: 本文提出了StreamMem，一种用于流式视频理解的查询无关KV缓存记忆机制。它以流式方式编码新的视频帧，并利用视觉tokens和通用查询tokens之间的注意力分数来压缩KV缓存，同时保持固定大小的KV内存。

Result: 在三个长视频理解和两个流式视频问答基准测试中，StreamMem在查询无关KV缓存压缩方面达到了最先进的性能，并与查询感知压缩方法具有竞争力。

Conclusion: StreamMem通过查询无关的KV缓存压缩机制，有效地解决了内存受限的长视频处理问题，并取得了领先的结果。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
visual-language reasoning, but their ability to efficiently handle long videos
remains limited. Despite recent advances in long-context MLLMs, storing and
attending to the key-value (KV) cache for long visual contexts incurs
substantial memory and computational overhead. Existing visual compression
methods require either encoding the entire visual context before compression or
having access to the questions in advance, which is impractical for long video
understanding and multi-turn conversational settings. In this work, we propose
StreamMem, a query-agnostic KV cache memory mechanism for streaming video
understanding. Specifically, StreamMem encodes new video frames in a streaming
manner, compressing the KV cache using attention scores between visual tokens
and generic query tokens, while maintaining a fixed-size KV memory to enable
efficient question answering (QA) in memory-constrained, long-video scenarios.
Evaluation on three long video understanding and two streaming video question
answering benchmarks shows that StreamMem achieves state-of-the-art performance
in query-agnostic KV cache compression and is competitive with query-aware
compression approaches.

</details>


### [60] [WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception](https://arxiv.org/abs/2508.15720)
*Zhiheng Liu,Xueqing Deng,Shoufa Chen,Angtian Wang,Qiushan Guo,Mingfei Han,Zeyue Xue,Mengzhao Chen,Ping Luo,Linjie Yang*

Main category: cs.CV

TL;DR: WorldWeaver是一个长视频生成框架，通过联合建模RGB和感知条件，并利用深度线索构建记忆库，有效解决了长视频生成中的结构和时间一致性问题，显著减少了时间漂移并提升了视频质量。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在长序列中保持结构和时间一致性仍面临挑战，主要问题在于现有方法过度依赖RGB信号，导致物体结构和运动误差随时间积累。

Method: 本文提出了WorldWeaver框架，它在一个统一的长周期建模方案中联合建模RGB帧和感知条件。该框架通过联合预测感知条件和颜色信息、利用深度线索构建记忆库、以及采用分段噪声调度来训练预测组，从而增强时间一致性和运动动态，减少漂移并降低计算成本。

Result: 在基于扩散和整流流的模型上的大量实验表明，WorldWeaver有效减少了时间漂移，并显著提高了生成视频的保真度。

Conclusion: WorldWeaver框架通过其创新的联合建模和记忆机制，成功解决了长视频生成中的关键挑战，实现了更高质量和更具时间一致性的长视频生成。

Abstract: Generative video modeling has made significant strides, yet ensuring
structural and temporal consistency over long sequences remains a challenge.
Current methods predominantly rely on RGB signals, leading to accumulated
errors in object structure and motion over extended durations. To address these
issues, we introduce WorldWeaver, a robust framework for long video generation
that jointly models RGB frames and perceptual conditions within a unified
long-horizon modeling scheme. Our training framework offers three key
advantages. First, by jointly predicting perceptual conditions and color
information from a unified representation, it significantly enhances temporal
consistency and motion dynamics. Second, by leveraging depth cues, which we
observe to be more resistant to drift than RGB, we construct a memory bank that
preserves clearer contextual information, improving quality in long-horizon
video generation. Third, we employ segmented noise scheduling for training
prediction groups, which further mitigates drift and reduces computational
cost. Extensive experiments on both diffusion- and rectified flow-based models
demonstrate the effectiveness of WorldWeaver in reducing temporal drift and
improving the fidelity of generated videos.

</details>


### [61] [Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model](https://arxiv.org/abs/2508.15751)
*Xueyuan Li,Can Cui,Ruining Deng,Yucheng Tang,Quan Liu,Tianyuan Yao,Shunxing Bao,Naweed Chowdhury,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 本文提出了All-in-SAM模型，通过分子赋能学习和SAM适配器，改进了计算病理学中细粒度细胞分割和分类的性能，减少了标注工作量并提高了可及性。


<details>
  <summary>Details</summary>
Motivation: 通用的视觉基础模型在计算病理学中进行细粒度语义分割（例如识别特定的细胞亚型）时面临挑战。

Method: 本文提出了分子赋能的All-in-SAM模型，该模型采用全栈方法：1. 通过分子赋能学习让非专业标注员参与标注，减少对详细像素级标注的需求。2. 利用SAM适配器调整SAM模型以强调特定语义。3. 通过整合面向分子的纠正学习（MOCL）来提高分割精度。

Result: 在内部和公共数据集上的实验结果表明，即使在标注质量不同的情况下，All-in-SAM模型也能显著提高细胞分类性能。

Conclusion: 该方法不仅减少了标注员的工作量，还将精确生物医学图像分析的可及性扩展到资源有限的环境，从而推进了医学诊断和病理图像分析自动化。

Abstract: Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentation through two primary methods:
prompt-based zero-shot segmentation and the use of cell-specific SAM models for
direct segmentation. These approaches enable effective segmentation across a
range of nuclei and cells. However, general vision foundation models often face
challenges with fine-grained semantic segmentation, such as identifying
specific nuclei subtypes or particular cells. Approach: In this paper, we
propose the molecular-empowered All-in-SAM Model to advance computational
pathology by leveraging the capabilities of vision foundation models. This
model incorporates a full-stack approach, focusing on: (1) annotation-engaging
lay annotators through molecular-empowered learning to reduce the need for
detailed pixel-level annotations, (2) learning-adapting the SAM model to
emphasize specific semantics, which utilizes its strong generalizability with
SAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating
Molecular-Oriented Corrective Learning (MOCL). Results: Experimental results
from both in-house and public datasets show that the All-in-SAM model
significantly improves cell classification performance, even when faced with
varying annotation quality. Conclusions: Our approach not only reduces the
workload for annotators but also extends the accessibility of precise
biomedical image analysis to resource-limited settings, thereby advancing
medical diagnostics and automating pathology image analysis.

</details>


### [62] [Waver: Wave Your Way to Lifelike Video Generation](https://arxiv.org/abs/2508.15761)
*Yifu Zhang,Hao Yang,Yuqi Zhang,Yifei Hu,Fengda Zhu,Chuang Lin,Xiaofeng Mei,Yi Jiang,Zehuan Yuan,Bingyue Peng*

Main category: cs.CV

TL;DR: Waver是一个高性能的统一图像和视频生成基础模型，能够生成高质量、高分辨率的视频，并在多项任务上达到最先进水平，同时支持文本到视频、图像到视频和文本到图像生成。


<details>
  <summary>Details</summary>
Motivation: 开发一个高性能的统一图像和视频生成基础模型，以生成更长、更高分辨率的视频，并在一套框架内整合文本到视频、图像到视频和文本到图像等多种生成任务，从而加速视频生成技术的发展。

Method: 提出了Waver模型，采用混合流DiT架构增强模态对齐和加速训练收敛。建立了全面的数据整理流程，并手动标注和训练了一个基于MLLM的视频质量模型来筛选高质量样本。提供了详细的训练和推理方案。

Result: Waver能够直接生成5到10秒的720p视频并上采样至1080p。在一个集成框架内支持文本到视频、图像到视频和文本到图像生成。在捕获复杂运动、运动幅度和时间一致性方面表现出色。在Artificial Analysis的T2V和I2V排行榜上排名前三（截至2025年7月30日），性能超越现有开源模型并与最先进的商业解决方案相当或更优。

Conclusion: Waver是一个高性能的统一图像和视频生成基础模型，能够生成高质量、高分辨率的视频，并在多项任务上达到最先进水平，有望帮助社区更有效地训练高质量视频生成模型，加速视频生成技术的发展。

Abstract: We present Waver, a high-performance foundation model for unified image and
video generation. Waver can directly generate videos with durations ranging
from 5 to 10 seconds at a native resolution of 720p, which are subsequently
upscaled to 1080p. The model simultaneously supports text-to-video (T2V),
image-to-video (I2V), and text-to-image (T2I) generation within a single,
integrated framework. We introduce a Hybrid Stream DiT architecture to enhance
modality alignment and accelerate training convergence. To ensure training data
quality, we establish a comprehensive data curation pipeline and manually
annotate and train an MLLM-based video quality model to filter for the
highest-quality samples. Furthermore, we provide detailed training and
inference recipes to facilitate the generation of high-quality videos. Building
on these contributions, Waver excels at capturing complex motion, achieving
superior motion amplitude and temporal consistency in video synthesis. Notably,
it ranks among the Top 3 on both the T2V and I2V leaderboards at Artificial
Analysis (data as of 2025-07-30 10:00 GMT+8), consistently outperforming
existing open-source models and matching or surpassing state-of-the-art
commercial solutions. We hope this technical report will help the community
more efficiently train high-quality video generation models and accelerate
progress in video generation technologies. Official page:
https://github.com/FoundationVision/Waver.

</details>


### [63] [ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling](https://arxiv.org/abs/2508.15767)
*Jinhyung Park,Javier Romero,Shunsuke Saito,Fabian Prada,Takaaki Shiratori,Yichen Xu,Federica Bogo,Shoou-I Yu,Kris Kitani,Rawal Khirodkar*

Main category: cs.CV

TL;DR: ATLAS通过解耦骨骼和形状，从大量高分辨率扫描中学习，创建了一个更精确、更具表现力的人体模型。


<details>
  <summary>Details</summary>
Motivation: 现有的人体网格建模方法难以捕捉不同姿势和形状的详细变化，因为训练数据多样性有限且建模假设具有限制性。此外，将内部骨骼和外部软组织联系起来的常见范式限制了对身高和骨长的直接控制。

Method: 我们提出了ATLAS，这是一个高保真人体模型，通过使用240个同步摄像头捕获的60万高分辨率扫描学习。ATLAS明确地将形状和骨骼基础解耦，并将网格表示植根于人体骨骼。

Result: ATLAS在拟合不同姿势的未见过的主题方面优于现有方法，并且量化评估表明，与线性模型相比，我们的非线性姿势校正器能更有效地捕捉复杂姿势。

Conclusion: ATLAS通过解耦形状和骨骼基础，并利用大量高分辨率数据，实现了比现有方法更准确、更富有表现力的人体建模，尤其在捕捉复杂姿势方面表现更优。

Abstract: Parametric body models offer expressive 3D representation of humans across a
wide range of poses, shapes, and facial expressions, typically derived by
learning a basis over registered 3D meshes. However, existing human mesh
modeling approaches struggle to capture detailed variations across diverse body
poses and shapes, largely due to limited training data diversity and
restrictive modeling assumptions. Moreover, the common paradigm first optimizes
the external body surface using a linear basis, then regresses internal
skeletal joints from surface vertices. This approach introduces problematic
dependencies between internal skeleton and outer soft tissue, limiting direct
control over body height and bone lengths. To address these issues, we present
ATLAS, a high-fidelity body model learned from 600k high-resolution scans
captured using 240 synchronized cameras. Unlike previous methods, we explicitly
decouple the shape and skeleton bases by grounding our mesh representation in
the human skeleton. This decoupling enables enhanced shape expressivity,
fine-grained customization of body attributes, and keypoint fitting independent
of external soft-tissue characteristics. ATLAS outperforms existing methods by
fitting unseen subjects in diverse poses more accurately, and quantitative
evaluations show that our non-linear pose correctives more effectively capture
complex poses compared to linear models.

</details>


### [64] [SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass](https://arxiv.org/abs/2508.15769)
*Yanxu Meng,Haoning Wu,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: SceneGen是一个新颖的框架，可以从单张场景图像（带物体掩码）同时生成多个带几何和纹理的3D资产，无需优化或资产检索，并可扩展到多图像输入。


<details>
  <summary>Details</summary>
Motivation: 3D内容生成在VR/AR和具身AI中具有重要应用，但从单一场景图像合成多个3D资产是一个具有挑战性的任务。

Method: 本文提出了SceneGen框架，以场景图像和对应物体掩码为输入，同步生成具有几何和纹理的多个3D资产。它无需优化或资产检索，并引入了一个新颖的特征聚合模块，结合视觉和几何编码器中的局部和全局场景信息，并通过位置头在一次前向传播中生成3D资产及其相对空间位置。SceneGen还可直接扩展到多图像输入场景。

Result: 广泛的定量和定性评估证实了该方法的效率和强大的生成能力。

Conclusion: SceneGen范式为高质量3D内容生成提供了一种新颖的解决方案，有望推动其在下游任务中的实际应用。

Abstract: 3D content generation has recently attracted significant research interest
due to its applications in VR/AR and embodied AI. In this work, we address the
challenging task of synthesizing multiple 3D assets within a single scene
image. Concretely, our contributions are fourfold: (i) we present SceneGen, a
novel framework that takes a scene image and corresponding object masks as
input, simultaneously producing multiple 3D assets with geometry and texture.
Notably, SceneGen operates with no need for optimization or asset retrieval;
(ii) we introduce a novel feature aggregation module that integrates local and
global scene information from visual and geometric encoders within the feature
extraction module. Coupled with a position head, this enables the generation of
3D assets and their relative spatial positions in a single feedforward pass;
(iii) we demonstrate SceneGen's direct extensibility to multi-image input
scenarios. Despite being trained solely on single-image inputs, our
architectural design enables improved generation performance with multi-image
inputs; and (iv) extensive quantitative and qualitative evaluations confirm the
efficiency and robust generation abilities of our approach. We believe this
paradigm offers a novel solution for high-quality 3D content generation,
potentially advancing its practical applications in downstream tasks. The code
and model will be publicly available at: https://mengmouxu.github.io/SceneGen.

</details>


### [65] [Visual Autoregressive Modeling for Instruction-Guided Image Editing](https://arxiv.org/abs/2508.15772)
*Qingyang Mao,Qi Cai,Yehao Li,Yingwei Pan,Mingyue Cheng,Ting Yao,Qi Liu,Tao Mei*

Main category: cs.CV

TL;DR: VAREdit是一个新的视觉自回归图像编辑框架，通过将图像编辑重构为下一尺度预测问题，解决了扩散模型在指令引导图像编辑中的局限性，实现了更高的编辑依从性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在指令引导图像编辑中存在局限性，即全局去噪过程会将编辑区域与整个图像上下文纠缠在一起，导致意外的修改和对编辑指令依从性下降。

Method: 本文提出了VAREdit，一个视觉自回归（VAR）框架，将图像编辑重构为下一尺度预测问题。它以源图像特征和文本指令为条件，生成多尺度目标特征以实现精确编辑。核心挑战是如何有效条件化源图像token，为此引入了一个尺度对齐参考（SAR）模块，将尺度匹配的条件信息注入到第一个自注意力层。

Result: VAREdit在编辑依从性和效率方面取得了显著进步。在标准基准测试中，它比领先的基于扩散的方法高出30%以上的GPT-Balance分数。此外，它在1.2秒内完成一个512x512的编辑，比同等大小的UltraEdit快2.2倍。

Conclusion: VAREdit是一个有效的视觉自回归框架，通过引入SAR模块，成功地将图像编辑重构为下一尺度预测问题，显著提高了图像编辑的依从性和效率，克服了扩散模型的缺点。

Abstract: Recent advances in diffusion models have brought remarkable visual fidelity
to instruction-guided image editing. However, their global denoising process
inherently entangles the edited region with the entire image context, leading
to unintended spurious modifications and compromised adherence to editing
instructions. In contrast, autoregressive models offer a distinct paradigm by
formulating image synthesis as a sequential process over discrete visual
tokens. Their causal and compositional mechanism naturally circumvents the
adherence challenges of diffusion-based methods. In this paper, we present
VAREdit, a visual autoregressive (VAR) framework that reframes image editing as
a next-scale prediction problem. Conditioned on source image features and text
instructions, VAREdit generates multi-scale target features to achieve precise
edits. A core challenge in this paradigm is how to effectively condition the
source image tokens. We observe that finest-scale source features cannot
effectively guide the prediction of coarser target features. To bridge this
gap, we introduce a Scale-Aligned Reference (SAR) module, which injects
scale-matched conditioning information into the first self-attention layer.
VAREdit demonstrates significant advancements in both editing adherence and
efficiency. On standard benchmarks, it outperforms leading diffusion-based
methods by 30\%+ higher GPT-Balance score. Moreover, it completes a
$512\times512$ editing in 1.2 seconds, making it 2.2$\times$ faster than the
similarly sized UltraEdit. The models are available at
https://github.com/HiDream-ai/VAREdit.

</details>


### [66] [Scaling Group Inference for Diverse and High-Quality Generation](https://arxiv.org/abs/2508.15773)
*Gaurav Parmar,Or Patashnik,Daniil Ostashev,Kuan-Chieh Wang,Kfir Aberman,Srinivasa Narasimhan,Jun-Yan Zhu*

Main category: cs.CV

TL;DR: 提出一种可扩展的群组推理方法，将生成模型的多个输出作为内聚的群组处理，以显著提高多样性和质量，解决独立采样导致的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型通常独立采样输出，但这往往导致结果冗余，限制了用户选择和想法探索。

Method: 提出一种可扩展的群组推理方法。将群组推理表述为二次整数分配问题，通过将候选输出建模为图节点，选择一个子集来优化样本质量（一元项）同时最大化群组多样性（二元项）。为提高运行时效率，通过中间预测逐步修剪候选集。

Result: 大量实验表明，该方法与独立采样基线和最新推理算法相比，显著提高了群组的多样性和质量。

Conclusion: 该框架可推广到文本到图像、图像到图像、图像提示和视频生成等多种任务，使生成模型能够将多个输出视为内聚的群组而非独立样本。

Abstract: Generative models typically sample outputs independently, and recent
inference-time guidance and scaling algorithms focus on improving the quality
of individual samples. However, in real-world applications, users are often
presented with a set of multiple images (e.g., 4-8) for each prompt, where
independent sampling tends to lead to redundant results, limiting user choices
and hindering idea exploration. In this work, we introduce a scalable group
inference method that improves both the diversity and quality of a group of
samples. We formulate group inference as a quadratic integer assignment
problem: candidate outputs are modeled as graph nodes, and a subset is selected
to optimize sample quality (unary term) while maximizing group diversity
(binary term). To substantially improve runtime efficiency, we progressively
prune the candidate set using intermediate predictions, allowing our method to
scale up to large candidate sets. Extensive experiments show that our method
significantly improves group diversity and quality compared to independent
sampling baselines and recent inference algorithms. Our framework generalizes
across a wide range of tasks, including text-to-image, image-to-image, image
prompting, and video generation, enabling generative models to treat multiple
outputs as cohesive groups rather than independent samples.

</details>


### [67] [CineScale: Free Lunch in High-Resolution Cinematic Visual Generation](https://arxiv.org/abs/2508.15774)
*Haonan Qiu,Ning Yu,Ziqi Huang,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: CineScale是一种新的推理范式，可以实现高分辨率图像和视频生成，解决了现有扩散模型在高分辨率下生成质量差和重复模式的问题，无需微调即可生成8k图像，仅需少量LoRA微调即可生成4k视频。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉扩散模型由于缺乏高分辨率数据和计算资源限制，通常在有限分辨率下进行训练，从而在高分辨率图像或视频生成时无法达到高保真度。最近的无调优策略在高分辨率视觉生成中容易产生低质量和重复模式的内容，主要原因是模型在超出训练分辨率生成视觉内容时高频信息不可避免地增加，导致累积误差产生不希望的重复模式。

Method: 我们提出了CineScale，一种新颖的推理范式，以实现更高分辨率的视觉生成。为了解决两种视频生成架构引入的各种问题，我们提出了针对每种架构的专用变体。与局限于高分辨率T2I和T2V生成的现有基线方法不同，CineScale扩展了范围，支持高分辨率I2V和V2V合成，并构建在最先进的开源视频生成框架之上。

Result: 广泛的实验验证了我们的范式在扩展图像和视频模型高分辨率视觉生成能力方面的优越性。值得注意的是，我们的方法无需任何微调即可实现8k图像生成，并且只需极少的LoRA微调即可实现4k视频生成。

Conclusion: CineScale作为一种新颖的推理范式，有效地解决了现有视觉扩散模型在高分辨率生成中的限制，通过专用变体和扩展的合成范围，无需或只需极少微调即可实现高质量的8k图像和4k视频生成。

Abstract: Visual diffusion models achieve remarkable progress, yet they are typically
trained at limited resolutions due to the lack of high-resolution data and
constrained computation resources, hampering their ability to generate
high-fidelity images or videos at higher resolutions. Recent efforts have
explored tuning-free strategies to exhibit the untapped potential
higher-resolution visual generation of pre-trained models. However, these
methods are still prone to producing low-quality visual content with repetitive
patterns. The key obstacle lies in the inevitable increase in high-frequency
information when the model generates visual content exceeding its training
resolution, leading to undesirable repetitive patterns deriving from the
accumulated errors. In this work, we propose CineScale, a novel inference
paradigm to enable higher-resolution visual generation. To tackle the various
issues introduced by the two types of video generation architectures, we
propose dedicated variants tailored to each. Unlike existing baseline methods
that are confined to high-resolution T2I and T2V generation, CineScale broadens
the scope by enabling high-resolution I2V and V2V synthesis, built atop
state-of-the-art open-source video generation frameworks. Extensive experiments
validate the superiority of our paradigm in extending the capabilities of
higher-resolution visual generation for both image and video models.
Remarkably, our approach enables 8k image generation without any fine-tuning,
and achieves 4k video generation with only minimal LoRA fine-tuning. Generated
video samples are available at our website:
https://eyeline-labs.github.io/CineScale/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [68] [Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training](https://arxiv.org/abs/2508.14904)
*Jianfeng Si,Lin Sun,Zhewen Tan,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种统一的协同训练框架，通过在单SFT阶段集成多种安全行为并使用“魔法令牌”动态激活，解决了LLM内容安全中现有方法的局限性。这种方法在安全对齐质量上与SFT+DPO相当，并显著降低了训练复杂性和部署成本。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM内容安全方法（如SFT和RLHF）存在多阶段训练流程复杂和部署后缺乏细粒度控制的局限性。

Method: 提出了一种统一的协同训练框架，该框架在单一SFT阶段有效整合了多种安全行为（积极、消极、拒绝性），并通过简单的系统级指令（“魔法令牌”）在推理时动态激活，实现行为的灵活切换。

Result: 该方法在安全对齐质量上与SFT+DPO相当，其8B模型在安全性能上超越了DeepSeek-R1（671B），同时显著降低了训练复杂性和部署成本。它还在输出空间中诱导了一个独特的安全对齐边界，表现出良好分离的响应分布。

Conclusion: 该工作为LLM内容安全提供了一个可扩展、高效且高度可控的解决方案。

Abstract: Current methods for content safety in Large Language Models (LLMs), such as
Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback
(RLHF), often rely on multi-stage training pipelines and lack fine-grained,
post-deployment controllability. To address these limitations, we propose a
unified co-training framework that efficiently integrates multiple safety
behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and
rejective (refusal-oriented/conservative) within a single SFT stage. Notably,
each behavior is dynamically activated via a simple system-level instruction,
or magic token, enabling stealthy and efficient behavioral switching at
inference time. This flexibility supports diverse deployment scenarios, such as
positive for safe user interaction, negative for internal red-teaming, and
rejective for context-aware refusals triggered by upstream moderation signals.
This co-training strategy induces a distinct Safety Alignment Margin in the
output space, characterized by well-separated response distributions
corresponding to each safety mode. The existence of this margin provides
empirical evidence for the model's safety robustness and enables unprecedented
fine-grained control. Experiments show that our method matches the safety
alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1
(671B) in safety performance, while significantly reducing both training
complexity and deployment costs. This work presents a scalable, efficient, and
highly controllable solution for LLM content safety.

</details>


### [69] [Preliminary Ranking of WMT25 General Machine Translation Systems](https://arxiv.org/abs/2508.14909)
*Tom Kocmi,Eleftherios Avramidis,Rachel Bawden,Ondřej Bojar,Konstantin Dranch,Anton Dvorkovich,Sergey Dukanov,Natalia Fedorova,Mark Fishel,Markus Freitag,Thamme Gowda,Roman Grundkiewicz,Barry Haddow,Marzena Karpinska,Philipp Koehn,Howard Lakougna,Jessica Lundin,Kenton Murray,Masaaki Nagata,Stefano Perrella,Lorenzo Proietti,Martin Popel,Maja Popović,Parker Riley,Mariya Shmatova,Steinþór Steingrímsson,Lisa Yankovskaya,Vilém Zouhar*

Main category: cs.CL

TL;DR: WMT25通用机器翻译共享任务的初步排名，基于自动评估，供参与者参考，最终排名将是人工评估。


<details>
  <summary>Details</summary>
Motivation: 分享初步结果给任务参与者，以便他们准备系统提交论文。

Method: 使用自动度量评估机器翻译系统。

Result: WMT25通用机器翻译共享任务的初步排名，该排名基于自动评估。

Conclusion: 本文介绍了WMT25通用机器翻译共享任务的初步排名，该排名基于自动评估，可能存在偏差。最终排名将基于更可靠的人工评估。

Abstract: We present the preliminary ranking of the WMT25 General Machine Translation
Shared Task, in which MT systems have been evaluated using automatic metrics.
As this ranking is based on automatic evaluations, it may be biased in favor of
systems that employ re-ranking techniques, such as Quality Estimation
re-ranking or Minimum Bayes Risk decoding. The official WMT25 ranking will be
based on human evaluation, which is more reliable and will supersede the
automatic ranking.
  The purpose of this report is not to present the final findings of the
General MT task, but rather to share preliminary results with task
participants, which may be useful when preparing their system submission
papers.

</details>


### [70] [Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages](https://arxiv.org/abs/2508.14913)
*Israel Abebe Azime,Tadesse Destaw Belay,Dietrich Klakow,Philipp Slusallek,Anshuman Chhabra*

Main category: cs.CL

TL;DR: LLMs在低资源语言中的多语言数学推理受限于缺乏文化本地化数据集。本文提出了一个LLM驱动的框架，自动生成包含本地实体的数学应用题数据集，以减轻英语中心偏差，提高多语言数学能力评估的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏反映准确本地实体（如人名、组织名和货币）的社会文化任务数据集，低资源语言中的多语言和文化背景数学推理落后于英语。现有的多语言基准测试主要通过翻译产生，并保留了以英语为中心的实体，真正的本地化数据集稀缺。

Method: 引入了一个由大型语言模型驱动的数学应用题文化本地化框架，该框架能自动从现有资源中构建包含本地名称、组织和货币的数据集。

Result: 翻译的基准测试可能会掩盖在适当社会文化背景下的真实多语言数学能力。该框架有助于减轻以英语为中心的实体偏差，并在引入各种语言的本地实体时提高了鲁棒性。

Conclusion: 该框架成功构建了文化本地化的数学应用题数据集，提高了多语言数学推理能力评估的准确性和鲁棒性，弥补了现有数据集的不足。

Abstract: Large language models (LLMs) have demonstrated significant capabilities in
solving mathematical problems expressed in natural language. However,
multilingual and culturally-grounded mathematical reasoning in low-resource
languages lags behind English due to the scarcity of socio-cultural task
datasets that reflect accurate native entities such as person names,
organization names, and currencies. Existing multilingual benchmarks are
predominantly produced via translation and typically retain English-centric
entities, owing to the high cost associated with human annotater-based
localization. Moreover, automated localization tools are limited, and hence,
truly localized datasets remain scarce. To bridge this gap, we introduce a
framework for LLM-driven cultural localization of math word problems that
automatically constructs datasets with native names, organizations, and
currencies from existing sources. We find that translated benchmarks can
obscure true multilingual math ability under appropriate socio-cultural
contexts. Through extensive experiments, we also show that our framework can
help mitigate English-centric entity bias and improves robustness when native
entities are introduced across various languages.

</details>


### [71] [Improving LLMs for Machine Translation Using Synthetic Preference Data](https://arxiv.org/abs/2508.14951)
*Dario Vajda,Domen Vreš,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 本文研究了如何使用DPO训练和少量程序化生成的数据，有效提升通用指令微调大模型在机器翻译（以斯洛文尼亚语为例）上的表现，超过基线模型并减少错误。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在机器翻译方面表现出色，但本文旨在探索如何利用相对较少且易于生成的数据资源，改进通用的指令微调大型语言模型在机器翻译方面的性能。

Method: 研究人员以斯洛文尼亚语为例，使用直接偏好优化（DPO）训练改进了GaMS-9B-Instruct模型。DPO的训练数据集是通过使用GaMS-9B-Instruct和EuroLLM-9B-Instruct两个LLM翻译英文维基百科文章，并结合启发式方法和COMET等自动评估指标对翻译结果进行质量排序而生成的。

Result: 经过微调的模型在翻译维基百科文章时，COMET分数比参与数据集生成的两个基线模型分别提高了约0.04和0.02。此外，微调模型更稳定地避免了语言和格式错误。

Conclusion: 通过使用直接偏好优化（DPO）训练和程序化策划的少量数据资源，可以有效提升通用指令微调大型语言模型在机器翻译任务上的性能，使其超越基线模型并显著减少错误。

Abstract: Large language models have emerged as effective machine translation systems.
In this paper, we explore how a general instruction-tuned large language model
can be improved for machine translation using relatively few easily produced
data resources. Using Slovene as a use case, we improve the GaMS-9B-Instruct
model using Direct Preference Optimization (DPO) training on a programmatically
curated and enhanced subset of a public dataset. As DPO requires pairs of
quality-ranked instances, we generated its training dataset by translating
English Wikipedia articles using two LLMs, GaMS-9B-Instruct and
EuroLLM-9B-Instruct. We ranked the resulting translations based on heuristics
coupled with automatic evaluation metrics such as COMET. The evaluation shows
that our fine-tuned model outperforms both models involved in the dataset
generation. In comparison to the baseline models, the fine-tuned model achieved
a COMET score gain of around 0.04 and 0.02, respectively, on translating
Wikipedia articles. It also more consistently avoids language and formatting
errors.

</details>


### [72] [Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems](https://arxiv.org/abs/2508.14982)
*Qianli Wang,Tatiana Anikina,Nils Feldhus,Simon Ostermann,Fedor Splitt,Jiaao Li,Yoana Tsoneva,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 针对多语言会话式可解释人工智能（ConvXAI）系统中训练数据稀缺和自定义输入支持受限的问题，本文提出了MultiCoXQL和Compass两个新的多语言数据集，并引入了一种新的解析方法，对多个大型语言模型（LLMs）和BERT类模型进行了广泛的单语、跨语言和多语言评估。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLMs）的会话式可解释人工智能（ConvXAI）系统在多语言泛化方面面临训练数据稀缺的挑战，且对自由格式的自定义输入支持有限。

Method: 本文首先引入了MultiCoXQL，一个CoXQL数据集的多语言扩展，涵盖五种不同语系的语言。随后，提出了一种新的解析方法以提升多语言解析性能，并评估了三种LLM在MultiCoXQL上使用不同解析策略的表现。此外，还提出了Compass，一个用于ConvXAI系统中自定义输入提取的多语言数据集，包含11种意图，涵盖与MultiCoXQL相同的五种语言。对Compass进行了单语、跨语言和多语言评估，使用了三种不同规模的LLM以及BERT类模型。

Result: 通过在MultiCoXQL数据集上使用多种解析策略评估了三种LLMs的性能。在Compass数据集上，对三种不同规模的LLM和BERT类模型进行了单语、跨语言和多语言评估，以验证其在自定义输入提取方面的能力。

Conclusion: 本文通过引入MultiCoXQL和Compass两个多语言数据集，并提出新的解析方法，有效弥补了ConvXAI系统在多语言泛化能力和自由格式自定义输入支持方面的空白。

Abstract: Conversational explainable artificial intelligence (ConvXAI) systems based on
large language models (LLMs) have garnered considerable attention for their
ability to enhance user comprehension through dialogue-based explanations.
Current ConvXAI systems often are based on intent recognition to accurately
identify the user's desired intention and map it to an explainability method.
While such methods offer great precision and reliability in discerning users'
underlying intentions for English, a significant challenge in the scarcity of
training data persists, which impedes multilingual generalization. Besides, the
support for free-form custom inputs, which are user-defined data distinct from
pre-configured dataset instances, remains largely limited. To bridge these
gaps, we first introduce MultiCoXQL, a multilingual extension of the CoXQL
dataset spanning five typologically diverse languages, including one
low-resource language. Subsequently, we propose a new parsing approach aimed at
enhancing multilingual parsing performance, and evaluate three LLMs on
MultiCoXQL using various parsing strategies. Furthermore, we present Compass, a
new multilingual dataset designed for custom input extraction in ConvXAI
systems, encompassing 11 intents across the same five languages as MultiCoXQL.
We conduct monolingual, cross-lingual, and multilingual evaluations on Compass,
employing three LLMs of varying sizes alongside BERT-type models.

</details>


### [73] [Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner](https://arxiv.org/abs/2508.15044)
*Bolian Li,Yanran Wu,Xinyu Luo,Ruqi Zhang*

Main category: cs.CL

TL;DR: 提出一种名为奖励漂移推测采样（SSS）的新算法，通过对齐草稿模型并利用分布差异，以显著降低的推理成本在测试时对齐中获得优异的性能。


<details>
  <summary>Details</summary>
Motivation: 当前测试时对齐（test-time alignment）技术推理成本高昂，限制了其实际应用。受推测采样（speculative sampling）加速方法的启发，旨在解决测试时对齐的效率瓶颈。

Method: 提出奖励漂移推测采样（reward-Shifted Speculative Sampling, SSS）算法，其中草稿模型与人类偏好对齐，而目标模型保持不变。通过修改接受标准和奖励token分布，利用对齐草稿模型与未对齐目标模型之间的分布差异来恢复RLHF最优解。

Result: 在测试时弱到强对齐实验中，算法以显著降低的推理成本实现了卓越的黄金奖励分数。

Conclusion: 该算法在测试时对齐方面既有效又高效。

Abstract: Aligning large language models (LLMs) with human preferences has become a
critical step in their development. Recent research has increasingly focused on
test-time alignment, where additional compute is allocated during inference to
enhance LLM safety and reasoning capabilities. However, these test-time
alignment techniques often incur substantial inference costs, limiting their
practical application. We are inspired by the speculative sampling
acceleration, which leverages a small draft model to efficiently predict future
tokens, to address the efficiency bottleneck of test-time alignment. We
introduce the reward-Shifted Speculative Sampling (SSS) algorithm, in which the
draft model is aligned with human preferences, while the target model remains
unchanged. We theoretically demonstrate that the distributional shift between
the aligned draft model and the unaligned target model can be exploited to
recover the RLHF optimal solution without actually obtaining it, by modifying
the acceptance criterion and bonus token distribution. Our algorithm achieves
superior gold reward scores at a significantly reduced inference cost in
test-time weak-to-strong alignment experiments, thereby validating both its
effectiveness and efficiency.

</details>


### [74] [LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text](https://arxiv.org/abs/2508.15085)
*MohamamdJavad Ardestani,Ehsan Kamalloo,Davood Rafiei*

Main category: cs.CL

TL;DR: LongRecall是一个三阶段的召回评估框架，通过事实分解、筛选和结构化蕴含检查来克服现有召回指标的局限性，在长篇问答基准测试中显示出显着更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 在医学和法律等领域以及基于列表的问答任务中，机器生成文本的完整性至关重要，因为遗漏可能会导致严重后果。然而，现有的召回指标依赖于词汇重叠，容易出现错误，而LLM-as-a-Judge方法在没有结构化验证的情况下容易出现错位和幻觉。

Method: 我们引入了LongRecall，一个通用的三阶段召回评估框架。它将答案分解为独立的“事实”，通过词汇和语义过滤逐步缩小可能的候选匹配，并通过结构化蕴含检查来验证其对齐。

Result: 我们在三个具有挑战性的长篇问答基准上评估了LongRecall，使用人工标注和基于LLM的评估器，结果表明其召回准确性比强大的词汇和LLM-as-a-Judge基线有显著提高。

Conclusion: 这种设计减少了假阳性和假阴性，同时适应了不同的措辞和上下文变体，为系统性召回评估奠定了基础。

Abstract: LongRecall. The completeness of machine-generated text, ensuring that it
captures all relevant information, is crucial in domains such as medicine and
law and in tasks like list-based question answering (QA), where omissions can
have serious consequences. However, existing recall metrics often depend on
lexical overlap, leading to errors with unsubstantiated entities and
paraphrased answers, while LLM-as-a-Judge methods with long holistic prompts
capture broader semantics but remain prone to misalignment and hallucinations
without structured verification. We introduce LongRecall, a general three-stage
recall evaluation framework that decomposes answers into self-contained facts,
successively narrows plausible candidate matches through lexical and semantic
filtering, and verifies their alignment through structured entailment checks.
This design reduces false positives and false negatives while accommodating
diverse phrasings and contextual variations, serving as a foundational building
block for systematic recall assessment. We evaluate LongRecall on three
challenging long-form QA benchmarks using both human annotations and LLM-based
judges, demonstrating substantial improvements in recall accuracy over strong
lexical and LLM-as-a-Judge baselines.

</details>


### [75] [Mapping the Course for Prompt-based Structured Prediction](https://arxiv.org/abs/2508.15090)
*Matt Pauk,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: LLMs在结构化预测中存在幻觉和推理问题。本文通过结合LLMs和组合推理来提高预测的准确性和一致性，并证明结构化学习在LLM时代仍然有价值。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种语言任务中表现出色，但由于其自回归特性，在幻觉和复杂推理问题上，尤其是在结构化预测领域，常常面临挑战。

Method: 本文提出将LLMs与组合推理相结合，以结合LLMs的预测能力和推理方法提供的结构一致性。研究了不同提示策略如何有效估计LLM置信度值以用于符号推理，并利用结构化预测目标进行校准和微调。

Result: 无论采用何种提示策略，在仅提示的基础上添加符号推理都能带来更一致和准确的预测。此外，使用结构化预测目标进行校准和微调可以提高挑战性任务的性能。

Conclusion: 将LLMs与组合推理相结合，并结合结构化学习方法（如校准和微调），可以有效解决LLMs在结构化预测中的一致性和准确性问题，表明结构化学习在LLM时代仍然具有重要价值。

Abstract: LLMs have been shown to be useful for a variety of language tasks, without
requiring task-specific fine-tuning. However, these models often struggle with
hallucinations and complex reasoning problems due to their autoregressive
nature. We propose to address some of these issues, specifically in the area of
structured prediction, by combining LLMs with combinatorial inference in an
attempt to marry the predictive power of LLMs with the structural consistency
provided by inference methods. We perform exhaustive experiments in an effort
to understand which prompting strategies can effectively estimate LLM
confidence values for use with symbolic inference, and show that, regardless of
the prompting strategy, the addition of symbolic inference on top of prompting
alone leads to more consistent and accurate predictions. Additionally, we show
that calibration and fine-tuning using structured prediction objectives leads
to increased performance for challenging tasks, showing that structured
learning is still valuable in the era of LLMs.

</details>


### [76] [Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset](https://arxiv.org/abs/2508.15096)
*Rabeeh Karimi Mahabadi,Sanjeev Satheesh,Shrimai Prabhumoye,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro*

Main category: cs.CL

TL;DR: 本文介绍了一个名为 Nemotron-CC-Math 的新型高质量数学语料库，它通过一种新颖的提取流程从 Common Crawl 构建。该语料库显著提高了大型语言模型在数学、代码和通用推理任务上的性能，并超越了现有的开放数学数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的数学数据集质量不佳，导致大型语言模型在数学和代码等结构化数据上的预训练效果受限，无法充分提升推理能力。

Method: 研究人员引入了一个名为 Nemotron-CC-Math 的大规模、高质量数学语料库。他们开发了一种新颖的、与领域无关的管道，专门用于鲁棒的科学文本提取。该管道利用 lynx 的布局感知渲染和基于 LLM 的清理阶段，恢复各种格式（例如 MathJax、KaTeX、MathML）的数学内容，同时保留方程和代码块的结构完整性，去除样板文件，将符号标准化为 LaTeX 表示，并纠正不一致性。

Result: 研究人员收集了 Nemotron-CC-Math-3+ (133B tokens) 和 Nemotron-CC-Math-4+ (52B tokens) 两个高质量数学语料库。其中，Nemotron-CC-Math-4+ 超越了所有之前的开放数学数据集，并且包含的 token 数量是 FineMath-4+ 的 5.5 倍。使用该语料库预训练 Nemotron-T 8B 模型，在 MATH 上获得了 +4.8 到 +12.6 的提升，在 MBPP+ 上获得了 +4.6 到 +14.3 的提升，同时也改善了 MMLU 和 MMLU-Stem 上的通用领域性能。

Conclusion: 本文提出了第一个能够从嘈杂的网页规模数据中可靠提取包括数学在内的科学内容的管道，从而在数学、代码和通用推理方面取得了可衡量的收益，并为开放数学预训练语料库树立了新的技术标准。研究人员发布了代码和数据集以支持开源工作。

Abstract: Pretraining large language models (LLMs) on high-quality, structured data
such as mathematics and code substantially enhances reasoning capabilities.
However, existing math-focused datasets built from Common Crawl suffer from
degraded quality due to brittle extraction heuristics, lossy HTML-to-text
conversion, and the failure to reliably preserve mathematical structure. In
this work, we introduce Nemotron-CC-Math, a large-scale, high-quality
mathematical corpus constructed from Common Crawl using a novel,
domain-agnostic pipeline specifically designed for robust scientific text
extraction.
  Unlike previous efforts, our pipeline recovers math across various formats
(e.g., MathJax, KaTeX, MathML) by leveraging layout-aware rendering with lynx
and a targeted LLM-based cleaning stage. This approach preserves the structural
integrity of equations and code blocks while removing boilerplate,
standardizing notation into LaTeX representation, and correcting
inconsistencies.
  We collected a large, high-quality math corpus, namely Nemotron-CC-Math-3+
(133B tokens) and Nemotron-CC-Math-4+ (52B tokens). Notably,
Nemotron-CC-Math-4+ not only surpasses all prior open math datasets-including
MegaMath, FineMath, and OpenWebMath-but also contains 5.5 times more tokens
than FineMath-4+, which was previously the highest-quality math pretraining
dataset. When used to pretrain a Nemotron-T 8B model, our corpus yields +4.8 to
+12.6 gains on MATH and +4.6 to +14.3 gains on MBPP+ over strong baselines,
while also improving general-domain performance on MMLU and MMLU-Stem.
  We present the first pipeline to reliably extract scientific
content--including math--from noisy web-scale data, yielding measurable gains
in math, code, and general reasoning, and setting a new state of the art among
open math pretraining corpora. To support open-source efforts, we release our
code and datasets.

</details>


### [77] [Identifying and Answering Questions with False Assumptions: An Interpretable Approach](https://arxiv.org/abs/2508.15139)
*Zijie Wang,Eduardo Blanco*

Main category: cs.CL

TL;DR: 该论文提出了一种识别并回答包含错误假设问题的方法，通过事实核查和利用外部证据来减少大型语言模型（LLMs）的幻觉。


<details>
  <summary>Details</summary>
Motivation: 人们经常提出包含错误假设的问题，这些问题没有常规答案，需要首先识别错误假设。大型语言模型（LLMs）常因幻觉产生误导性答案。

Method: 将问题简化为事实核查问题；利用外部证据来减轻幻觉；生成并验证原子假设。

Result: 实验表明，结合检索到的证据是有益的；生成和验证原子假设能带来更多改进，并通过明确指出错误假设提供可解释的答案。

Conclusion: 结合外部证据和生成/验证原子假设的方法可以有效地识别和回答包含错误假设的问题，并提高大型语言模型答案的可解释性。

Abstract: People often ask questions with false assumptions, a type of question that
does not have regular answers. Answering such questions require first
identifying the false assumptions. Large Language Models (LLMs) often generate
misleading answers because of hallucinations. In this paper, we focus on
identifying and answering questions with false assumptions in several domains.
We first investigate to reduce the problem to fact verification. Then, we
present an approach leveraging external evidence to mitigate hallucinations.
Experiments with five LLMs demonstrate that (1) incorporating retrieved
evidence is beneficial and (2) generating and validating atomic assumptions
yields more improvements and provides an interpretable answer by specifying the
false assumptions.

</details>


### [78] [ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following](https://arxiv.org/abs/2508.15164)
*Seungmin Han,Haeun Kwon,Ji-jun Park,Taeyang Yoon*

Main category: cs.CL

TL;DR: 本文针对大型语言和视觉语言模型在复杂多模态对话中的不足，提出了MMDR-Bench数据集和CoLVLM Agent框架。CoLVLM Agent通过迭代循环，无需重新训练即可显著提升性能，并在新基准上超越了现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）和大型视觉-语言模型（LVLMs）取得了显著进展，但它们在处理需要深度推理、持续上下文理解、实体追踪和多步骤指令遵循的复杂、多轮次、视觉接地任务时仍面临挑战。现有基准未能捕捉真实世界多模态交互的动态性和复杂性，导致上下文丢失和视觉幻觉等问题。

Method: 本文提出了MMDR-Bench（多模态对话推理基准），这是一个包含300个精心设计复杂多轮对话场景的新数据集。此外，我们提出了CoLVLM Agent（上下文LVLM代理），这是一个整体框架，通过迭代的“记忆-感知-规划-执行”循环增强现有LVLMs的推理和指令遵循能力，无需对底层模型进行大量重新训练。

Result: CoLVLM Agent在MMDR-Bench上取得了卓越的性能，平均人类评估得分达到4.03，显著超越了GPT-4o（3.92）和Gemini 1.5 Pro（3.85）等最先进的商业模型。该框架在推理深度、指令遵循和错误抑制方面表现出显著优势，并在延长对话轮次中保持了稳健的性能。

Conclusion: CoLVLM Agent的模块化设计和迭代方法在复杂多模态交互中是有效的，并在扩展对话轮次中保持了强大的性能，验证了其有效性。

Abstract: Despite significant advancements in Large Language Models (LLMs) and Large
Vision-Language Models (LVLMs), current models still face substantial
challenges in handling complex, multi-turn, and visually-grounded tasks that
demand deep reasoning, sustained contextual understanding, entity tracking, and
multi-step instruction following. Existing benchmarks often fall short in
capturing the dynamism and intricacies of real-world multi-modal interactions,
leading to issues such as context loss and visual hallucinations. To address
these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning
Benchmark), a novel dataset comprising 300 meticulously designed complex
multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across
six core dimensions including visual entity tracking and reasoning depth.
Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic
framework that enhances existing LVLMs with advanced reasoning and instruction
following capabilities through an iterative
"memory-perception-planning-execution" cycle, requiring no extensive
re-training of the underlying models. Our extensive experiments on MMDR-Bench
demonstrate that CoLVLM Agent consistently achieves superior performance,
attaining an average human evaluation score of 4.03, notably surpassing
state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro
(3.85). The framework exhibits significant advantages in reasoning depth,
instruction adherence, and error suppression, and maintains robust performance
over extended dialogue turns, validating the effectiveness of its modular
design and iterative approach for complex multi-modal interactions.

</details>


### [79] [SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling](https://arxiv.org/abs/2508.15190)
*Dong Liu,Yanxuan Yu*

Main category: cs.CL

TL;DR: SemToken是一种语义感知的标记化框架，可以减少标记冗余并提高计算效率，在不牺牲性能的情况下显著减少标记数量并加快处理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的标记化方法（如BPE或WordPiece）只依赖频率统计，忽略文本的底层语义结构，导致语义冗余的跨度过度标记，并低估了上下文连贯性，尤其是在长上下文场景中。

Method: SemToken首先通过轻量级编码器提取上下文语义嵌入，然后执行局部语义聚类以合并语义等效的标记。接着，它根据语义密度分配异构的标记粒度，在内容丰富的区域进行更细粒度的标记化，在重复或低熵的跨度中进行更粗粒度的压缩。

Result: 在WikiText-103和LongBench等长上下文语言建模基准测试中，SemToken实现了高达2.4倍的标记数量减少和1.9倍的速度提升，同时困惑度和下游准确性几乎没有下降或没有下降。

Conclusion: 研究结果表明，语义结构为优化大型语言模型中的标记化和计算提供了一个有前景的新方向。

Abstract: Tokenization plays a critical role in language modeling, yet existing
approaches such as Byte-Pair Encoding (BPE) or WordPiece operate purely on
frequency statistics, ignoring the underlying semantic structure of text. This
leads to over-tokenization of semantically redundant spans and underutilization
of contextual coherence, particularly in long-context scenarios. In this work,
we propose \textbf{SemToken}, a semantic-aware tokenization framework that
jointly reduces token redundancy and improves computation efficiency. SemToken
first extracts contextual semantic embeddings via lightweight encoders and
performs local semantic clustering to merge semantically equivalent tokens.
Then, it allocates heterogeneous token granularity based on semantic density,
allowing finer-grained tokenization in content-rich regions and coarser
compression in repetitive or low-entropy spans. SemToken can be seamlessly
integrated with modern language models and attention acceleration methods.
Experiments on long-context language modeling benchmarks such as WikiText-103
and LongBench show that SemToken achieves up to $2.4\times$ reduction in token
count and $1.9\times$ speedup, with negligible or no degradation in perplexity
and downstream accuracy. Our findings suggest that semantic structure offers a
promising new axis for optimizing tokenization and computation in large
language models.

</details>


### [80] [Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models](https://arxiv.org/abs/2508.15202)
*Yuanchen Zhou,Shuo Jiang,Jie Zhu,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang*

Main category: cs.CL

TL;DR: 现有的过程奖励模型（PRMs）在金融等特定领域表现不佳。Fin-PRM是一种专门针对金融领域、轨迹感知的PRM，它通过整合步骤级和轨迹级奖励监督，显著提高了大语言模型在金融推理任务上的性能，在监督学习、强化学习和测试时间性能方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（PRMs）主要在通用或STEM领域训练，但在金融等领域特定的上下文中表现不足。金融领域的推理更结构化、符号化，并且对事实和监管的正确性更敏感。

Method: 本文引入了Fin-PRM，一个领域专业化、轨迹感知的PRM，专门用于评估金融任务中的中间推理步骤。Fin-PRM集成了步骤级和轨迹级奖励监督，支持离线和在线奖励学习设置，应用于：(i) 选择高质量推理轨迹进行蒸馏式监督微调，(ii) 为强化学习提供密集的流程级奖励，以及(iii) 在测试时指导奖励知情的Best-of-N推理。

Result: Fin-PRM在金融推理基准测试（包括CFLUE和FinQA）中，在轨迹选择质量方面始终优于通用PRMs和强大的领域基线。使用Fin-PRM训练的下游模型在监督学习中获得了12.9%的提升，在强化学习中获得了5.2%的提升，在测试时性能上获得了5.1%的提升。

Conclusion: 领域专业化的奖励建模对于使大型语言模型与专家级金融推理对齐具有重要价值。

Abstract: Process Reward Models (PRMs) have emerged as a promising framework for
supervising intermediate reasoning in large language models (LLMs), yet
existing PRMs are primarily trained on general or Science, Technology,
Engineering, and Mathematics (STEM) domains and fall short in domain-specific
contexts such as finance, where reasoning is more structured, symbolic, and
sensitive to factual and regulatory correctness. We introduce \textbf{Fin-PRM},
a domain-specialized, trajectory-aware PRM tailored to evaluate intermediate
reasoning steps in financial tasks. Fin-PRM integrates step-level and
trajectory-level reward supervision, enabling fine-grained evaluation of
reasoning traces aligned with financial logic. We apply Fin-PRM in both offline
and online reward learning settings, supporting three key applications: (i)
selecting high-quality reasoning trajectories for distillation-based supervised
fine-tuning, (ii) providing dense process-level rewards for reinforcement
learning, and (iii) guiding reward-informed Best-of-N inference at test time.
Experimental results on financial reasoning benchmarks, including CFLUE and
FinQA, demonstrate that Fin-PRM consistently outperforms general-purpose PRMs
and strong domain baselines in trajectory selection quality. Downstream models
trained with Fin-PRM yield substantial improvements with baselines, with gains
of 12.9\% in supervised learning, 5.2\% in reinforcement learning, and 5.1\% in
test-time performance. These findings highlight the value of domain-specialized
reward modeling for aligning LLMs with expert-level financial reasoning. Our
project resources will be available at https://github.com/aliyun/qwen-dianjin.

</details>


### [81] [SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning](https://arxiv.org/abs/2508.15212)
*Huanxuan Liao,Yixing Xu,Shizhu He,Guanchen Li,Xuanwu Yin,Dong Li,Emad Barsoum,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: SPARK是一种无需训练的方法，通过在通道级别剪枝KV缓存，有效减少了LLMs长上下文推理的内存占用（超过30%），同时保持或提高了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的长上下文推理受到KV缓存瓶颈的限制，现有方法忽略了特征维度上的细粒度重要性变化，导致效率和准确性难以平衡。

Method: 提出SPARK，一种无需训练的即插即用方法，通过在通道级别剪枝KV以实现非结构化稀疏性，并在注意力分数计算期间动态恢复被剪枝的条目。该方法可与其他KV压缩和量化技术结合使用。

Result: SPARK将KV缓存存储减少了30%以上，保持或提高了模型准确性，并能在相同的内存预算内处理更长的序列。即使在80%的激进剪枝率下，性能下降也小于5%。

Conclusion: SPARK通过减少KV缓存的通道级冗余，有效解决了LLMs长上下文推理中的KV缓存瓶颈问题，在显著提高效率的同时保持了模型的准确性和鲁棒性。

Abstract: Long-context inference in large language models (LLMs) is increasingly
constrained by the KV cache bottleneck: memory usage grows linearly with
sequence length, while attention computation scales quadratically. Existing
approaches address this issue by compressing the KV cache along the temporal
axis through strategies such as token eviction or merging to reduce memory and
computational overhead. However, these methods often neglect fine-grained
importance variations across feature dimensions (i.e., the channel axis),
thereby limiting their ability to effectively balance efficiency and model
accuracy. In reality, we observe that channel saliency varies dramatically
across both queries and positions: certain feature channels carry near-zero
information for a given query, while others spike in relevance. To address this
oversight, we propose SPARK, a training-free plug-and-play method that applies
unstructured sparsity by pruning KV at the channel level, while dynamically
restoring the pruned entries during attention score computation. Notably, our
approach is orthogonal to existing KV compression and quantization techniques,
making it compatible for integration with them to achieve further acceleration.
By reducing channel-level redundancy, SPARK enables processing of longer
sequences within the same memory budget. For sequences of equal length, SPARK
not only preserves or improves model accuracy but also reduces KV cache storage
by over 30% compared to eviction-based methods. Furthermore, even with an
aggressive pruning ratio of 80%, SPARK maintains performance with less
degradation than 5% compared to the baseline eviction method, demonstrating its
robustness and effectiveness. Our code will be available at
https://github.com/Xnhyacinth/SparK.

</details>


### [82] [Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering](https://arxiv.org/abs/2508.15213)
*Bolei He,Xinran He,Run Shao,Shanfu Shu,Xianwei Xue,Mingquan Cheng,Haifeng Li,Zhenhua Ling*

Main category: cs.CL

TL;DR: S2K通过逐步内化领域知识，经济高效地提高了大型语言模型在特定领域问答中的表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定领域问答中表现不佳，而RAG方法存在幻觉和延迟问题，持续预训练则成本高昂且缺乏灵活性。主要挑战在于领域知识的长尾分布导致部分内部知识未被充分利用。

Method: 本文提出了Selct2Know (S2K) 框架，通过内部-外部知识自选择策略和选择性监督微调来内化领域知识。此外，还引入了结构化推理数据生成流程并结合GRPO以增强推理能力。

Result: 在医学、法律和金融问答基准测试中，S2K始终优于现有方法，并以显著更低的成本达到了领域预训练LLM的性能。

Conclusion: Selct2Know (S2K) 框架提供了一种成本效益高的方法，通过渐进式知识获取和利用内部-外部知识自选择，有效解决了大型语言模型在领域特定问答中的挑战，并在性能上超越现有方法或与高成本的领域预训练模型相当。

Abstract: Large Language Models (LLMs) perform well in general QA but often struggle in
domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces
external knowledge but suffers from hallucinations and latency due to noisy
retrievals. Continued pretraining internalizes domain knowledge but is costly
and lacks cross-domain flexibility. We attribute this challenge to the
long-tail distribution of domain knowledge, which leaves partial yet useful
internal knowledge underutilized. We further argue that knowledge acquisition
should be progressive, mirroring human learning: first understanding concepts,
then applying them to complex reasoning. To address this, we propose Selct2Know
(S2K), a cost-effective framework that internalizes domain knowledge through an
internal-external knowledge self-selection strategy and selective supervised
fine-tuning. We also introduce a structured reasoning data generation pipeline
and integrate GRPO to enhance reasoning ability. Experiments on medical, legal,
and financial QA benchmarks show that S2K consistently outperforms existing
methods and matches domain-pretrained LLMs with significantly lower cost.

</details>


### [83] [Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall](https://arxiv.org/abs/2508.15214)
*Sijia Cui,Aiyao He,Shuai Xu,Hongming Zhang,Yanna Wang,Qingyang Zhang,Yajing Wang,Bo Xu*

Main category: cs.CL

TL;DR: SEER是一种自引导方法，通过逐步检索和更新经验池，解决了LLM在多步工具使用中的挑战，并在基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在多步工具使用中面临挑战，包括工具选择、参数生成和工具链规划。现有方法依赖于手动设计任务特定示例或从精选库中检索，这需要大量的专家投入，并且随着工具多样性和任务难度的增加，提示工程变得复杂和低效。

Method: 我们提出了一种名为“逐步经验召回”（SEER）的自引导方法。SEER通过从不断更新的经验池中进行细粒度的、逐步的检索来解决这些挑战。它不依赖于静态或手动策划的库，而是通过成功的历史轨迹逐步扩充经验池，从而实现经验池的持续扩展和模型性能随时间的改善。

Result: 在ToolQA基准测试中，SEER在简单问题上平均提高了6.1%，在困难问题上平均提高了4.7%。在包含两个真实世界领域的τ-bench上，SEER在Qwen2.5-7B和Qwen2.5-72B模型的支持下，分别实现了7.44%和23.38%的显著准确率提升。

Conclusion: SEER通过持续学习和改进经验池，有效解决了LLM在多步工具使用中的挑战，并在多个基准测试中展现出显著的性能提升。

Abstract: Function calling enables large language models (LLMs) to interact with
external systems by leveraging tools and APIs. When faced with multi-step tool
usage, LLMs still struggle with tool selection, parameter generation, and
tool-chain planning. Existing methods typically rely on manually designing
task-specific demonstrations, or retrieving from a curated library. These
approaches demand substantial expert effort and prompt engineering becomes
increasingly complex and inefficient as tool diversity and task difficulty
scale. To address these challenges, we propose a self-guided method, Stepwise
Experience Recall (SEER), which performs fine-grained, stepwise retrieval from
a continually updated experience pool. Instead of relying on static or manually
curated library, SEER incrementally augments the experience pool with past
successful trajectories, enabling continuous expansion of the pool and improved
model performance over time. Evaluated on the ToolQA benchmark, SEER achieves
an average improvement of 6.1\% on easy and 4.7\% on hard questions. We further
test SEER on $\tau$-bench, which includes two real-world domains. Powered by
Qwen2.5-7B and Qwen2.5-72B models, SEER demonstrates substantial accuracy gains
of 7.44\% and 23.38\%, respectively.

</details>


### [84] [Are Checklists Really Useful for Automatic Evaluation of Generative Tasks?](https://arxiv.org/abs/2508.15218)
*Momoka Furuhashi,Kouta Nakayama,Takashi Kodama,Saku Sugawara*

Main category: cs.CL

TL;DR: 该研究探讨了使用大型语言模型进行生成任务自动评估时，检查清单的有效性。研究发现，选择性使用检查清单在配对比较任务中能提高评估性能，但在直接评分中效果不一。即使与人类评分相关性低的检查清单项目也反映了人类标准，这表明人类评估可能存在不一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成任务的自动评估中面临标准模糊的挑战，而自动生成检查清单的潜力尚未被充分探索。

Method: 研究调查了检查清单应全面使用还是选择性使用，采用了六种方法生成检查清单，并在八种模型大小上评估了其有效性，同时识别了与人类评估相关的检查清单项目。实验涵盖了配对比较和直接评分任务。

Result: 选择性使用检查清单在配对比较设置中能提升评估性能，但在直接评分中的效益不一致。即使与人类评分相关性不高的检查清单项目，也常反映出人类制定的标准，这表明人类评估可能存在不一致性。

Conclusion: 研究结果强调需要更清晰地定义客观评估标准，以指导人类和自动评估。

Abstract: Automatic evaluation of generative tasks using large language models faces
challenges due to ambiguous criteria. Although automatic checklist generation
is a potentially promising approach, its usefulness remains underexplored. We
investigate whether checklists should be used for all questions or selectively,
generate them using six methods, evaluate their effectiveness across eight
model sizes, and identify checklist items that correlate with human
evaluations. Through experiments on pairwise comparison and direct scoring
tasks, we find that selective checklist use tends to improve evaluation
performance in pairwise settings, while its benefits are less consistent in
direct scoring. Our analysis also shows that even checklist items with low
correlation to human scores often reflect human-written criteria, indicating
potential inconsistencies in human evaluation. These findings highlight the
need to more clearly define objective evaluation criteria to guide both human
and automatic evaluations. \footnote{Our code is available
at~https://github.com/momo0817/checklist-effectiveness-study

</details>


### [85] [VocabTailor: Dynamic Vocabulary Selection for Downstream Tasks in Small Language Models](https://arxiv.org/abs/2508.15229)
*Hanling Zhang,Yayu Zhou,Tongcheng Fang,Zhihang Yuan,Guohao Dai,Yu Wang*

Main category: cs.CL

TL;DR: VocabTailor通过动态管理词汇量，显著降低了小型语言模型在边缘设备上的内存占用，同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在资源受限环境中具有计算优势，但内存限制仍是边缘设备部署的关键瓶颈。词汇相关组件（特别是嵌入和语言模型头部）的内存占用是主要原因。现有静态词汇剪枝方法会导致信息损失且缺乏灵活性。

Method: 本文提出了VocabTailor，这是一种新颖的解耦动态词汇选择框架。它通过卸载嵌入层并为语言模型头部实现混合静态-动态词汇选择策略来解决内存限制，从而实现词汇组件的按需加载。该方法基于词汇局部性原理和词汇相关组件计算特性不对称的洞察。

Result: VocabTailor在多种下游任务中，将词汇相关组件的内存使用量减少了高达99%，同时任务性能退化最小甚至没有退化，显著优于现有静态词汇剪枝方法。

Conclusion: VocabTailor有效解决了小型语言模型在边缘设备上部署时的内存限制问题，在不牺牲任务性能的情况下大幅减少了词汇相关组件的内存使用。

Abstract: Small Language Models (SLMs) provide computational advantages in
resource-constrained environments, yet memory limitations remain a critical
bottleneck for edge device deployment. A substantial portion of SLMs' memory
footprint stems from vocabulary-related components, particularly embeddings and
language modeling (LM) heads, due to large vocabulary sizes. Existing static
vocabulary pruning, while reducing memory usage, suffers from rigid,
one-size-fits-all designs that cause information loss from the prefill stage
and a lack of flexibility. In this work, we identify two key principles
underlying the vocabulary reduction challenge: the lexical locality principle,
the observation that only a small subset of tokens is required during any
single inference, and the asymmetry in computational characteristics between
vocabulary-related components of SLM. Based on these insights, we introduce
VocabTailor, a novel decoupled dynamic vocabulary selection framework that
addresses memory constraints through offloading embedding and implements a
hybrid static-dynamic vocabulary selection strategy for LM Head, enabling
on-demand loading of vocabulary components. Comprehensive experiments across
diverse downstream tasks demonstrate that VocabTailor achieves a reduction of
up to 99% in the memory usage of vocabulary-related components with minimal or
no degradation in task performance, substantially outperforming existing static
vocabulary pruning.

</details>


### [86] [WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai](https://arxiv.org/abs/2508.15239)
*Peerat Limkonchotiwat,Pume Tuchinda,Lalita Lowphansirikul,Surapon Nonesung,Panuthep Tasawong,Alham Fikri Aji,Can Udomcharoenchaikit,Sarana Nutanong*

Main category: cs.CL

TL;DR: 大型语言模型在泰语等低资源语言中表现不佳，因为缺乏文化特定数据。本文介绍了WangchanThaiInstruct，一个人工编写的泰语数据集。使用该数据集进行微调显著提高了大型语言模型在泰语中的性能，表明了文化基础数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语指令遵循方面表现出色，但在泰语等低资源语言中的表现尚未得到充分探索。现有基准通常依赖翻译，忽略了现实世界所需的文化和领域特定细微差别。

Method: 我们提出了WangchanThaiInstruct，一个人工编写的泰语数据集，用于评估和指令微调，涵盖四个专业领域和七种任务类型。该数据集通过标注者、领域专家和AI研究人员的多阶段质量控制流程创建。该数据集支持两项研究：零样本评估和指令微调研究。

Result: 在WangchanThaiInstruct上微调的模型在领域内和领域外基准测试中均优于使用翻译数据的模型。零样本评估显示在文化和专业特定任务上存在性能差距。

Conclusion: 这些发现强调了需要文化和专业基础的指令数据来改善低资源、语言多样化环境中大型语言模型的对齐。

Abstract: Large language models excel at instruction-following in English, but their
performance in low-resource languages like Thai remains underexplored. Existing
benchmarks often rely on translations, missing cultural and domain-specific
nuances needed for real-world use. We present WangchanThaiInstruct, a
human-authored Thai dataset for evaluation and instruction tuning, covering
four professional domains and seven task types. Created through a multi-stage
quality control process with annotators, domain experts, and AI researchers,
WangchanThaiInstruct supports two studies: (1) a zero-shot evaluation showing
performance gaps on culturally and professionally specific tasks, and (2) an
instruction tuning study with ablations isolating the effect of native
supervision. Models fine-tuned on WangchanThaiInstruct outperform those using
translated data in both in-domain and out-of-domain benchmarks. These findings
underscore the need for culturally and professionally grounded instruction data
to improve LLM alignment in low-resource, linguistically diverse settings.

</details>


### [87] [UniCoM: A Universal Code-Switching Speech Generator](https://arxiv.org/abs/2508.15244)
*Sangmin Lee,Woojin Chung,Seyun Um,Hong-Goo Kang*

Main category: cs.CL

TL;DR: 该论文提出了UniCoM流水线和SWORDS算法，用于生成高质量的语码转换（CS）语音数据，并创建了CS-FLEURS语料库，该语料库在可懂度和自然度方面表现出色，旨在推动多语言语音技术的发展。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）在真实对话中很常见，但由于缺乏合适的数据集，对多语言语音技术构成了重大挑战，导致相关系统研究不足。

Method: 提出了一种名为Universal Code-Mixer（UniCoM）的新颖流程，用于生成高质量、自然的CS样本而不改变句子语义。该方法利用了一种名为Substituting WORDs with Synonyms（SWORDS）的算法，通过在考虑词性的情况下用翻译词替换选定的词来生成CS语音。

Result: 利用UniCoM构建了Code-Switching FLEURS（CS-FLEURS）多语言CS语料库，用于自动语音识别（ASR）和语音到文本翻译（S2TT）。实验结果表明，CS-FLEURS在可懂度和自然度方面表现出色，在客观和主观指标上与现有数据集相当。

Conclusion: 该方法有望推动CS语音技术的发展，并实现更具包容性的多语言系统。

Abstract: Code-switching (CS), the alternation between two or more languages within a
single speaker's utterances, is common in real-world conversations and poses
significant challenges for multilingual speech technology. However, systems
capable of handling this phenomenon remain underexplored, primarily due to the
scarcity of suitable datasets. To resolve this issue, we propose Universal
Code-Mixer (UniCoM), a novel pipeline for generating high-quality, natural CS
samples without altering sentence semantics. Our approach utilizes an algorithm
we call Substituting WORDs with Synonyms (SWORDS), which generates CS speech by
replacing selected words with their translations while considering their parts
of speech. Using UniCoM, we construct Code-Switching FLEURS (CS-FLEURS), a
multilingual CS corpus designed for automatic speech recognition (ASR) and
speech-to-text translation (S2TT). Experimental results show that CS-FLEURS
achieves high intelligibility and naturalness, performing comparably to
existing datasets on both objective and subjective metrics. We expect our
approach to advance CS speech technology and enable more inclusive multilingual
systems.

</details>


### [88] [EMNLP: Educator-role Moral and Normative Large Language Models Profiling](https://arxiv.org/abs/2508.15250)
*Yilin Jiang,Mingzi Zhang,Sheng Jin,Zengyi Yu,Xiangjie Kong,Binghao Tu*

Main category: cs.CL

TL;DR: EMNLP框架首次评估了教师角色LLMs的心理和伦理一致性，发现其人格理想化、抽象道德推理强但情感处理弱，且能力越强越易受提示注入攻击，存在能力与安全悖论。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对模拟专业角色的大型语言模型进行全面的心理和伦理评估。

Method: 本文提出了EMNLP框架，用于对教师角色LLMs进行人格分析、道德发展阶段测量以及软提示注入下的伦理风险评估。该框架扩展了现有量表，构建了88个教师特有的道德困境，并使用定向软提示注入集来评估依从性和脆弱性。

Result: 实验表明，教师角色LLMs比人类教师表现出更理想化和两极化的人格，在抽象道德推理方面表现出色，但在情感复杂情境中表现不佳。推理能力越强的模型越容易受到有害提示注入的影响，揭示了能力与安全性之间的悖论。模型温度和其他超参数的影响有限。

Conclusion: 本文提出了首个用于评估教育AI中教师角色LLMs伦理和心理一致性的基准。

Abstract: Simulating Professions (SP) enables Large Language Models (LLMs) to emulate
professional roles. However, comprehensive psychological and ethical evaluation
in these contexts remains lacking. This paper introduces EMNLP, an
Educator-role Moral and Normative LLMs Profiling framework for personality
profiling, moral development stage measurement, and ethical risk under soft
prompt injection. EMNLP extends existing scales and constructs 88
teacher-specific moral dilemmas, enabling profession-oriented comparison with
human teachers. A targeted soft prompt injection set evaluates compliance and
vulnerability in teacher SP. Experiments on 12 LLMs show teacher-role LLMs
exhibit more idealized and polarized personalities than human teachers, excel
in abstract moral reasoning, but struggle with emotionally complex situations.
Models with stronger reasoning are more vulnerable to harmful prompt injection,
revealing a paradox between capability and safety. The model temperature and
other hyperparameters have limited influence except in some risk behaviors.
This paper presents the first benchmark to assess ethical and psychological
alignment of teacher-role LLMs for educational AI. Resources are available at
https://e-m-n-l-p.github.io/.

</details>


### [89] [Conflict-Aware Soft Prompting for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.15253)
*Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee*

Main category: cs.CL

TL;DR: 提出CARE框架，通过上下文评估器解决RAG中检索内容与LLM内部知识的冲突，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: RAG在处理检索到的上下文与LLM的参数知识冲突时（即上下文-记忆冲突）存在问题，LLM难以解决这种不一致。

Method: 本文引入了冲突感知检索增强生成（CARE）框架，它由一个上下文评估器和一个基础LLM组成。上下文评估器通过接地/对抗性软提示进行训练，旨在识别不可靠的上下文并引导推理转向更可靠的知识源。

Result: CARE有效缓解了上下文-记忆冲突，在问答和事实核查基准测试中平均性能提升了5.0%。

Conclusion: CARE为构建可信赖和自适应的RAG系统提供了一个有前景的方向。

Abstract: Retrieval-augmented generation (RAG) enhances the capabilities of large
language models (LLMs) by incorporating external knowledge into their input
prompts. However, when the retrieved context contradicts the LLM's parametric
knowledge, it often fails to resolve the conflict between incorrect external
context and correct parametric knowledge, known as context-memory conflict. To
tackle this problem, we introduce Conflict-Aware REtrieval-Augmented Generation
(CARE), consisting of a context assessor and a base LLM. The context assessor
encodes compact memory token embeddings from raw context tokens. Through
grounded/adversarial soft prompting, the context assessor is trained to discern
unreliable context and capture a guidance signal that directs reasoning toward
the more reliable knowledge source. Extensive experiments show that CARE
effectively mitigates context-memory conflicts, leading to an average
performance gain of 5.0\% on QA and fact-checking benchmarks, establishing a
promising direction for trustworthy and adaptive RAG systems.

</details>


### [90] [TComQA: Extracting Temporal Commonsense from Text](https://arxiv.org/abs/2508.15274)
*Lekshmi R Nair,Arun Sankar,Koninika Pal*

Main category: cs.CL

TL;DR: LLMs在时间常识方面表现不佳。本研究提出一个基于LLM的时间常识提取流程，并构建了TComQA数据集，达到了80%以上的准确率，并提升了时间问答模型的性能。


<details>
  <summary>Details</summary>
Motivation: 理解事件需要掌握其时间背景，但这在自然语言中通常没有明确说明。大型语言模型（LLMs）在需要时间常识推理的文本生成方面表现不佳，因为时间常识在文本中很少被明确提及。因此，自动挖掘事件的时间常识有助于创建强大的语言模型。

Method: 我们研究了LLMs从文本中提取时间常识的能力，并评估了多种实验设置。我们提出了一种时间常识提取流程，该流程利用LLMs自动挖掘时间常识，并用它构建了TComQA数据集，该数据集来源于SAMSum和RealNews语料库。

Result: TComQA已通过众包验证，在提取时间常识方面达到了80%以上的准确率。使用TComQA训练的模型也优于在现有时间问答任务数据集上微调的LLM。

Conclusion: 本研究成功提出了一种利用LLMs自动挖掘时间常识的方法，并构建了一个高质量的数据集（TComQA），该数据集显著提高了模型在时间问答任务上的性能。

Abstract: Understanding events necessitates grasping their temporal context, which is
often not explicitly stated in natural language. For example, it is not a
trivial task for a machine to infer that a museum tour may last for a few
hours, but can not take months. Recent studies indicate that even advanced
large language models (LLMs) struggle in generating text that require reasoning
with temporal commonsense due to its infrequent explicit mention in text.
Therefore, automatically mining temporal commonsense for events enables the
creation of robust language models. In this work, we investigate the capacity
of LLMs to extract temporal commonsense from text and evaluate multiple
experimental setups to assess their effectiveness. Here, we propose a temporal
commonsense extraction pipeline that leverages LLMs to automatically mine
temporal commonsense and use it to construct TComQA, a dataset derived from
SAMSum and RealNews corpora. TComQA has been validated through crowdsourcing
and achieves over 80\% precision in extracting temporal commonsense. The model
trained with TComQA also outperforms an LLM fine-tuned on existing dataset of
temporal question answering task.

</details>


### [91] [CUPE: Contextless Universal Phoneme Encoder for Language-Agnostic Speech Processing](https://arxiv.org/abs/2508.15316)
*Abdul Rehman,Jian-Jun Zhang,Xiaosong Yang*

Main category: cs.CL

TL;DR: CUPE是一个轻量级模型，它能快速捕捉音素特征，通过学习基本声学模式实现出色的跨语言音素识别，证明了短窗口内通用语音处理的可能性。


<details>
  <summary>Details</summary>
Motivation: 许多语音处理任务需要不受上下文影响的纯音素表示。

Method: CUPE是一个轻量级模型，能在120毫秒内捕获关键音素特征，它独立处理短的、固定宽度的窗口，并通过学习所有语言共有的基本声学模式来实现有竞争力的跨语言性能。

Result: CUPE在多语言（包括零样本测试）上的监督和自监督训练评估显示出强大的跨语言泛化能力，尽管参数比现有方法少，但仍能实现有竞争力的跨语言性能。

Conclusion: 通过在音素长度窗口内建模基本声学模式，可以实现有效的通用语音处理。

Abstract: Universal phoneme recognition typically requires analyzing long speech
segments and language-specific patterns. Many speech processing tasks require
pure phoneme representations free from contextual influence, which motivated
our development of CUPE - a lightweight model that captures key phoneme
features in just 120 milliseconds, about one phoneme's length. CUPE processes
short, fixed-width windows independently and, despite fewer parameters than
current approaches, achieves competitive cross-lingual performance by learning
fundamental acoustic patterns common to all languages. Our extensive evaluation
through supervised and self-supervised training on diverse languages, including
zero-shot tests on the UCLA Phonetic Corpus, demonstrates strong cross-lingual
generalization and reveals that effective universal speech processing is
possible through modeling basic acoustic patterns within phoneme-length
windows.

</details>


### [92] [KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models](https://arxiv.org/abs/2508.15357)
*Haji Gul,Abul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.CL

TL;DR: 提出了一种新的元度量EDAS，用于统一知识图谱补全模型在不同数据集和指标上的评估。


<details>
  <summary>Details</summary>
Motivation: 评估知识图谱补全（KGC）模型时，在多个数据集和指标之间进行性能比较存在主要挑战，因为模型表现可能不一致，且缺乏统一的元度量来整体评估。

Method: 提出了一种基于平均解决方案距离的知识图谱评估（EDAS）方法，这是一种鲁棒且可解释的元度量，能将模型在多个数据集和不同评估标准下的性能综合为一个归一化分数。

Result: 实验结果表明，EDAS能够有效地将多指标、多数据集的性能整合到统一的排名中，为评估KGC模型提供了一个一致、鲁棒且可推广的框架。

Conclusion: EDAS是一种鲁棒且可解释的元度量，它能综合KGC模型在多数据集和多指标上的性能，提供统一的评估框架，从而支持更明智的模型选择和更公平的跨数据集评估。

Abstract: Knowledge Graphs (KGs) enable applications in various domains such as
semantic search, recommendation systems, and natural language processing. KGs
are often incomplete, missing entities and relations, an issue addressed by
Knowledge Graph Completion (KGC) methods that predict missing elements.
Different evaluation metrics, such as Mean Reciprocal Rank (MRR), Mean Rank
(MR), and Hit@k, are commonly used to assess the performance of such KGC
models. A major challenge in evaluating KGC models, however, lies in comparing
their performance across multiple datasets and metrics. A model may outperform
others on one dataset but underperform on another, making it difficult to
determine overall superiority. Moreover, even within a single dataset,
different metrics such as MRR and Hit@1 can yield conflicting rankings, where
one model excels in MRR while another performs better in Hit@1, further
complicating model selection for downstream tasks. These inconsistencies hinder
holistic comparisons and highlight the need for a unified meta-metric that
integrates performance across all metrics and datasets to enable a more
reliable and interpretable evaluation framework. To address this need, we
propose KG Evaluation based on Distance from Average Solution (EDAS), a robust
and interpretable meta-metric that synthesizes model performance across
multiple datasets and diverse evaluation criteria into a single normalized
score ($M_i \in [0,1]$). Unlike traditional metrics that focus on isolated
aspects of performance, EDAS offers a global perspective that supports more
informed model selection and promotes fairness in cross-dataset evaluation.
Experimental results on benchmark datasets such as FB15k-237 and WN18RR
demonstrate that EDAS effectively integrates multi-metric, multi-dataset
performance into a unified ranking, offering a consistent, robust, and
generalizable framework for evaluating KGC models.

</details>


### [93] [A Survey on Large Language Model Benchmarks](https://arxiv.org/abs/2508.15361)
*Shiwen Ni,Guhong Chen,Shuaimin Li,Xuanang Chen,Siyi Li,Bingli Wang,Qiyao Wang,Xingjian Wang,Yifan Zhang,Liyang Fan,Chengming Li,Ruifeng Xu,Le Sun,Min Yang*

Main category: cs.CL

TL;DR: 本文首次系统回顾并分类了283个大语言模型评估基准（通用能力、领域特定、目标特定），揭示了现有基准存在的问题（如数据污染、偏见、评估不足），并提出了未来基准设计的范式。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力的快速发展，需要评估基准来衡量模型性能、指导模型发展并促进技术创新。

Method: 首次系统回顾了大语言模型基准的现状与发展，将283个代表性基准分为通用能力、领域特定和目标特定三类进行分析。

Result: 通用能力基准涵盖核心语言学、知识、推理等；领域特定基准侧重自然科学、人文社会科学、工程技术等；目标特定基准关注风险、可靠性、智能体等。同时指出当前基准存在数据污染导致分数虚高、文化和语言偏见导致评估不公、缺乏对过程可信度和动态环境的评估等问题。

Conclusion: 为未来基准创新提供可参考的设计范式。

Abstract: In recent years, with the rapid development of the depth and breadth of large
language models' capabilities, various corresponding evaluation benchmarks have
been emerging in increasing numbers. As a quantitative assessment tool for
model performance, benchmarks are not only a core means to measure model
capabilities but also a key element in guiding the direction of model
development and promoting technological innovation. We systematically review
the current status and development of large language model benchmarks for the
first time, categorizing 283 representative benchmarks into three categories:
general capabilities, domain-specific, and target-specific. General capability
benchmarks cover aspects such as core linguistics, knowledge, and reasoning;
domain-specific benchmarks focus on fields like natural sciences, humanities
and social sciences, and engineering technology; target-specific benchmarks pay
attention to risks, reliability, agents, etc. We point out that current
benchmarks have problems such as inflated scores caused by data contamination,
unfair evaluation due to cultural and linguistic biases, and lack of evaluation
on process credibility and dynamic environments, and provide a referable design
paradigm for future benchmark innovation.

</details>


### [94] [Unveiling Trust in Multimodal Large Language Models: Evaluation, Analysis, and Mitigation](https://arxiv.org/abs/2508.15370)
*Yichi Zhang,Yao Huang,Yifan Wang,Yitong Sun,Chang Liu,Zhe Zhao,Zhengwei Fang,Huanran Chen,Xiao Yang,Xingxing Wei,Hang Su,Yinpeng Dong,Jun Zhu*

Main category: cs.CL

TL;DR: 该论文提出了MultiTrust-X，一个用于评估、分析和减轻多模态大型语言模型（MLLMs）信任度问题的综合基准，并揭示了当前模型的脆弱性以及现有缓解策略的局限性，最终提出了一个推理增强安全对齐（RESA）方法。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大型语言模型（MLLMs）的能力取得了显著进展，但其信任度仍然是一个令人担忧的问题。现有评估和缓解方法往往只关注狭窄的方面，并忽视了多模态引入的风险。

Method: 本文提出了MultiTrust-X，一个综合基准，用于评估、分析和减轻MLLM的信任度问题。它定义了一个三维框架，包含五个信任度方面、两种新颖的风险类型，并涵盖了数据、模型架构、训练和推理算法等多种缓解策略。MultiTrust-X包含32项任务和28个数据集，对30多个开源和专有MLLM进行了评估，并深入分析了8种代表性缓解方法。此外，基于实验发现，论文提出了一种推理增强安全对齐（RESA）方法。

Result: 广泛的实验揭示了当前模型的显著脆弱性，包括信任度与通用能力之间的差距，以及多模态训练和推理对基础LLM潜在风险的放大作用。受控分析揭示了现有缓解策略的关键局限性，即很少有方法能有效解决整体信任度问题，并且许多方法会引入意想不到的权衡。RESAL方法在发现潜在风险方面取得了最先进的结果。

Conclusion: 研究结果为未来的改进提供了实用的见解，例如推理能力在平衡安全性和性能方面的好处。基于这些见解，本文提出了一种推理增强安全对齐（RESA）方法，通过链式思考推理能力帮助模型发现潜在风险，并取得了最先进的结果。

Abstract: The trustworthiness of Multimodal Large Language Models (MLLMs) remains an
intense concern despite the significant progress in their capabilities.
Existing evaluation and mitigation approaches often focus on narrow aspects and
overlook risks introduced by the multimodality. To tackle these challenges, we
propose MultiTrust-X, a comprehensive benchmark for evaluating, analyzing, and
mitigating the trustworthiness issues of MLLMs. We define a three-dimensional
framework, encompassing five trustworthiness aspects which include
truthfulness, robustness, safety, fairness, and privacy; two novel risk types
covering multimodal risks and cross-modal impacts; and various mitigation
strategies from the perspectives of data, model architecture, training, and
inference algorithms. Based on the taxonomy, MultiTrust-X includes 32 tasks and
28 curated datasets, enabling holistic evaluations over 30 open-source and
proprietary MLLMs and in-depth analysis with 8 representative mitigation
methods. Our extensive experiments reveal significant vulnerabilities in
current models, including a gap between trustworthiness and general
capabilities, as well as the amplification of potential risks in base LLMs by
both multimodal training and inference. Moreover, our controlled analysis
uncovers key limitations in existing mitigation strategies that, while some
methods yield improvements in specific aspects, few effectively address overall
trustworthiness, and many introduce unexpected trade-offs that compromise model
utility. These findings also provide practical insights for future
improvements, such as the benefits of reasoning to better balance safety and
performance. Based on these insights, we introduce a Reasoning-Enhanced Safety
Alignment (RESA) approach that equips the model with chain-of-thought reasoning
ability to discover the underlying risks, achieving state-of-the-art results.

</details>


### [95] [Confidence-Modulated Speculative Decoding for Large Language Models](https://arxiv.org/abs/2508.15371)
*Jaydip Sen,Subhasis Dasgupta,Hetvi Waghela*

Main category: cs.CL

TL;DR: 本文提出了一种基于置信度调节的信息论框架，通过动态调整推测生成令牌的数量和验证过程，改进了推测解码，从而在保持质量的同时显著提高了大型语言模型的解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法依赖静态草稿长度和刚性验证标准，限制了其在不同模型不确定性和输入复杂性下的适应性。

Method: 提出了一种基于置信度调节草稿的信息论推测解码框架。通过利用草稿器输出分布上的熵和基于裕度的不确定性度量，动态调整每次迭代中推测生成的令牌数量。验证过程也使用相同的置信度信号进行调节。

Result: 在机器翻译和摘要任务上的实验表明，与标准推测解码相比，显著提高了速度，同时保持或改进了BLEU和ROUGE分数。

Conclusion: 所提出的方法为大型语言模型在不同不确定性条件下的高效、鲁棒解码提供了一种原则性的即插即用方法。

Abstract: Speculative decoding has emerged as an effective approach for accelerating
autoregressive inference by parallelizing token generation through a
draft-then-verify paradigm. However, existing methods rely on static drafting
lengths and rigid verification criteria, limiting their adaptability across
varying model uncertainties and input complexities. This paper proposes an
information-theoretic framework for speculative decoding based on
confidence-modulated drafting. By leveraging entropy and margin-based
uncertainty measures over the drafter's output distribution, the proposed
method dynamically adjusts the number of speculatively generated tokens at each
iteration. This adaptive mechanism reduces rollback frequency, improves
resource utilization, and maintains output fidelity. Additionally, the
verification process is modulated using the same confidence signals, enabling
more flexible acceptance of drafted tokens without sacrificing generation
quality. Experiments on machine translation and summarization tasks demonstrate
significant speedups over standard speculative decoding while preserving or
improving BLEU and ROUGE scores. The proposed approach offers a principled,
plug-in method for efficient and robust decoding in large language models under
varying conditions of uncertainty.

</details>


### [96] [Exploiting Vocabulary Frequency Imbalance in Language Model Pre-training](https://arxiv.org/abs/2508.15390)
*Woojin Chung,Jeonghoon Kim*

Main category: cs.CL

TL;DR: 大型语言模型中，更大的词汇表通过降低分词文本复杂度（特别是降低常见词的不确定性）来提高性能。模型利用而非受损于分词频率不平衡。这一发现为分词器与模型的协同设计提供了新视角。


<details>
  <summary>Details</summary>
Motivation: ""近期实践倾向于使用越来越大的词汇表，但其益处来源尚不明确。本研究旨在探究词汇表大小对大型语言模型性能的影响及其背后的机制。""

Method: 本研究进行了一项受控实验，在固定数据、计算资源和优化方法的情况下，将语言模型的词汇表从24K扩展到196K。我们通过柯尔莫哥洛夫复杂度量化了分词文本的复杂度，并进行了词级损失分解。此外，我们还约束了输入和输出嵌入范数以评估分词频率不平衡的影响。

Result: 1. 词汇表越大，分词文本的复杂度越低。
2. 词汇量超过24K后，词汇表增长主要加剧了相对的分词频率不平衡。
3. 较大的词汇表几乎完全通过降低2500个最常见词的不确定性来减少交叉熵，即使稀有词的损失有所增加。
4. 限制输入和输出嵌入范数会逆转增益，表明模型是利用而不是受制于不平衡。
5. 这种训练优势会转移到下游基准测试中，因为相同的常见词约占77%的标记。
6. 在固定词汇表的情况下增加模型参数也能带来相同的常见词益处。

Conclusion: 本研究将“更大的词汇表有帮助”重新定义为“降低分词文本的复杂度有帮助”，为分词器-模型协同设计提供了简单、有原则的杠杆，并阐明了预训练中语言模型扩展的损失动态。

Abstract: Large language models are trained with tokenizers, and the resulting token
distribution is highly imbalanced: a few words dominate the stream while most
occur rarely. Recent practice favors ever-larger vocabularies, but the source
of the benefit is unclear. We conduct a controlled study that scales the
language model's vocabulary from 24K to 196K while holding data, compute, and
optimization fixed. We first quantify the complexity of tokenized text,
formalized via Kolmogorov complexity, and show that larger vocabularies reduce
this complexity. Above 24K, every common word is already a single token, so
further growth mainly deepens the relative token-frequency imbalance. A
word-level loss decomposition shows that larger vocabularies reduce
cross-entropy almost exclusively by lowering uncertainty on the 2,500 most
frequent words, even though loss on the rare tail rises. Constraining input and
output embedding norms to attenuate the effect of token-frequency imbalance
reverses the gain, directly showing that the model exploits rather than suffers
from imbalance. Because the same frequent words cover roughly 77% of tokens in
downstream benchmarks, this training advantage transfers intact. We also show
that enlarging model parameters with a fixed vocabulary yields the same
frequent-word benefit. Our results reframe "bigger vocabularies help" as
"lowering the complexity of tokenized text helps," providing a simple,
principled lever for tokenizer-model co-design and clarifying the loss dynamics
that govern language-model scaling in pre-training.

</details>


### [97] [Attribution, Citation, and Quotation: A Survey of Evidence-based Text Generation with Large Language Models](https://arxiv.org/abs/2508.15396)
*Tobias Schreieder,Tim Schopf,Michael Färber*

Main category: cs.CL

TL;DR: 为解决LLM循证文本生成领域的碎片化问题，本研究系统分析了大量论文，提出了统一的分类法，调查了评估指标，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的广泛应用带来了对其可靠性和可信度的担忧，且LLM循证文本生成领域因术语不一致、评估实践孤立以及缺乏统一基准而碎片化。

Method: 系统分析了134篇论文，引入了LLM循证文本生成的统一分类法，并调查了七个关键维度的300个评估指标。重点关注使用引文、归因或引述的方法，并考察了该领域的独特特征和代表性方法。

Result: 该研究引入了统一的分类法，对评估指标进行了深入调查，并审视了该领域的特点和方法。

Conclusion: 强调了开放性挑战并概述了未来工作的有前景方向。

Abstract: The increasing adoption of large language models (LLMs) has been accompanied
by growing concerns regarding their reliability and trustworthiness. As a
result, a growing body of research focuses on evidence-based text generation
with LLMs, aiming to link model outputs to supporting evidence to ensure
traceability and verifiability. However, the field is fragmented due to
inconsistent terminology, isolated evaluation practices, and a lack of unified
benchmarks. To bridge this gap, we systematically analyze 134 papers, introduce
a unified taxonomy of evidence-based text generation with LLMs, and investigate
300 evaluation metrics across seven key dimensions. Thereby, we focus on
approaches that use citations, attribution, or quotations for evidence-based
text generation. Building on this, we examine the distinctive characteristics
and representative methods in the field. Finally, we highlight open challenges
and outline promising directions for future work.

</details>


### [98] [When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models](https://arxiv.org/abs/2508.15407)
*Cheng Wang,Gelei Deng,Xianglin Yang,Han Qiu,Tianwei Zhang*

Main category: cs.CL

TL;DR: LALMs在处理音视频冲突信息时，倾向于文本输入而忽视音频，导致性能下降。MCR-BENCH基准测试揭示了这种文本偏见和过度自信，强调需要更好的模态平衡和融合机制。


<details>
  <summary>Details</summary>
Motivation: 尽管大型音视频语言模型（LALMs）具有音频感知能力，但其在处理音频和文本之间冲突信息时的性能仍未得到充分检验。

Method: 本文引入了MCR-BENCH，这是第一个专门评估LALMs在不一致音文本对情况下信息优先级的综合基准。此外，还研究了文本偏见的影响因素，并通过有监督的微调探索了缓解策略，并分析了模型置信度模式。

Result: 当模态之间存在不一致时，LALMs表现出对文本输入的显著偏见，经常忽视音频证据。这种倾向导致在以音频为中心的任务中性能显著下降，并引发了对实际应用可靠性的担忧。研究还发现，即使输入矛盾，模型也持续表现出过度自信。

Conclusion: 为了提高处理冲突多模态输入的鲁棒性，需要在训练过程中改善模态平衡，并采用更复杂的融合机制。

Abstract: Large Audio-Language Models (LALMs) are enhanced with audio perception
capabilities, enabling them to effectively process and understand multimodal
inputs that combine audio and text. However, their performance in handling
conflicting information between audio and text modalities remains largely
unexamined. This paper introduces MCR-BENCH, the first comprehensive benchmark
specifically designed to evaluate how LALMs prioritize information when
presented with inconsistent audio-text pairs. Through extensive evaluation
across diverse audio understanding tasks, we reveal a concerning phenomenon:
when inconsistencies exist between modalities, LALMs display a significant bias
toward textual input, frequently disregarding audio evidence. This tendency
leads to substantial performance degradation in audio-centric tasks and raises
important reliability concerns for real-world applications. We further
investigate the influencing factors of text bias, and explore mitigation
strategies through supervised finetuning, and analyze model confidence patterns
that reveal persistent overconfidence even with contradictory inputs. These
findings underscore the need for improved modality balance during training and
more sophisticated fusion mechanisms to enhance the robustness when handling
conflicting multi-modal inputs. The project is available at
https://github.com/WangCheng0116/MCR-BENCH.

</details>


### [99] [LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model](https://arxiv.org/abs/2508.15418)
*Yirong Sun,Yizhong Geng,Peidong Wei,Yanjun Chen,Jinghan Yang,Rongfei Chen,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: LLaSO是首个开放的端到端大规模语音语言模型（LSLM）框架，旨在解决现有LSLM开发中碎片化和透明度不足的问题。它提供了一套新的数据集、评估基准和一个强大的基线模型，旨在统一研究并加速社区在LSLM领域的发展。


<details>
  <summary>Details</summary>
Motivation: 大规模语音语言模型（LSLM）的发展因架构碎片化和透明度不足而受阻，导致系统性比较和研究的可重复性困难。当前LSLM领域常发布模型权重但不提供相应的训练数据和配置。

Method: 我们引入了LLaSO，一个完全开放的端到端大规模语音语言建模框架。它提供了LLaSO-Align（语音-文本对齐语料库）、LLaSO-Instruct（多任务指令调优数据集）和LLaSO-Eval（可复现评估基准）三个核心资源。我们还构建并发布了LLaSO-Base模型（3.8B参数）作为参考。

Result: LLaSO-Base模型在公开数据上训练，取得了0.72的标准化分数，建立了强大的、可复现的基线，并超越了同类模型。分析表明，更广泛的训练覆盖能提升性能，但对未见任务（尤其是纯音频场景）仍存在显著的泛化差距。

Conclusion: LLaSO通过发布完整的数据、基准和模型，为LSLM领域建立了开放标准，旨在统一研究工作并加速社区驱动的进展。

Abstract: The development of Large Speech-Language Models (LSLMs) has been slowed by
fragmented architectures and a lack of transparency, hindering the systematic
comparison and reproducibility of research. Unlike in the vision-language
domain, the LSLM field suffers from the common practice of releasing model
weights without their corresponding training data and configurations. To
address these critical gaps, we introduce LLaSO, the first fully open,
end-to-end framework for large-scale speech-language modeling. LLaSO provides
the community with three essential resources: (1) LLaSO-Align, a 12M-instance
speech-text alignment corpus; (2) LLaSO-Instruct, a 13.5M-instance multi-task
instruction-tuning dataset; and (3) LLaSO-Eval, a reproducible benchmark for
standardized evaluation. To validate our framework, we build and release
LLaSO-Base, a 3.8B-parameter reference model trained exclusively on our public
data. It achieves a normalized score of 0.72, establishing a strong,
reproducible baseline that surpasses comparable models. Our analysis reveals
that while broader training coverage enhances performance, significant
generalization gaps persist on unseen tasks, particularly in pure audio
scenarios. By releasing the complete stack of data, benchmarks, and models,
LLaSO establishes a foundational open standard to unify research efforts and
accelerate community-driven progress in LSLMs. We release the code, dataset,
pretrained models, and results in https://github.com/EIT-NLP/LLaSO.

</details>


### [100] [A Study of Privacy-preserving Language Modeling Approaches](https://arxiv.org/abs/2508.15421)
*Pritilata Saha,Abhirup Sinha*

Main category: cs.CL

TL;DR: 全面研究了隐私保护语言模型方法，识别了它们的优点、局限性并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 语言模型在敏感数据上训练时可能泄露隐私，但目前对隐私风险及其缓解方法知之甚少。

Method: 通过对隐私保护语言建模方法进行全面深入的研究。

Result: 研究强调了这些方法的优点并探讨了它们的局限性。

Conclusion: 为隐私保护语言建模的持续研究做出了贡献，提供了有价值的见解并勾勒了未来的研究方向。

Abstract: Recent developments in language modeling have increased their use in various
applications and domains. Language models, often trained on sensitive data, can
memorize and disclose this information during privacy attacks, raising concerns
about protecting individuals' privacy rights. Preserving privacy in language
models has become a crucial area of research, as privacy is one of the
fundamental human rights. Despite its significance, understanding of how much
privacy risk these language models possess and how it can be mitigated is still
limited. This research addresses this by providing a comprehensive study of the
privacy-preserving language modeling approaches. This study gives an in-depth
overview of these approaches, highlights their strengths, and investigates
their limitations. The outcomes of this study contribute to the ongoing
research on privacy-preserving language modeling, providing valuable insights
and outlining future research directions.

</details>


### [101] [M-HELP: Using Social Media Data to Detect Mental Health Help-Seeking Signals](https://arxiv.org/abs/2508.15440)
*MSVPJ Sathvik,Zuhair Hasan Shaik,Vivek Gupta*

Main category: cs.CL

TL;DR: 新数据集 M-Help 旨在识别社交媒体上寻求心理健康帮助的用户，诊断疾病并找出根本原因。


<details>
  <summary>Details</summary>
Motivation: 尽管存在各种用于检测精神疾病的数据集，但在识别积极寻求帮助的个体方面仍然存在关键空白。

Method: 本文介绍了一种新颖的数据集 M-Help，专门用于检测社交媒体上的求助行为。该数据集通过识别求助活动、具体的精神疾病及其根本原因（例如人际关系挑战或经济压力）来超越传统标签。

Result: 在 M-Help 上训练的 AI 模型可以解决三个关键任务：识别求助者、诊断精神健康状况以及揭示问题的根本原因。

Conclusion: 该论文引入了一个新数据集 M-Help，以弥补在识别社交媒体上的求助行为方面的空白，使人工智能模型能够执行多项与精神健康检测和分析相关的关键任务。

Abstract: Mental health disorders are a global crisis. While various datasets exist for
detecting such disorders, there remains a critical gap in identifying
individuals actively seeking help. This paper introduces a novel dataset,
M-Help, specifically designed to detect help-seeking behavior on social media.
The dataset goes beyond traditional labels by identifying not only help-seeking
activity but also specific mental health disorders and their underlying causes,
such as relationship challenges or financial stressors. AI models trained on
M-Help can address three key tasks: identifying help-seekers, diagnosing mental
health conditions, and uncovering the root causes of issues.

</details>


### [102] [Principle Methods of Rendering Non-equivalent Words from Uzbek and Dari to Russian and English](https://arxiv.org/abs/2508.15453)
*Mohammad Ibrahim Qani*

Main category: cs.CL

TL;DR: 本研究探讨了翻译中非对等词引起的误解问题，提出了专业的转译方法和规则，并通过实例展示了如何将达里语和乌兹别克语的非对等词转译成英语和俄语。


<details>
  <summary>Details</summary>
Motivation: 由于非对等词（如食物、服装、文化和传统词汇）的存在，翻译中常出现误解，导致语言理解不彻底。

Method: 本研究采用基于文献的调研方法，旨在介绍将源语言中的非对等词专业地转译到目标语言的方法。

Result: 本研究论文提出了转译非对等词的不同方法和规则，并成功将25个达里语和乌兹别克语的非对等词转译成英语和俄语。

Conclusion: 虽然有些非对等词已被专业转译，但仍有许多词汇需要进一步处理。本研究提供了转译非对等词的有效方法和规则，以促进语言之间的充分理解。

Abstract: These pure languages understanding directly relates to translation knowledge
where linguists and translators need to work and research to eradicate
misunderstanding. Misunderstandings mostly appear in non-equivalent words
because there are different local and internal words like food, garment,
cultural and traditional words and others in every notion. Truly, most of these
words do not have equivalent in the target language and these words need to be
worked and find their equivalent in the target language to fully understand the
both languages. The purpose of this research is to introduce the methods of
rendering non-equivalent words professionally from the source language to the
target language and this research has been completed using library-based
research. However, some of these non-equivalent words are already
professionally rendered to the target language but still there many other words
to be rendered. As a result, this research paper includes different ways and
rules of rendering non-equivalent words from source language to the target
language and 25 non-equvalent words have been rendered from Dar & Uzbek into
English and Russian languages.

</details>


### [103] [PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback](https://arxiv.org/abs/2508.15456)
*Alexandru Coca,Bo-Hsiang Tseng,Pete Boothroyd,Jianpeng Cheng,Mark Gaynor,Zhenxing Zhang,Joe Stacey,Tristan Guigue,Héctor Martinez Alonso,Diarmuid Ó Séaghdha,Anders Johannsen*

Main category: cs.CL

TL;DR: PyTOD是一个通过生成可执行代码来追踪对话状态的代理，它利用语言模型遵循API模式而非语法规则，在SGD基准测试上实现了最先进的状态追踪性能，并证明了执行感知状态追踪的有效性。


<details>
  <summary>Details</summary>
Motivation: 可编程任务导向对话（TOD）代理的有效性取决于准确的状态追踪。

Method: 本文提出了PyTOD，一个通过生成可执行代码来追踪对话状态的代理。它利用策略和执行反馈进行高效的错误校正，并采用受限解码方法，使用语言模型而非语法规则来遵循API模式。

Result: PyTOD在具有挑战性的SGD基准测试上实现了最先进的状态追踪性能，并在对话进行过程中，在准确性和鲁棒的用户目标估计方面超越了强大的基线。

Conclusion: 实验证明了执行感知状态追踪的有效性。

Abstract: Programmable task-oriented dialogue (TOD) agents enable language models to
follow structured dialogue policies, but their effectiveness hinges on accurate
state tracking. We present PyTOD, an agent that generates executable code to
track dialogue state and uses policy and execution feedback for efficient error
correction. To this end, PyTOD employs a simple constrained decoding approach,
using a language model instead of grammar rules to follow API schemata. This
leads to state-of-the-art state tracking performance on the challenging SGD
benchmark. Our experiments show that PyTOD surpasses strong baselines in both
accuracy and robust user goal estimation as the dialogue progresses,
demonstrating the effectiveness of execution-aware state tracking.

</details>


### [104] [RadReason: Radiology Report Evaluation Metric with Reasons and Sub-Scores](https://arxiv.org/abs/2508.15464)
*Yingshu Li,Yunyi Liu,Lingqiao Liu,Lei Wang,Luping Zhou*

Main category: cs.CL

TL;DR: RadReason是一个用于放射学报告评估的新框架，提供细粒度、可解释的评分和理由，性能优于现有方法，并与GPT-4相当，适用于临床。


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告自动评估方法缺乏临床依据、可解释性和细粒度指标，且现有方法得分粗略或依赖黑盒模型，限制了其在临床工作流中的应用。

Method: 引入了RadReason框架，它不仅能输出六种临床定义错误类型的细粒度子分数，还能提供人类可读的理由。该方法基于Group Relative Policy Optimization，并包含两项创新：子分数动态加权和多数引导优势缩放。

Result: RadReason在ReXVal基准测试中超越了所有先前的离线指标，与基于GPT-4的评估达到相同水平，并且可解释、成本效益高，适用于临床部署。

Conclusion: RadReason通过提供细粒度、可解释的评估和稳定的优化，更好地与专家临床判断保持一致，为放射学报告评估提供了有效且实用的解决方案。

Abstract: Evaluating automatically generated radiology reports remains a fundamental
challenge due to the lack of clinically grounded, interpretable, and
fine-grained metrics. Existing methods either produce coarse overall scores or
rely on opaque black-box models, limiting their usefulness in real-world
clinical workflows. We introduce RadReason, a novel evaluation framework for
radiology reports that not only outputs fine-grained sub-scores across six
clinically defined error types, but also produces human-readable justifications
that explain the rationale behind each score. Our method builds on Group
Relative Policy Optimization and incorporates two key innovations: (1)
Sub-score Dynamic Weighting, which adaptively prioritizes clinically
challenging error types based on live F1 statistics; and (2) Majority-Guided
Advantage Scaling, which adjusts policy gradient updates based on prompt
difficulty derived from sub-score agreement. Together, these components enable
more stable optimization and better alignment with expert clinical judgment.
Experiments on the ReXVal benchmark show that RadReason surpasses all prior
offline metrics and achieves parity with GPT-4-based evaluations, while
remaining explainable, cost-efficient, and suitable for clinical deployment.
Code will be released upon publication.

</details>


### [105] [SLM4Offer: Personalized Marketing Offer Generation Using Contrastive Learning Based Fine-Tuning](https://arxiv.org/abs/2508.15471)
*Vedasamhitha Challapalli,Konduru Venkat Sai,Piyush Pratap Singh,Rupesh Prasad,Arvind Maurya,Atul Singh*

Main category: cs.CL

TL;DR: SLM4Offer是一个基于对比学习（InfoNCE损失）和微调T5-Small的生成式AI模型，用于个性化优惠生成，将优惠接受率提高了17%。


<details>
  <summary>Details</summary>
Motivation: 个性化营销对提升客户参与度和业务增长至关重要，特别是通过生成智能、数据驱动的个性化优惠来提高转化率和客户满意度。

Method: 本文提出SLM4Offer，一个用于个性化优惠生成的生成式AI模型。该模型通过对比学习方法微调预训练的编码器-解码器语言模型（T5-Small 60M），并利用InfoNCE损失在共享嵌入空间中对齐客户画像与相关优惠。对比损失引入的自适应学习行为是关键创新，它重塑了潜在空间并增强了模型的泛化能力。

Result: 在合成数据集上的实验结果显示，与监督微调基线相比，优惠接受率提高了17%。

Conclusion: 对比学习目标在推动个性化营销方面非常有效。

Abstract: Personalized marketing has emerged as a pivotal strategy for enhancing
customer engagement and driving business growth. Academic and industry efforts
have predominantly focused on recommendation systems and personalized
advertisements. Nonetheless, this facet of personalization holds significant
potential for increasing conversion rates and improving customer satisfaction.
Prior studies suggest that well-executed personalization strategies can boost
revenue by up to 40 percent, underscoring the strategic importance of
developing intelligent, data-driven approaches for offer generation. This work
introduces SLM4Offer, a generative AI model for personalized offer generation,
developed by fine-tuning a pre-trained encoder-decoder language model,
specifically Google's Text-to-Text Transfer Transformer (T5-Small 60M) using a
contrastive learning approach. SLM4Offer employs InfoNCE (Information
Noise-Contrastive Estimation) loss to align customer personas with relevant
offers in a shared embedding space. A key innovation in SLM4Offer lies in the
adaptive learning behaviour introduced by contrastive loss, which reshapes the
latent space during training and enhances the model's generalizability. The
model is fine-tuned and evaluated on a synthetic dataset designed to simulate
customer behaviour and offer acceptance patterns. Experimental results
demonstrate a 17 percent improvement in offer acceptance rate over a supervised
fine-tuning baseline, highlighting the effectiveness of contrastive objectives
in advancing personalized marketing.

</details>


### [106] [Subjective Behaviors and Preferences in LLM: Language of Browsing](https://arxiv.org/abs/2508.15474)
*Sai Sundaresan,Harshita Chopra,Atanu R. Sinha,Koustava Goswami,Nagasai Saketh Naidu,Raghav Karan,N Anushka*

Main category: cs.CL

TL;DR: 本文质疑LLM在主观用户行为方面的表现。提出HeTLM，一种聚类语言模型训练方法。研究发现，使用页面级分词器的小型LM表现优于大型LM，HeTLM在性能上优于单一LM，并显著提高了对齐效果，降低了性能方差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理用户主观行为和偏好（如浏览行为）时可能存在局限性，因为用户行为日志缺乏自然语言的结构和语法。

Method: 本文提出了一种针对主观行为的聚类语言模型训练方法——HeTLM（异质性感知语言模型训练）。

Result: (i) 使用页面级分词器训练的小型语言模型优于大型预训练或微调的语言模型；(ii) 具有异构聚类特定参数集的HeTLM优于相同家族的单一语言模型；(iii) HeTLM导致生成结果的平均值更高，方差更低。

Conclusion: HeTLM通过有效捕捉用户行为的异质性，提高了模型对用户主观行为的对齐能力，并实现了更好的平均性能和更低的性能方差。

Abstract: A Large Language Model (LLM) offers versatility across domains and tasks,
purportedly benefiting users with a wide variety of behaviors and preferences.
We question this perception about an LLM when users have inherently subjective
behaviors and preferences, as seen in their ubiquitous and idiosyncratic
browsing of websites or apps. The sequential behavior logs of pages, thus
generated, form something akin to each user's self-constructed "language",
albeit without the structure and grammar imbued in natural languages. We ask:
(i) Can a small LM represent the "language of browsing" better than a large LM?
(ii) Can an LM with a single set of parameters (or, single LM) adequately
capture myriad users' heterogeneous, subjective behaviors and preferences?
(iii) Can a single LM with high average performance, yield low variance in
performance to make alignment good at user level? We introduce clusterwise LM
training, HeTLM (Heterogeneity aware Training of Language Model), appropriate
for subjective behaviors. We find that (i) a small LM trained using a
page-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM
with heterogeneous cluster specific set of parameters outperforms a single LM
of the same family, controlling for the number of parameters; and (iii) a
higher mean and a lower variance in generation ensues, implying improved
alignment.

</details>


### [107] [Influence-driven Curriculum Learning for Pre-training on Limited Data](https://arxiv.org/abs/2508.15475)
*Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth*

Main category: cs.CL

TL;DR: 课程学习在语言模型预训练中效果不佳。本文提出了一种新的、以模型为中心的难度度量方法，即训练数据影响分数。结果表明，采用这种方法，课程学习可以使模型性能提高10个百分点以上。


<details>
  <summary>Details</summary>
Motivation: 课程学习在语言模型预训练中的表现不佳，研究人员希望找到一种更有效的难度衡量标准，以提高其竞争力。

Method: 本文通过根据训练数据影响（一种估计单个训练示例对模型输出影响的得分）对训练示例进行排序，来实验一种新的课程学习方法。

Result: 采用新课程训练的模型在基准测试中比随机顺序训练的模型性能高出10个百分点以上。

Conclusion: 只要采用以模型为中心的难度概念，课程学习对语言模型预训练是有益的。

Abstract: Curriculum learning, a training technique where data is presented to the
model in order of example difficulty (e.g., from simpler to more complex
documents), has shown limited success for pre-training language models. In this
work, we investigate whether curriculum learning becomes competitive if we
replace conventional human-centered difficulty metrics with one that more
closely corresponds to example difficulty as observed during model training.
Specifically, we experiment with sorting training examples by their
\textit{training data influence}, a score which estimates the effect of
individual training examples on the model's output. Models trained on our
curricula are able to outperform ones trained in random order by over 10
percentage points in benchmarks, confirming that curriculum learning is
beneficial for language model pre-training, as long as a more model-centric
notion of difficulty is adopted.

</details>


### [108] [SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts -- Extended Version](https://arxiv.org/abs/2508.15478)
*Nghiem Thanh Pham,Tung Kieu,Duc-Manh Nguyen,Son Ha Xuan,Nghia Duong-Trung,Danh Le-Phuoc*

Main category: cs.CL

TL;DR: SLM-Bench是一个针对小型语言模型（SLM）的基准测试平台，用于全面评估其准确性、计算效率和环境影响，并揭示了不同SLM在性能和能效上的权衡。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对小型语言模型（SLMs）性能和环境影响的系统评估。

Method: 我们引入了SLM-Bench，这是第一个专门设计用于评估SLM多维度表现的基准测试平台。它在4种硬件配置上，使用23个数据集（涵盖14个领域）评估了15个SLM在9个NLP任务上的表现，量化了11个指标。

Result: 我们的研究结果揭示了SLM之间存在多种权衡，一些模型在准确性上表现出色，而另一些则在能效方面表现更优。

Conclusion: SLM-Bench为SLM评估设立了新标准，弥合了资源效率和实际应用之间的差距。

Abstract: Small Language Models (SLMs) offer computational efficiency and
accessibility, yet a systematic evaluation of their performance and
environmental impact remains lacking. We introduce SLM-Bench, the first
benchmark specifically designed to assess SLMs across multiple dimensions,
including accuracy, computational efficiency, and sustainability metrics.
SLM-Bench evaluates 15 SLMs on 9 NLP tasks using 23 datasets spanning 14
domains. The evaluation is conducted on 4 hardware configurations, providing a
rigorous comparison of their effectiveness. Unlike prior benchmarks, SLM-Bench
quantifies 11 metrics across correctness, computation, and consumption,
enabling a holistic assessment of efficiency trade-offs. Our evaluation
considers controlled hardware conditions, ensuring fair comparisons across
models. We develop an open-source benchmarking pipeline with standardized
evaluation protocols to facilitate reproducibility and further research. Our
findings highlight the diverse trade-offs among SLMs, where some models excel
in accuracy while others achieve superior energy efficiency. SLM-Bench sets a
new standard for SLM evaluation, bridging the gap between resource efficiency
and real-world applicability.

</details>


### [109] [HebID: Detecting Social Identities in Hebrew-language Political Text](https://arxiv.org/abs/2508.15483)
*Guy Mor-Lan,Naama Rivlin-Angert,Yael R. Kaplan,Tamir Sheafer,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: 论文介绍了首个希伯来语多标签社会身份语料库HebID，用于分析以色列政客的语言，发现希伯来语LLMs效果最好，并揭示了政治言论中身份表达的模式，为非英语环境研究提供了模型。


<details>
  <summary>Details</summary>
Motivation: 现有身份识别数据集以英文为主、单标签且类别粗糙，而政治语言与社会身份密切相关并具文化特异性，因此需要一个多标签、细致的非英文身份识别语料库。

Method: 引入首个多标签希伯来语社会身份检测语料库HebID，包含5,536句以色列政客Facebook帖子，手动标注12种细致的社会身份。对多标签和单标签编码器以及大型语言模型进行基准测试，并应用分类器分析政客的Facebook帖子和议会演讲，评估身份表达的差异，并与国家公共调查数据进行比较。

Result: 希伯来语优化的LLMs表现最佳（macro-$F_1$ = 0.74）。分析揭示了身份表达在流行度、时间趋势、聚类模式和性别相关的差异，并可比较精英言论与公众身份偏好。

Conclusion: HebID为希伯来语社会身份研究提供了全面基础，并可作为其他非英语政治背景下类似研究的范例。

Abstract: Political language is deeply intertwined with social identities. While social
identities are often shaped by specific cultural contexts and expressed through
particular uses of language, existing datasets for group and identity detection
are predominantly English-centric, single-label and focus on coarse identity
categories. We introduce HebID, the first multilabel Hebrew corpus for social
identity detection: 5,536 sentences from Israeli politicians' Facebook posts
(Dec 2018-Apr 2021), manually annotated for twelve nuanced social identities
(e.g. Rightist, Ultra-Orthodox, Socially-oriented) grounded by survey data. We
benchmark multilabel and single-label encoders alongside 2B-9B-parameter
generative LLMs, finding that Hebrew-tuned LLMs provide the best results
(macro-$F_1$ = 0.74). We apply our classifier to politicians' Facebook posts
and parliamentary speeches, evaluating differences in popularity, temporal
trends, clustering patterns, and gender-related variations in identity
expression. We utilize identity choices from a national public survey, enabling
a comparison between identities portrayed in elite discourse and the public's
identity priorities. HebID provides a comprehensive foundation for studying
social identities in Hebrew and can serve as a model for similar research in
other non-English political contexts.

</details>


### [110] [Dream 7B: Diffusion Large Language Models](https://arxiv.org/abs/2508.15487)
*Jiacheng Ye,Zhihui Xie,Lin Zheng,Jiahui Gao,Zirui Wu,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream 7B是一个新的、强大的开放扩散大型语言模型，通过离散扩散建模实现并行序列精炼，在多项任务上超越现有模型，并提供更高的灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 开发一个比现有自回归模型更强大、更高效的开放扩散大型语言模型。

Method: Dream 7B采用离散扩散建模，通过迭代去噪并行地精炼序列。通过基于自回归的LLM初始化和上下文自适应的token级噪声重调度等简单而有效的训练技术实现。

Result: Dream 7B在通用、数学和编码任务上持续优于现有扩散语言模型。它展示了卓越的规划能力和推理灵活性，包括任意顺序生成、填充能力和可调的质量-速度权衡。

Conclusion: Dream 7B是目前最强大的开放扩散大型语言模型，其卓越性能和灵活性通过创新的训练技术实现，并已发布模型以促进后续研究。

Abstract: We introduce Dream 7B, the most powerful open diffusion large language model
to date. Unlike autoregressive (AR) models that generate tokens sequentially,
Dream 7B employs discrete diffusion modeling to refine sequences in parallel
through iterative denoising. Our model consistently outperforms existing
diffusion language models on general, mathematical, and coding tasks. Dream 7B
demonstrates superior planning abilities and inference flexibility, including
arbitrary-order generation, infilling capabilities, and tunable quality-speed
trade-offs. These results are achieved through simple yet effective training
techniques, including AR-based LLM initialization and context-adaptive
token-level noise rescheduling. We release both Dream-Base and Dream-Instruct
to facilitate further research in diffusion-based language modeling.

</details>


### [111] [The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech](https://arxiv.org/abs/2508.15524)
*Naama Rivlin-Angert,Guy Mor-Lan*

Main category: cs.CL

TL;DR: 首次对政治非合法化言论（PDD）进行大规模计算研究，利用希伯来语语料库和两阶段分类模型，揭示了PDD在不同平台和政治角色中的演变趋势和特征。


<details>
  <summary>Details</summary>
Motivation: 对政治非合法化言论（PDD）进行首次大规模计算研究，因为此前缺乏相关研究。

Method: 收集并手动标注了一个包含10,410个句子的希伯来语语料库，并引入了一个结合微调编码器模型和解码器LLMs的两阶段分类流程。

Result: 最佳模型（DictaLM 2.0）在二元PDD检测中达到0.74的F1分数，在非合法化特征分类中达到0.67的宏F1分数。研究发现，PDD在三十年间显著增加，在社交媒体上的流行度高于议会辩论，男性政治家比女性政治家使用更多，右翼行为者倾向更强，并在选举活动和重大政治事件期间出现明显高峰。

Conclusion: 研究结果证明了自动化PDD分析对于理解民主话语的可行性和价值。

Abstract: We present the first large-scale computational study of political
delegitimization discourse (PDD), defined as symbolic attacks on the normative
validity of political entities. We curate and manually annotate a novel
Hebrew-language corpus of 10,410 sentences drawn from Knesset speeches
(1993-2023), Facebook posts (2018-2021), and leading news outlets, of which
1,812 instances (17.4\%) exhibit PDD and 642 carry additional annotations for
intensity, incivility, target type, and affective framing. We introduce a
two-stage classification pipeline combining finetuned encoder models and
decoder LLMs. Our best model (DictaLM 2.0) attains an F$_1$ of 0.74 for binary
PDD detection and a macro-F$_1$ of 0.67 for classification of delegitimization
characteristics. Applying this classifier to longitudinal and cross-platform
data, we see a marked rise in PDD over three decades, higher prevalence on
social media versus parliamentary debate, greater use by male than female
politicians, and stronger tendencies among right-leaning actors - with
pronounced spikes during election campaigns and major political events. Our
findings demonstrate the feasibility and value of automated PDD analysis for
understanding democratic discourse.

</details>


### [112] [SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking](https://arxiv.org/abs/2508.15526)
*Xiangyang Zhu,Yuan Tian,Chunyi Li,Kaiwei Zhang,Wei Sun,Guangtao Zhai*

Main category: cs.CL

TL;DR: SafetyFlow是一个自动构建大型语言模型安全基准的代理流系统，它克服了现有基准耗时、资源密集、冗余和难度有限的问题，并在四天内自动生成了一个包含23,446个查询的SafetyFlowBench数据集，首次实现了全自动化基准测试流程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速普及对可靠的安全评估提出了更高要求，但现有安全评估基准通常依赖人工策划，导致时间、资源消耗大，并存在显著冗余和有限的难度。

Method: 本文引入了SafetyFlow，这是首个旨在自动化构建LLM安全基准的代理流系统。SafetyFlow通过编排七个专门的代理，在没有任何人工干预的情况下，仅用四天时间即可自动构建一个全面的安全基准，并配备了多功能工具，确保过程和成本的可控性，同时将人类专业知识融入自动化流程。

Result: SafetyFlow可以在四天内自动构建一个全面的安全基准，无需人工干预，显著减少了时间和资源成本。最终构建的数据集SafetyFlowBench包含23,446个查询，具有低冗余和强大的区分能力。研究人员还在该数据集上评估了49个先进的LLM。

Conclusion: 本文的贡献在于提出了首个全自动化的基准测试管道和一个全面的安全基准。

Abstract: The rapid proliferation of large language models (LLMs) has intensified the
requirement for reliable safety evaluation to uncover model vulnerabilities. To
this end, numerous LLM safety evaluation benchmarks are proposed. However,
existing benchmarks generally rely on labor-intensive manual curation, which
causes excessive time and resource consumption. They also exhibit significant
redundancy and limited difficulty. To alleviate these problems, we introduce
SafetyFlow, the first agent-flow system designed to automate the construction
of LLM safety benchmarks. SafetyFlow can automatically build a comprehensive
safety benchmark in only four days without any human intervention by
orchestrating seven specialized agents, significantly reducing time and
resource cost. Equipped with versatile tools, the agents of SafetyFlow ensure
process and cost controllability while integrating human expertise into the
automatic pipeline. The final constructed dataset, SafetyFlowBench, contains
23,446 queries with low redundancy and strong discriminative power. Our
contribution includes the first fully automated benchmarking pipeline and a
comprehensive safety benchmark. We evaluate the safety of 49 advanced LLMs on
our dataset and conduct extensive experiments to validate our efficacy and
efficiency.

</details>


### [113] [Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing](https://arxiv.org/abs/2508.15617)
*Ishaan Bhola,Mukunda NS,Sravanth Kurmala,Harsh Nandwani,Arihant Jain*

Main category: cs.CL

TL;DR: 针对LLMs成本过高的问题，本文提出了“训练微缩模型”的概念，即通过微调小型语言模型（SLMs）来在特定应用中以更低的成本生成相似的文本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文本生成方面表现出色，但在特定应用场景（如销售和营销推广）中，其高昂的计算成本是不可行的。

Method: 本文引入了“训练微缩模型”（Trained Miniatures）的概念，即针对特定高价值应用进行微调的小型语言模型（SLMs）。

Result: 通过使用“训练微缩模型”，可以在保持相似的领域特定响应质量的同时，显著降低文本生成的成本。

Conclusion: 小型语言模型（SLMs）能够以极低的成本生成相似的领域特定响应。

Abstract: Large language models (LLMs) excel in text generation; however, these
creative elements require heavy computation and are accompanied by a steep
cost. Especially for targeted applications such as sales and marketing
outreach, these costs are far from feasible. This paper introduces the concept
of "Trained Miniatures" - Small Language Models(SLMs) fine-tuned for specific,
high-value applications, generating similar domain-specific responses for a
fraction of the cost.

</details>


### [114] [SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](https://arxiv.org/abs/2508.15648)
*Peng Ding,Wen Sun,Dailin Li,Wei Zou,Jiaming Wang,Jiajun Chen,Shujian Huang*

Main category: cs.CL

TL;DR: 提出SDGO框架，通过对齐LLM的辨别和生成能力，有效提升模型安全性，抵抗越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）容易受到越狱攻击，且在识别有害请求方面比生成防御方面更有效。

Method: 提出SDGO（自辨别引导优化），一个利用模型自身辨别能力作为奖励信号的强化学习框架，通过迭代自我改进提升生成安全性。

Result: SDGO显著提高了模型安全性，并在通用基准上保持了实用性，对分布外（OOD）越狱攻击表现出鲁棒性。

Conclusion: SDGO通过对齐LLM的辨别和生成能力，实现了更紧密的耦合，从而在仅少量辨别样本的情况下显著增强了模型的生成能力。

Abstract: Large Language Models (LLMs) excel at various natural language processing
tasks but remain vulnerable to jailbreaking attacks that induce harmful content
generation. In this paper, we reveal a critical safety inconsistency: LLMs can
more effectively identify harmful requests as discriminators than defend
against them as generators. This insight inspires us to explore aligning the
model's inherent discrimination and generation capabilities. To this end, we
propose SDGO (Self-Discrimination-Guided Optimization), a reinforcement
learning framework that leverages the model's own discrimination capabilities
as a reward signal to enhance generation safety through iterative
self-improvement. Our method does not require any additional annotated data or
external models during the training phase. Extensive experiments demonstrate
that SDGO significantly improves model safety compared to both prompt-based and
training-based baselines while maintaining helpfulness on general benchmarks.
By aligning LLMs' discrimination and generation capabilities, SDGO brings
robust performance against out-of-distribution (OOD) jailbreaking attacks. This
alignment achieves tighter coupling between these two capabilities, enabling
the model's generation capability to be further enhanced with only a small
amount of discriminative samples. Our code and datasets are available at
https://github.com/NJUNLP/SDGO.

</details>


### [115] [Benchmarking Computer Science Survey Generation](https://arxiv.org/abs/2508.15658)
*Weihang Su,Anzhe Xie,Qingyao Ai,Jianming Long,Jiaxin Mao,Ziyi Ye,Yiqun Liu*

Main category: cs.CL

TL;DR: 介绍了SurGE基准测试和自动化评估框架，旨在评估大型语言模型在生成科学综述方面的能力。研究发现，即使是先进的LLM方法，在综述生成方面仍面临巨大挑战。


<details>
  <summary>Details</summary>
Motivation: 由于学术文献的快速增长，人工创建科学综述文章变得越来越不可行。尽管大型语言模型（LLM）在此方面具有自动化潜力，但缺乏标准化的基准和评估协议阻碍了该领域的发展。

Method: 本文引入了SurGE（Survey Generation Evaluation）基准，用于评估计算机科学领域的科学综述生成。SurGE包含测试实例（包括主题描述、专家撰写综述及其引用文献）和一个超过一百万篇论文的大规模学术语料库作为检索池。此外，还提出了一个自动化评估框架，从信息覆盖、引用准确性、结构组织和内容质量四个维度衡量生成的综述。

Result: 对多样化基于LLM的方法的评估表明，综述生成仍然极具挑战性，即使对于先进的自反思框架也是如此。

Conclusion: 这些发现强调了任务的复杂性以及持续研究的必要性。

Abstract: Scientific survey articles play a vital role in summarizing research
progress, yet their manual creation is becoming increasingly infeasible due to
the rapid growth of academic literature. While large language models (LLMs)
offer promising capabilities for automating this process, progress in this area
is hindered by the absence of standardized benchmarks and evaluation protocols.
To address this gap, we introduce SurGE (Survey Generation Evaluation), a new
benchmark for evaluating scientific survey generation in the computer science
domain. SurGE consists of (1) a collection of test instances, each including a
topic description, an expert-written survey, and its full set of cited
references, and (2) a large-scale academic corpus of over one million papers
that serves as the retrieval pool. In addition, we propose an automated
evaluation framework that measures generated surveys across four dimensions:
information coverage, referencing accuracy, structural organization, and
content quality. Our evaluation of diverse LLM-based approaches shows that
survey generation remains highly challenging, even for advanced self-reflection
frameworks. These findings highlight the complexity of the task and the
necessity for continued research. We have open-sourced all the code, data, and
models at: https://github.com/oneal2000/SurGE

</details>


### [116] [Position Bias Mitigates Position Bias:Mitigate Position Bias Through Inter-Position Knowledge Distillation](https://arxiv.org/abs/2508.15709)
*Yifei Wang,Feng Xiong,Yong Wang,Linjing Li,Xiangxiang Chu,Daniel Dajun Zeng*

Main category: cs.CL

TL;DR: Pos2Distill是一个知识蒸馏框架，旨在通过利用位置差异来缓解长上下文任务中的位置偏差，从而提高性能和均匀性。


<details>
  <summary>Details</summary>
Motivation: 位置偏差（PB）严重损害了长上下文的理解和处理能力，尽管现有方法有所改进，但显著的PB依然存在。

Method: 我们引入了Pos2Distill，一个从优势位置向劣势位置传递能力的知识蒸馏框架，以减少巨大的性能差距。它利用固有、位置引起的差异来对抗PB本身。为解决检索和推理范式下的PB，设计了Pos2Distill-R¹和Pos2Distill-R²两个专门的实例化。

Result: 通过Pos2Distill方法，我们在长上下文检索和推理任务中实现了所有上下文位置的均匀性增强和显著的性能提升。两个专门系统在互相之间表现出强大的跨任务泛化能力，同时在各自任务上实现了卓越的性能。

Conclusion: Pos2Distill框架成功地解决了长上下文任务中的位置偏差问题，显著提高了性能和均匀性，并展现出强大的跨任务泛化能力。

Abstract: Positional bias (PB), manifesting as non-uniform sensitivity across different
contextual locations, significantly impairs long-context comprehension and
processing capabilities. While prior work seeks to mitigate PB through
modifying the architectures causing its emergence, significant PB still
persists. To address PB effectively, we introduce \textbf{Pos2Distill}, a
position to position knowledge distillation framework. Pos2Distill transfers
the superior capabilities from advantageous positions to less favorable ones,
thereby reducing the huge performance gaps. The conceptual principle is to
leverage the inherent, position-induced disparity to counteract the PB itself.
We identify distinct manifestations of PB under \textbf{\textsc{r}}etrieval and
\textbf{\textsc{r}}easoning paradigms, thereby designing two specialized
instantiations: \emph{Pos2Distill-R\textsuperscript{1}} and
\emph{Pos2Distill-R\textsuperscript{2}} respectively, both grounded in this
core principle. By employing the Pos2Distill approach, we achieve enhanced
uniformity and significant performance gains across all contextual positions in
long-context retrieval and reasoning tasks. Crucially, both specialized systems
exhibit strong cross-task generalization mutually, while achieving superior
performance on their respective tasks.

</details>


### [117] [Stemming -- The Evolution and Current State with a Focus on Bangla](https://arxiv.org/abs/2508.15711)
*Abhijit Paul,Mashiat Amin Farin,Sharif Md. Abdullah,Ahmedul Kabir,Zarif Masud,Shebuti Rayana*

Main category: cs.CL

TL;DR: 对孟加拉语词干提取进行了调查，指出了研究和实施方面的空白，批评了评估方法，并提出了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为一种资源匮乏、高度屈折的语言，在数字世界中代表性不足。词干提取是降低算法和模型复杂性的关键预处理步骤。现有研究存在显著空白，缺乏可复制的实现，并且评估方法存在问题。

Method: 本文对词干提取方法进行了全面调查，强调了有效处理形态变体的重要性。文章探讨了孟加拉语词干提取的现状，指出了文献中的空白，批评了评估方法，并为孟加拉语词干提取工具的开发提出了方向。

Result: 本文揭示了孟加拉语词干提取现有文献中的显著空白、与先前研究的脱节、可访问实现稀缺以及评估方法需要改进的问题。

Conclusion: 本文呼吁开发鲁棒的孟加拉语词干提取工具，并继续该领域的研究，以增强语言分析和处理能力。

Abstract: Bangla, the seventh most widely spoken language worldwide with 300 million
native speakers, faces digital under-representation due to limited resources
and lack of annotated datasets. Stemming, a critical preprocessing step in
language analysis, is essential for low-resource, highly-inflectional languages
like Bangla, because it can reduce the complexity of algorithms and models by
significantly reducing the number of words the algorithm needs to consider.
This paper conducts a comprehensive survey of stemming approaches, emphasizing
the importance of handling morphological variants effectively. While exploring
the landscape of Bangla stemming, it becomes evident that there is a
significant gap in the existing literature. The paper highlights the
discontinuity from previous research and the scarcity of accessible
implementations for replication. Furthermore, it critiques the evaluation
methodologies, stressing the need for more relevant metrics. In the context of
Bangla's rich morphology and diverse dialects, the paper acknowledges the
challenges it poses. To address these challenges, the paper suggests directions
for Bangla stemmer development. It concludes by advocating for robust Bangla
stemmers and continued research in the field to enhance language analysis and
processing.

</details>


### [118] [EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models](https://arxiv.org/abs/2508.15721)
*Xinyi Ling,Hanwen Du,Zhihui Zhu,Xia Ning*

Main category: cs.CL

TL;DR: 该论文提出了一个名为 EcomMMMU 的大规模多模态数据集，旨在研究电商图片是否总能提升产品理解。研究发现，产品图片有时会降低性能，表明多模态大语言模型（MLLMs）在利用视觉内容方面存在挑战。为此，论文提出了 SUMEI 方法，通过预测视觉效用来策略性地利用多张图片，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有电商平台中产品图片的数据集规模和设计有限，难以系统地探究图片是否总能增强产品理解，以及它们是否会引入冗余或降低性能。

Method: 本文引入了一个名为 EcomMMMU 的电商多模态多任务理解数据集，包含 406,190 个样本和 8,989,510 张图片。EcomMMMU 包含多图像视觉-语言数据，设计了 8 项基本任务和一个专门的 VSS 子集，以评估多模态大语言模型（MLLMs）有效利用视觉内容的能力。此外，本文提出了 SUMEI 方法，该方法通过预测视觉效用，然后将其用于下游任务来策略性地利用多张图片。

Result: 对 EcomMMMU 的分析表明，产品图片并非总能提升性能，在某些情况下甚至会降低性能，这表明 MLLMs 可能难以有效利用丰富的视觉内容进行电商任务。综合实验证明了 SUMEI 方法的有效性和鲁棒性。

Conclusion: 产品图片在电商任务中并非总能提升模型性能，有时甚至会降低性能，这表明当前的多模态大语言模型在有效利用丰富的视觉内容方面仍面临挑战。本文提出的 SUMEI 方法能够策略性地利用多张图片，有效提高了模型性能。

Abstract: E-commerce platforms are rich in multimodal data, featuring a variety of
images that depict product details. However, this raises an important question:
do these images always enhance product understanding, or can they sometimes
introduce redundancy or degrade performance? Existing datasets are limited in
both scale and design, making it difficult to systematically examine this
question. To this end, we introduce EcomMMMU, an e-commerce multimodal
multitask understanding dataset with 406,190 samples and 8,989,510 images.
EcomMMMU is comprised of multi-image visual-language data designed with 8
essential tasks and a specialized VSS subset to benchmark the capability of
multimodal large language models (MLLMs) to effectively utilize visual content.
Analysis on EcomMMMU reveals that product images do not consistently improve
performance and can, in some cases, degrade it. This indicates that MLLMs may
struggle to effectively leverage rich visual content for e-commerce tasks.
Building on these insights, we propose SUMEI, a data-driven method that
strategically utilizes multiple images via predicting visual utilities before
using them for downstream tasks. Comprehensive experiments demonstrate the
effectiveness and robustness of SUMEI. The data and code are available through
https://anonymous.4open.science/r/submission25.

</details>


### [119] [End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning](https://arxiv.org/abs/2508.15746)
*Qiaoyu Zheng,Yuze Sun,Chaoyi Wu,Weike Zhao,Pengcheng Qiu,Yongguo Yu,Kun Sun,Yanfeng Wang,Ya Zhang,Weidi Xie*

Main category: cs.CL

TL;DR: Deep-DxSearch是一个基于RL训练的智能RAG系统，通过构建大规模医学检索语料库和定制奖励，解决了医学LLM的知识空白和幻觉问题，并在诊断准确性上显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 医学大型语言模型在诊断中存在知识空白和幻觉，而现有检索增强方法因外部知识利用不足和反馈推理可追溯性差而效果有限。

Method: 本文提出Deep-DxSearch，一个通过强化学习（RL）端到端训练的代理RAG系统，旨在实现可追溯的检索增强推理以进行医学诊断。该系统首先构建大规模医学检索语料库，然后将LLM作为核心代理，语料库作为其环境，通过定制的奖励（基于格式、检索、推理结构和诊断准确性）从大规模数据中通过RL演化代理RAG策略。

Result: 实验证明，Deep-DxSearch的端到端代理RL训练框架在多个数据中心持续优于提示工程和免训练RAG方法。Deep-DxSearch在诊断准确性上取得了显著提升，超越了GPT-4o、DeepSeek-R1等强大诊断基线以及其他医学专用框架，适用于常见和罕见疾病的诊断，且在分布内和分布外设置下均表现良好。奖励设计和检索语料库组件的消融研究证实了它们的关键作用。

Conclusion: Deep-DxSearch显著提升了医学诊断政策，提供了更深入的性能洞察，并支持临床医生提供更可靠和精确的初步诊断。

Abstract: Accurate diagnosis with medical large language models is hindered by
knowledge gaps and hallucinations. Retrieval and tool-augmented methods help,
but their impact is limited by weak use of external knowledge and poor
feedback-reasoning traceability. To address these challenges, We introduce
Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement
learning (RL) that enables steer tracebale retrieval-augmented reasoning for
medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical
retrieval corpus comprising patient records and reliable medical knowledge
sources to support retrieval-aware reasoning across diagnostic scenarios. More
crutially, we frame the LLM as the core agent and the retrieval corpus as its
environment, using tailored rewards on format, retrieval, reasoning structure,
and diagnostic accuracy, thereby evolving the agentic RAG policy from
large-scale data through RL.
  Experiments demonstrate that our end-to-end agentic RL training framework
consistently outperforms prompt-engineering and training-free RAG approaches
across multiple data centers. After training, Deep-DxSearch achieves
substantial gains in diagnostic accuracy, surpassing strong diagnostic
baselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks
for both common and rare disease diagnosis under in-distribution and
out-of-distribution settings. Moreover, ablation studies on reward design and
retrieval corpus components confirm their critical roles, underscoring the
uniqueness and effectiveness of our approach compared with traditional
implementations. Finally, case studies and interpretability analyses highlight
improvements in Deep-DxSearch's diagnostic policy, providing deeper insight
into its performance gains and supporting clinicians in delivering more
reliable and precise preliminary diagnoses. See
https://github.com/MAGIC-AI4Med/Deep-DxSearch.

</details>


### [120] [Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis](https://arxiv.org/abs/2508.15754)
*Yufeng Zhao,Junnan Liu,Hongwei Liu,Dongsheng Zhu,Yuan Shen,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 本文介绍了ReasonZoo基准和PAC/AUC-PCC指标，以评估工具集成推理（TIR）对大型语言模型（LLM）推理能力的提升。研究发现TIR显著提高了LLM在数学和非数学任务中的表现和推理效率，减少了过度思考。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在链式思考（CoT）推理等方法下在推理任务中取得了显著进展，但它们在需要精确计算的任务中往往表现不佳。工具集成推理（TIR）作为一种解决方案应运而生，但其在提高LLM推理能力方面的泛化性仍不清楚。此外，TIR是否改善了模型的推理行为并帮助模型思考仍有待研究。

Method: 我们引入了ReasonZoo，一个包含九种不同推理类别的综合基准，以评估TIR在各个领域的有效性。此外，我们提出了两种新颖的指标：性能感知成本（PAC）和性能-成本曲线下面积（AUC-PCC），用于评估推理效率。

Result: 我们的实证评估表明，TIR模型在数学和非数学任务中均持续优于非TIR模型。此外，TIR提高了推理效率，PAC和AUC-PCC的改善证明了这一点，表明减少了过度思考并简化了推理。

Conclusion: 这些发现强调了TIR的领域通用优势及其在复杂推理任务中提升LLM潜力的能力。

Abstract: Large Language Models (LLMs) have made significant strides in reasoning tasks
through methods like chain-of-thought (CoT) reasoning. However, they often fall
short in tasks requiring precise computations. Tool-Integrated Reasoning (TIR)
has emerged as a solution by incorporating external tools into the reasoning
process. Nevertheless, the generalization of TIR in improving the reasoning
ability of LLM is still unclear. Additionally, whether TIR has improved the
model's reasoning behavior and helped the model think remains to be studied. We
introduce ReasonZoo, a comprehensive benchmark encompassing nine diverse
reasoning categories, to evaluate the effectiveness of TIR across various
domains. Additionally, we propose two novel metrics, Performance-Aware Cost
(PAC) and Area Under the Performance-Cost Curve (AUC-PCC), to assess reasoning
efficiency. Our empirical evaluation demonstrates that TIR-enabled models
consistently outperform their non-TIR counterparts in both mathematical and
non-mathematical tasks. Furthermore, TIR enhances reasoning efficiency, as
evidenced by improved PAC and AUC-PCC, indicating reduced overthinking and more
streamlined reasoning. These findings underscore the domain-general benefits of
TIR and its potential to advance LLM capabilities in complex reasoning tasks.

</details>


### [121] [LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries](https://arxiv.org/abs/2508.15760)
*Ming Yin,Dinghan Shen,Silei Xu,Jianbing Han,Sixun Dong,Mian Zhang,Yebowen Hu,Shujian Liu,Simin Ma,Song Wang,Sathish Reddy Indurthi,Xun Wang,Yiran Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: 本文提出了LiveMCP-101基准测试，用于评估AI智能体在多步骤、真实世界场景中使用多种MCP工具的能力。结果显示，即使是领先的LLM在工具编排方面也面临巨大挑战，成功率低于60%。


<details>
  <summary>Details</summary>
Motivation: 尽管模型上下文协议（MCP）为工具集成提供了一个强大的标准化框架，但在基准测试AI智能体如何有效解决使用各种MCP工具的多步骤任务方面存在显著差距，尤其是在现实、动态的场景中。

Method: 我们提出了LiveMCP-101，这是一个包含101个经过精心策划的真实世界查询的基准，需要协调使用多种MCP工具。此外，我们引入了一种新颖的评估方法，利用真实执行计划而不是原始API输出。

Result: 实验表明，即使是前沿的大型语言模型（LLMs）成功率也低于60%，这突出显示了工具编排方面的重大挑战。详细的消融实验和错误分析进一步揭示了不同的失败模式和令牌使用效率低下。

Conclusion: LiveMCP-101为评估真实世界智能体能力设定了严格的标准，推动了自主AI系统通过工具使用可靠地执行复杂任务。

Abstract: Tool calling has emerged as a critical capability for AI agents to interact
with the real world and solve complex tasks. While the Model Context Protocol
(MCP) provides a powerful standardized framework for tool integration, there is
a significant gap in benchmarking how well AI agents can effectively solve
multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In
this work, we present LiveMCP-101, a benchmark of 101 carefully curated
real-world queries, refined through iterative LLM rewriting and manual review,
that require coordinated use of multiple MCP tools including web search, file
operations, mathematical reasoning, and data analysis. Moreover, we introduce a
novel evaluation approach that leverages ground-truth execution plans rather
than raw API outputs, better reflecting the evolving nature of real-world
environments. Experiments show that even frontier LLMs achieve a success rate
below 60\%, highlighting major challenges in tool orchestration. Detailed
ablations and error analysis further reveal distinct failure modes and
inefficiencies in token usage, pointing to concrete directions for advancing
current models. LiveMCP-101 sets a rigorous standard for evaluating real-world
agent capabilities, advancing toward autonomous AI systems that reliably
execute complex tasks through tool use.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [122] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 该论文提出了一种完全谱化的神经符号推理架构，利用图信号处理（GSP）作为核心计算骨干，整合符号逻辑和神经网络推理，并在多个基准数据集上取得了逻辑一致性、可解释性和计算效率的显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型将谱图方法视为辅助组件，而本文提出了一种将图信号处理（GSP）作为主要计算骨干，以整合符号逻辑和神经推理的架构。

Method: 该方法在图谱域中构建了整个推理流程，将逻辑实体和关系编码为图信号，通过可学习的谱滤波器进行处理，并映射为符号谓词进行基于规则的推理。该框架包括图傅里叶变换、带选择性注意力以及谱规则接地。

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等基准推理数据集上的实验表明，与现有最先进的神经符号模型相比，该方法在逻辑一致性、可解释性和计算效率方面均有所提高。

Conclusion: 图信号处理（GSP）为构建鲁棒且可解释的推理系统提供了一个具有数学基础和计算效率的基底。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [123] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 本文提出了一种新的计算框架，其中世界模型的描述性（“是什么”）和规范性（“什么是可取的”）方面从代理的目标中协同出现，而不是独立存在，并引入了受佛教认识论启发的“目的性状态”概念。


<details>
  <summary>Details</summary>
Motivation: 通常认为有目的的行为依赖于世界模型，该模型包含描述性（“是什么”）和规范性（“什么是可取的”）两方面。然而，一个尚未在计算上形成替代可能性是，这两方面从代理的目标中相互依存地共同出现。

Method: 我们描述了一个认知代理中目标导向状态表示的计算框架，其中世界模型的描述性和规范性方面从代理与环境的交互序列（或经验）中共同出现。借鉴佛教认识论，我们引入了目标导向或目的性状态的构建，将其定义为目标等效经验分布的类别。

Result: 目的性状态提供了一种简约的解释，说明了目标导向学习如何通过行为策略和期望经验特征之间的统计差异来实现。我们回顾了支持这一新观点的实证和理论文献。

Conclusion: 本框架有望为跨不同基质的有目的行为的行为、现象学和神经维度提供统一的解释。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [124] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC是一个多智能体LLM框架，通过解决流行度偏差来提高旅游推荐的多样性和相关性，优于单智能体系统。


<details>
  <summary>Details</summary>
Motivation: 解决旅游推荐中的流行度偏差并增强多样性，从而应对过度旅游问题。

Method: 提出Collab-REC，一个多智能体框架，包含三个基于LLM的智能体（个性化、流行度、可持续性）生成城市建议，并通过一个非LLM协调器进行多轮协商合并和优化这些建议。

Result: Collab-REC在多样性和整体相关性方面优于单智能体基线，能够发现经常被忽视的访问量较少的地点。

Conclusion: LLM驱动的推荐系统中的多方协作具有巨大潜力，可实现平衡、上下文感知的旅游推荐。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [125] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 利用大型语言模型（LLMs）让智能体进行对话并基于对话和感知进行移动，从而实现更真实的、具有涌现群体行为的人群模拟。


<details>
  <summary>Details</summary>
Motivation: 现有的人群模拟方法未充分考虑语言和对话驱动的复杂社会和环境互动，导致智能体间互动受限。

Method: 提出了一种利用大型语言模型（LLMs）控制智能体移动的新方法。该方法包含对话系统和语言驱动导航两个主要部分。通过周期性查询以智能体个性、角色、欲望和关系为条件的LLMs来生成智能体间对话，然后结合对话、个性、情感状态等来控制每个智能体的导航和转向。

Result: 智能体能够基于感知输入和正在进行的对话做出移动决策。在复杂场景中验证了该方法，观察到智能体自动分组和解组，并且该方法作为人群中的信息传递机制。

Conclusion: 本框架能够产生更真实的人群模拟，其中涌现的群体行为自然地从任何环境设置中产生。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [126] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: LLM在知识密集型任务中的信心校准会随着推理深度的增加而恶化；通过信息检索（搜索）来提高信心校准比更深入的推理更有效。


<details>
  <summary>Details</summary>
Motivation: 作为问答工具部署的大型语言模型需要强大的校准能力以避免过度自信。

Method: 我们系统地评估了推理能力和预算如何影响信心评估的准确性，使用了ClimateX数据集（Lacombe et al., 2023），并将其扩展到人类和地球健康领域。我们比较了纯推理和搜索增强生成两种方法。

Result: 最近的推理LLM在评估专家信心方面的准确率为48.7%；增加推理预算反而会损害而非改善校准，导致系统性过度自信。相反，搜索增强生成显著优于纯推理，通过检索相关证据达到89.3%的准确率。

Conclusion: 信息获取，而非推理深度或推理预算，可能是提高知识密集型任务信心校准的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [127] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: 论文将展示在CogniSAT-6卫星上使用深度学习和光谱分析算法进行星载数据分析，以实现新的地球科学测量。


<details>
  <summary>Details</summary>
Motivation: 旨在通过在边缘（例如星载）进行数据分析，实现新的地球科学测量和响应。

Method: 利用CogniSAT-6/HAMMER (CS-6) 卫星的可见光和近红外高光谱仪器以及神经网络加速硬件，结合深度学习和光谱分析算法，进行星载数据分析和推理。

Result: 计划在CS-6卫星上成功演示用于多种应用的星载数据分析和推理。

Conclusion: 通过在CS-6上成功演示星载数据分析，证明其能够支持新的地球科学测量和响应。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [128] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA是一种轻量级、无需数据的新方法，通过修剪微调权重中的风险部分，使LoRA适应的LLM更安全，同时不牺牲性能或增加成本。


<details>
  <summary>Details</summary>
Motivation: 使用LoRA等PEFT技术调整大型语言模型（LLM）可以增强LLM代理的能力，但可能无意中损害安全对齐，导致不安全或不稳定的行为，特别是在代理规划任务中。现有的安全感知适应方法通常需要访问基础模型和指令微调模型检查点，这在实践中通常不可用。

Method: 我们提出了S3LoRA（Safe Spectral Sharpness-Guided Pruning LoRA），一个轻量级、无数据、与模型无关的框架，通过仅检查微调的权重更新来减轻LoRA适应模型中的安全风险。我们首先引入了Magnitude-Aware Spherically Normalized SVD (MAS-SVD) 来分析LoRA更新的结构特性。然后，我们设计了Spectral Sharpness Index (SSI) 来检测具有高度集中且可能不安全更新的层，并对这些层进行事后剪枝以降低风险。

Result: 在代理规划和语言生成任务上的广泛实验和消融研究表明，S3LoRA始终能提高安全指标，同时保持或改进实用指标，并显著降低推理成本。

Conclusion: 这些结果确立了S3LoRA作为一种实用且可扩展的解决方案，用于在真实世界、资源受限和安全关键环境中安全部署基于LLM的代理。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [129] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文将劳动力管理视为抽象论证，以适应执行时变化并提供解释，用户研究表明其工具和解释能提高问题解决的速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 劳动力管理中，在执行时适应变化并向所有利益相关者提供解释是一个关键挑战。

Method: 通过将劳动力管理理解为工业应用中的抽象论证。

Result: 用户研究表明，我们的工具和解释比传统手动解决方案能更快、更准确地解决问题。

Conclusion: 通过将劳动力管理理解为抽象论证，可以成功适应变化并提供忠实解释，从而实现更快、更准确的问题解决。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [130] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 本文介绍了一种名为GOOD（GOals from Open-ended Dialogue）的数据高效在线方法，用于具身AI代理通过开放式对话从人类交互中提取自然语言形式的目标，并在“开放宇宙协助博弈”（OU-AGs）框架下推断目标分布，解决了预定义人类目标和偏好未知的挑战。该方法通过LLM模拟用户进行概率推断，实现了丰富的目标表示和不确定性估计，无需大量离线数据集，并在多个模拟环境中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 具身AI代理必须以可解释的方式推断和执行未预定义的多样化人类目标和偏好。为了形式化这种设定，论文引入了“开放宇宙协助博弈”（OU-AGs），这是一个代理必须对无限且不断演进的可能目标空间进行推理的框架。

Method: 论文提出了一种名为GOOD（GOals from Open-ended Dialogue）的数据高效在线方法。该方法在与人类交互过程中以自然语言形式提取目标，并推断自然语言目标上的分布。GOOD提示大型语言模型（LLM）模拟具有不同复杂意图的用户，利用其响应对候选目标进行概率推断。

Result: 该方法在文本杂货购物领域和文本操作的模拟家庭机器人环境（AI2Thor）中进行了评估，并使用合成用户配置文件。结果显示，该方法优于没有明确目标跟踪的基线方法，并得到了基于LLM和人类评估的证实。

Conclusion: GOOD方法无需大型离线数据集，即可实现丰富的目标表示和不确定性估计，有效解决了具身AI代理在开放式、未预定义的人类目标和偏好下的目标推理和行为问题。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [131] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: aiXiv 是一个新平台，旨在解决当前出版生态系统对AI生成研究内容的限制，提供开放获取、人机协作的提交、评审和迭代修订机制，从而加速高质量AI研究的传播。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型（LLMs）使AI能够生成科学内容，但现有的出版生态系统（如传统期刊和预印本服务器）碎片化、封闭且缺乏规模化能力，导致大量高质量的AI生成研究内容难以找到合适的发布平台，阻碍了科学进步。

Method: 本文引入了aiXiv，一个面向人类和AI科学家的下一代开放获取平台。它采用多智能体架构，允许人类和AI科学家共同提交、评审和迭代改进研究提案和论文。该平台还提供API和MCP接口，实现异构人机科学家的无缝集成，构建可扩展、可扩展的自主科学发现生态系统。

Result: 通过广泛的实验证明，aiXiv 是一个可靠且强大的平台，在aiXiv上经过迭代修订和评审后，能够显著提高AI生成研究提案和论文的质量。

Conclusion: 这项工作为AI科学家构建了一个下一代开放获取生态系统，加速了高质量AI生成研究内容的出版和传播。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [132] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 本文介绍了GUI-Owl和Mobile-Agent-v3，它们是开源的GUI代理模型/框架，在桌面和移动GUI基准测试中实现了最先进的性能，这得益于大规模环境基础设施、多样化的基础代理能力和可扩展的强化学习。


<details>
  <summary>Details</summary>
Motivation: 旨在引入GUI-Owl（一个基础GUI代理模型）和Mobile-Agent-v3（一个通用GUI代理框架），以在GUI基准测试中实现开源模型的最新性能。

Method: GUI-Owl集成了三大创新：
1.  大规模环境基础设施：一个基于云的虚拟环境，涵盖Android、Ubuntu、macOS和Windows，支持“自进化GUI轨迹生成”框架，通过自动化查询生成和正确性验证生成高质量交互数据。
2.  多样化的基础代理能力：整合了UI定位、规划、动作语义和推理模式，支持端到端的决策。
3.  可扩展的环境强化学习：开发了带有完全异步训练的可扩展强化学习框架，并引入了轨迹感知相对策略优化（TRPO）进行在线强化学习。
Mobile-Agent-v3则在GUI-Owl的基础上进一步提升性能。

Result: GUI-Owl-7B在AndroidWorld上达到66.4分，在OSWorld上达到29.4分。
Mobile-Agent-v3进一步将AndroidWorld的性能提升到73.3分，OSWorld的性能提升到37.7分，为开源GUI代理框架树立了新的SOTA。
TRPO在OSWorld上取得了34.9分。

Conclusion: GUI-Owl和Mobile-Agent-v3是开源的基础GUI代理模型/框架，通过创新的基础设施、多样化的能力和可扩展的强化学习，在各种GUI基准测试中取得了最先进的性能。

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [133] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: PuzzleClone是一个使用SMT生成可验证的数学和逻辑数据集的框架，通过数据增强显著提升了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 高质量、可验证的数学和逻辑数据集对于增强大型语言模型的推理能力至关重要。现有的大模型生成数据集在可靠性、多样性和可扩展性方面存在局限。

Method: 提出了PuzzleClone，一个使用可满足性模理论（SMT）大规模合成可验证数据的形式化框架。主要创新包括：将谜题编码为结构化逻辑规范、通过系统变量和约束随机化生成可扩展变体、通过复现机制确保有效性。

Result: 构建了一个包含超过8.3万个多样化且经过程序验证的谜题基准。在PuzzleClone数据集上进行训练（SFT和RL）显著提高了模型在PuzzleClone测试集以及其他逻辑和数学基准上的表现。PuzzleClone平均分从14.4提高到56.2，并在7个逻辑和数学基准上实现了高达12.5个百分点的持续改进。

Conclusion: PuzzleClone框架成功生成了高质量、可验证的数学和逻辑数据集，这些数据集能有效提升大型语言模型在相关任务上的推理能力。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [134] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat是一个针对多汗症的开源LLM框架，通过数据增强、微调和专家评估，提供可信赖和富有同情心的支持，超越了基线模型，并为其他罕见疾病提供了可推广的方法。


<details>
  <summary>Details</summary>
Motivation: 针对罕见疾病（如多汗症）的医疗应用中，大型语言模型（LLMs）因数据稀缺和不可靠而受阻，且目前尚无专门针对多汗症诊断或护理的LLMs。

Method: 提出LLM4Sweat，一个三阶段的开源领域特定LLM框架。包括：1. 数据增强阶段，使用LLM生成合成病历以创建多样化数据集。2. 微调阶段，在数据集上微调开源基础模型以提供诊断、个性化治疗和心理支持。3. 推理和专家评估阶段，由专家评估并迭代优化数据集。

Result: LLM4Sweat超越了基线模型，并提供了首个针对多汗症的开源LLM框架。

Conclusion: LLM4Sweat为解决罕见疾病在数据和信任度方面的挑战提供了一种可推广的方法。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [135] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: 该研究介绍了R-ConstraintBench，一个用于评估大型语言模型在强约束调度问题下可靠性的框架。结果显示，当约束类型复杂交互时，LLM的性能显著下降，且其泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在高度受限条件下进行推理的可靠性尚未得到充分表征。

Method: 提出了R-ConstraintBench框架，该框架通过逐步增加有向无环图（DAGs）中的非冗余前置约束，并引入停机时间、时间窗口和分离约束来评估模型在资源受限项目调度问题（RCPSP）上的表现。

Result: 在仅有前置约束的DAGs上，强模型表现接近上限，但当停机时间、时间窗口和分离约束相互作用时，可行性性能急剧下降，表明约束交互而非图深度是主要瓶颈。此外，在纯合成场景下的表现不能保证在实际场景中的迁移，这凸显了有限的泛化能力。

Conclusion: 大型语言模型在处理复杂约束交互下的调度问题时面临显著挑战，其性能瓶颈主要在于约束间的相互作用而非图的深度，且模型的泛化能力有限。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [136] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 一个无需训练的智能系统，结合VLM和LLM，将草图转换为精确的可编辑SVG图表，优于现有图像生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在将手绘草图转换为流程图时，在空间精度、对齐和符号结构方面表现不佳。

Method: 提出“See it. Say it. Sorted.”系统，一个无需训练的智能系统，结合视觉语言模型（VLM）和大型语言模型（LLM）来生成可编辑的SVG程序。该系统采用迭代循环，通过Critic VLM提出编辑建议，候选LLM合成SVG更新，并由Judge VLM选择最佳方案。

Result: 该方法在流程图草图上比GPT-5和Gemini-2.5-Pro等前沿图像生成LLM更能忠实地重建布局和结构，并且能够准确地组合图元，不会插入不必要的文本。

Conclusion: 该设计优先考虑定性推理而非脆弱的数值估计，保留了全局约束（例如对齐、连接），并自然支持人工干预校正。由于输出是可编程的SVG，因此易于扩展到演示工具。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [137] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的计算智能方法来优化城市土地利用分配，通过CR+DES和MSBX+MO算法在兼容性和经济效益上取得了显著改进，为城市规划者提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 城市土地利用分配是一个复杂的、多目标优化问题，对可持续城市发展政策至关重要。本文旨在解决混合用途区域土地利用分配的固有权衡问题，即土地利用兼容性与经济目标之间的权衡。

Method: 开发了多种优化算法，包括将差分进化与多目标遗传算法相结合的定制变体。主要贡献包括：1) 利用比例差分向量增强探索的CR+DES算法；2) 提高解决方案质量同时保持可行性的系统性约束放宽策略；3) 使用Kruskal-Wallis检验进行统计验证。

Result: 在对一个包含1,290个地块的真实案例研究中，CR+DES在土地利用兼容性方面比现有方法提高了3.16%，而MSBX+MO在价格优化方面提高了3.3%。统计分析证实，包含差分向量的算法在多个指标上显著优于传统方法。约束放宽技术在保持实际约束的同时，能够探索更广阔的解决方案空间。

Conclusion: 这些研究结果为城市规划者和政策制定者提供了基于证据的计算工具，用于平衡土地利用分配中的相互竞争目标，支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [138] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 针对大语言模型代理记忆质量问题，提出多重记忆系统（MMS），通过构建检索和上下文记忆单元有效处理历史数据，实验证明其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型代理在处理大量历史交互数据时面临挑战，现有记忆模块方法（如MemoryBank和A-MEM）存储记忆内容质量差，影响召回性能和响应质量。

Method: 提出多重记忆系统（MMS），受认知心理学启发。它将短期记忆处理成多个长期记忆片段，并构建检索记忆单元和上下文记忆单元，两者一一对应。检索阶段，MMS匹配最相关的检索记忆单元，获取相应的上下文记忆单元作为响应的上下文，以增强知识。

Result: 在LoCoMo数据集上的实验证明了该方法的有效性。消融研究证实了记忆单元的合理性。还分析了所选记忆片段数量和存储开销的鲁棒性。

Conclusion: MMS通过有效利用历史数据，提高了大语言模型代理的性能，并具有实际应用价值。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [139] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 提出了一个名为“Coarse-to-Fine Grounded Memory”的LLM代理框架，通过结合粗细粒度记忆来提高复杂规划任务中的知识多样性和灵活性，解决了现有单一粒度记忆的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的记忆机制受限于单一粒度记忆，导致知识多样性和规划灵活性不足。

Method: 提出Coarse-to-Fine Grounded Memory (Ours) 框架，通过LLM将环境信息 grounding 为粗粒度焦点，指导经验收集，并从经验中 grounding 混合粒度提示。推理时检索相关经验和提示支持规划。面对异常时，LLM将当前情况 grounding 为细粒度关键信息，实现灵活的自我问答反射和规划修正。

Result: 增强了LLM代理在复杂规划任务中对多样化场景的灵活适应能力，并能在环境异常时进行灵活的自我修正。

Conclusion: Coarse-to-Fine Grounded Memory (Ours) 框架通过结合粗粒度和细粒度记忆，解决了现有LLM代理在复杂规划任务中记忆单一粒度的问题，提升了其知识多样性和规划灵活性。

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [140] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: SPW是一种结合专家演示和偏好的新方法，用于离线强化学习，通过搜索相似性来分配信用，从而在机器人操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中的奖励函数设计困难且昂贵；人类反馈（专家演示和偏好）各有局限性，演示成本高昂且行为模式有限，偏好则存在信用分配不明确的问题。

Method: 本文提出了一种基于搜索的偏好加权（SPW）方案。对于偏好标注轨迹中的每个转换，SPW从专家演示中搜索最相似的状态-动作对，并根据相似性分数直接导出分步重要性权重。这些权重用于指导标准偏好学习，从而实现更准确的信用分配。

Result: SPW方案能够实现对偏好和演示的有效联合学习，在具有挑战性的机器人操作任务中，其性能优于以往利用两种反馈类型的方法，并实现了传统方法难以实现更准确的信用分配。

Conclusion: SPW成功地统一了专家演示和偏好两种反馈来源，解决了信用分配问题，并在离线强化学习中，特别是在机器人操作任务中，取得了显著的性能提升。

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [141] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 该论文提出了RETAIL数据集和TGMA多智能体框架，旨在改进现有大语言模型在旅行规划中无法处理隐性查询、环境因素和详细POI的问题。TGMA模型在真实旅行规划场景中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型增强了自动化旅行规划能力，但当前系统仍与实际场景不符。主要挑战包括：1. 现有系统假设用户提供明确查询，而实际需求往往是隐性的。2. 忽略多样化的环境因素和用户偏好，限制了计划的可行性。3. 系统只能生成基本POI安排的计划，缺乏细节丰富的“一体化”计划。

Method: 为了解决这些挑战，论文构建了一个名为“RETAIL”的新型数据集，支持隐性查询的决策，同时涵盖显性查询（包括需要和不需要修订的）。该数据集还支持环境感知，确保在真实场景下计划的可行性，并包含详细的POI信息以实现“一体化”旅行计划。此外，论文提出了一个名为“TGMA”的话题引导多智能体框架。

Result: 实验结果表明，即使是最强的现有模型也仅达到1.0%的通过率，这表明真实世界的旅行规划仍然极具挑战性。相比之下，TGMA模型表现出显著的性能提升，达到2.72%的通过率。

Conclusion: 当前大语言模型在旅行规划方面面临真实世界场景的挑战。本文通过构建RETAIL数据集和提出TGMA框架，有效缓解了现有模型的不足。TGMA的改进性能为未来真实世界旅行规划提供了有前景的方向。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [142] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG是一个将心电图信号与大语言模型结合的框架，通过将心电图嵌入离散化为符号token，扩展LLM词汇表，并进行预训练和指令微调，实现了在心电图问答和诊断报告生成任务上的优异表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化心电图方法在跨临床任务的泛化能力和开放式推理方面存在局限性。

Method: DiagECG框架通过将连续心电图嵌入离散化为符号token，扩展大语言模型（LLM）的词汇表，使其能够统一处理心电图和自然语言输入。该方法还通过自回归心电图预测任务进行预训练以弥合模态差距，并对心电图问答和诊断报告生成任务进行指令微调。

Result: DiagECG在不修改核心模型的情况下，在各种任务中取得了出色的性能，并保持了对分布外设置的泛化能力。大量的实验证明了每个组件的有效性。

Conclusion: 将符号心电图表示整合到大语言模型中，在医学推理方面具有巨大潜力。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [143] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文引入了“计划中断”的概念，旨在规划中寻求对初始状态修改最小的方案。作者提出了一种方法，可以同时优化行动成本和计划中断，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在许多规划应用中，人们可能对寻找那些对初始状态修改最小以实现目标的计划感兴趣。

Method: 本文正式引入了“计划中断”的概念，并定义了各种基于规划的编译方法，旨在共同优化行动成本总和与计划中断。

Result: 在不同的基准测试中，实验结果表明，重新制定的任务在实践中可以有效地解决。

Conclusion: 所生成计划能够平衡行动成本和计划中断这两个目标。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [144] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 一个合成数据生成框架，用于大规模高质量地为LLM训练（SFT/DPO）生成对话数据，显著降低数据准备成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的进步严重依赖于高质量数据集，尤其是在监督微调（SFT）和对齐任务（如DPO）中。

Method: 我们提出了一个全面的合成数据生成框架，该框架具有可扩展、可配置和高保真度的特点。它采用模块化、基于配置的管道来建模复杂对话流，并结合了启发式规则和基于LLM的评估的双阶段质量标记机制，以过滤和评分数据，确保高质量对话样本的生成。

Result: 生成的丰富数据集具有灵活的结构，支持SFT和DPO两种用例，可无缝集成到各种训练工作流中。

Conclusion: 这些创新提供了一个强大的解决方案，用于大规模生成和管理合成对话数据，显著减少了LLM训练管道中数据准备的开销。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [145] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个利用LLMs的多智能体框架，通过CTMDP、熵优化和Stackelberg博弈解决企业决策碎片化问题，并在多个业务场景中表现优异，显著提升了解决方案质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 当前的企业决策支持和战略规划方法难以整合复杂的运营分析与宏观战略目标，导致工作流程碎片化和协作效率低下。

Method: 论文提出了BusiAgent，一个基于LLM的多智能体框架。它结合了扩展的连续时间马尔可夫决策过程（CTMDP）、广义熵度量以及多级Stackelberg博弈来处理决策。此外，还采用了上下文Thompson采样进行提示优化，并辅以质量保证系统。

Result: 在各种业务场景下的广泛实证评估验证了BusiAgent的有效性，证明它能生成连贯、以客户为中心的解决方案，无缝整合细致洞察与高层战略，在解决方案质量和用户满意度方面显著优于现有方法。

Conclusion: BusiAgent将先进的AI技术与商业洞察相结合，在AI驱动的企业决策中迈出了重要一步，使组织能更有效地应对复杂的商业环境。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [146] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 提出了“分块思考”框架，使LLM能根据任务复杂性动态调整推理深度，提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）的思维链过长会导致计算资源浪费和响应变慢，因此需要研究LLM是否能根据任务复杂性动态调整推理过程长度。

Method: 提出了“分块思考（Think in Blocks）”框架，通过将推理过程划分为可调数量的块来实现自适应推理。并采用三阶段训练流程：监督微调、奖励引导的直接偏好优化和强化学习。

Result: 建立了显式的块结构范式，使模型能够预测推理预算并相应地划分推理；训练出了能够根据问题难度调整推理深度的自适应模型；利用显式块计数在推理时动态控制推理深度，从而灵活调整思维链长度。

Conclusion: 本文提出的“分块思考”框架使LLM能够根据任务复杂性动态调整推理深度，有效解决了思维链过长带来的计算效率问题。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [147] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 本研究受超加性合作理论启发，通过模拟语言模型代理在囚徒困境游戏中的内部团队动态和外部竞争，发现这种结合能显著提高合作水平，为设计更具合作性的多智能体AI系统提供了新框架和见解。


<details>
  <summary>Details</summary>
Motivation: 受超加性合作理论的启发，该理论认为重复互动和群体间竞争是人类合作倾向的原因，本研究旨在探讨自主AI代理的合作行为。

Method: 本研究设计了一个虚拟锦标赛，将语言模型代理分组，在囚徒困境游戏中进行对抗，模拟内部团队动态和外部竞争。

Result: 研究发现，内部团队动态和外部竞争的结合显著提升了总体和初始的一次性合作水平。

Conclusion: 本研究为大型语言模型在复杂社会场景中制定策略和行动提供了一个新颖的框架，并提供了群体间竞争如何反直觉地导致更多合作行为的证据，这对设计未来多智能体AI系统至关重要。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [148] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: 本文介绍了 DeepThink3D，通过生成更复杂的3D场景推理问题并使用 DPO 优化工具链策略，提升大型语言模型在复杂3D推理任务中的表现和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中问题的简单性导致大型语言模型在3D场景推理任务中生成的程序推理链相对较短，限制了其执行复杂推理的能力。

Method: 引入 DeepThink3D 框架；在 SQA3D 基准上提出一种组合和迭代演进的方法来生成更复杂的问题；微调大型语言模型以提高其3D工具使用能力；通过直接偏好优化（DPO）直接优化模型生成的工具链策略。

Result: 通过优化工具链策略，增强了大型语言模型在复杂任务中的准确性。

Conclusion: 通过生成更复杂的3D推理问题并优化工具链策略，可以显著提高大型语言模型在复杂3D场景推理任务中的准确性。

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [149] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 该论文提出了一种新的框架，通过将强化学习智能体及其环境分析为离散时间自主动力系统，来验证强化学习策略在安全关键系统中的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受限于缺乏验证学习策略鲁棒性和安全性的形式化方法。

Method: 该论文将强化学习智能体及其环境组合分析为离散时间自主动力系统。通过利用动力系统理论中的有限时间李雅普诺夫指数（FTLE），识别并可视化拉格朗日相干结构（LCS）。引入了定量指标：平均边界排斥（MBR）、聚合虚假吸引子强度（ASAS）和时间感知虚假吸引子强度（TASAS），并提供了推导局部稳定性保证和处理模型不确定性的方法。

Result: 排斥性LCS可作为不安全区域周围的安全屏障，吸引性LCS揭示了系统的收敛特性和潜在故障模式。该框架提供了一种全面且可解释的策略行为评估方法，成功识别了仅凭奖励看似成功的策略中的关键缺陷。

Conclusion: 该框架通过识别和分析拉格朗日相干结构以及引入定量指标，为评估强化学习策略在安全关键系统中的安全裕度和鲁棒性提供了一种有效且可解释的方法，能够发现传统奖励机制无法察觉的策略缺陷。

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [150] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: Agentics是一个模块化框架，通过让大型语言模型（LLMs）在数据类型内部进行逻辑转导，实现代理系统的结构化推理和组合泛化。它鼓励开发者关注数据建模而非提示工程，并在多项任务中取得了最先进的性能或更高的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有AI工作流在处理复杂数据时面临挑战，需要一种新的方法来简化AI开发，并提升代理系统的结构化推理和组合泛化能力。

Method: 本文提出了Agentics，一个模块化框架。在该框架中，代理从逻辑流中抽象出来，并在数据类型内部使用，以实现数据之间的逻辑转导。它通过LLMs提供数据类型并进行组合，形成一种声明式语言，使开发者能专注于数据建模而非提示工程。

Result: Agentics在领域特定的多项选择问答、文本到SQL的语义解析和自动化提示优化任务中表现出卓越的适用性。它达到了最先进的准确性，或在不牺牲性能的情况下提高了可扩展性。

Conclusion: Agentics框架为构建基于代理的系统提供了一种新颖而有效的方法，通过聚焦数据建模和利用LLMs进行逻辑转导，简化了AI开发并显著提升了复杂数据处理的性能。

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [151] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 该论文将全息声明式记忆（HDM）应用于ACT-R，以实现更好的可伸缩性和块相似性。作者使HDM与Lisp ACT-R兼容，并开发了矢量化功能和基于矢量的块检索机制。初步结果显示，HDM保留了其矢量符号优势，并能与现有ACT-R模型良好兼容。


<details>
  <summary>Details</summary>
Motivation: 为了提供ACT-R声明式记忆（DM）系统的矢量符号替代方案，HDM具有可伸缩性和架构上定义的DM块相似性等优势。

Method: 作者将HDM适配到Lisp ACT-R中，开发了通用的ACT-R矢量化功能，建立了文本处理管道以将大型文档内容添加到ACT-R记忆中，并创建了一种基于矢量表示来检索整个记忆块的新机制。

Result: 初步结果表明，HDM在与现有ACT-R模型兼容的同时，保持了其矢量符号的优势（例如，无需存储实际块即可召回，以及扩展性优势），且对模型中的程序和声明式记忆部分的修改很少（甚至没有）。

Conclusion: 新转换的全息声明式记忆模块可与现有ACT-R模型无缝协作，并保留了HDM的优势。未来将继续改进时间-上下文矢量表示，并开发使用实例学习理论的决策模型以进一步测试该模块。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [152] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本文提出了一种名为“预期合作值（ICVs）”的方法，它基于信息论Shapley值，通过分析策略分布来量化多智能体强化学习（MARL）中每个智能体对其队友的因果影响，尤其是在缺乏价值反馈的情况下，从而增强了MARL系统的可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了可靠地部署多智能体强化学习（MARL）系统，理解团队中单个智能体的行为至关重要。以往的工作通常根据显式奖励信号或学习到的价值函数评估整体团队性能，但尚不清楚在没有任何价值反馈的情况下如何推断智能体的贡献。

Method: 本文引入了“预期合作值（ICVs）”，这是一种基于信息论Shapley值的方法，用于量化每个智能体对其合作者工具性赋能的因果影响。具体来说，ICVs通过评估智能体的决策不确定性和偏好一致性来衡量智能体行为对其队友策略的影响。

Result: 对合作和竞争性MARL环境的分析揭示了智能体采用相似或多样化策略的程度。通过比较策略和价值函数之间的行为影响，我们的方法识别出哪些智能体行为有利于团队成功，无论是通过促进确定性决策还是通过保持未来行动选择的灵活性。

Conclusion: 我们提出的方法为合作动态提供了新颖的见解，并增强了MARL系统的可解释性。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [153] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文通过技术-哲学视角分析欧盟AI法案，揭示AI数据生命周期中的递归价值链和监管盲点。文章引入“未来性”概念来解释AI的自我强化特性，并指出当前监管忽视了AI的“生成动态”以及数据带来的权力集中。为应对此，论文提出了一系列解决基础设施和时间动态的监管措施。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过对欧盟人工智能法案的技术-哲学解读，揭示AI系统中数据长期动态，特别是从摄取到部署的生命周期如何产生挑战现有负责任AI框架的递归价值链。作者指出，政策制定中缺少对AI技术操作和经济逻辑背后“生成动态”的理解。

Method: 引入一个概念工具来构建AI管道框架，涵盖数据、训练机制、架构、特征存储和迁移学习。采用跨学科方法，开发出技术上扎实且哲学上连贯的分析，以识别监管盲点。提出一种受西蒙东（Simondonian）技术哲学启发的AI形式化解读，重新阐释其个体化概念以建模AI生命周期，并引入“未来性”（futurity）来描述AI的自我强化生命周期。

Result: 政策制定中缺乏对AI技术操作和经济逻辑背后“生成动态”的理解。通过“未来性”概念，揭示数据递归生成、非竞争性以及由特征存储等基础设施支持的反馈、适应和时间递归特性。突出了日益加剧的权力不对称，特别是科技寡头通过其捕获、训练和部署的基础设施集中了价值和决策权。

Conclusion: 有效的监管必须解决这些基础设施和时间动态，并提出生命周期审计、时间可追溯性、反馈问责制、递归透明度以及质疑递归重用权利等措施。

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [154] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个新的多模态基准测试，它使用程序生成的图表和表格，以及系统生成的多步分析问题，以结构化格式（如JSON或YAML）提供答案，用于评估模型在遵循指令、视觉推理和视觉-文本对齐方面的能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个结构化的多模态基准，用于评估模型在指令遵循、视觉推理和视觉-文本对齐任务上的能力，并为该领域设立新的评估标准。

Method: GRAFT通过Python可视化库程序化生成图表和合成渲染表格，以确保对数据语义、结构和清晰度的控制。每个GRAFT实例将图表或表格图像与系统生成的多步分析问题配对，并以JSON或YAML等结构化格式提供答案。它还引入了包括比较、趋势识别、排名、聚合、比例估计和异常检测在内的推理类型分类。

Result: GRAFT支持对推理和输出格式进行一致评估，实现全面评估。参考答案遵循严格的事实和格式指南，以进行精确的基于方面的评估。GRAFT提供了一个统一、可扩展的框架，用于对视觉基础结构化推理任务上的多模态模型进行细粒度基准测试。

Conclusion: GRAFT为视觉基础结构化推理任务上的多模态模型提供了一个统一、可扩展的细粒度基准测试框架，为该领域树立了新的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [155] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，可以将任何基于Jax的强化学习环境转换为在线接口，支持单智能体和多智能体环境，从而帮助研究人员进行在线人类实验，以开发类人AI、人机协作AI和人机辅助AI。


<details>
  <summary>Details</summary>
Motivation: 使研究人员能够利用机器学习强化学习（RL）环境进行在线人类主体实验，解决AI算法与人类表现对比、认知科学家测试ML算法作为人类认知理论以及多智能体研究人员开发人机协作算法的需求。

Method: 开发了NiceWebRL，一个Python库，可以将任何基于Jax的环境转换为在线接口，支持单智能体和多智能体环境。

Result: 通过3个案例研究展示了NiceWebRL的潜力：在网格世界和Craftax中开发并测试了新颖的类人AI认知RL模型；在Overcooked领域开发了可泛化到人类伙伴的新型多智能体RL算法；以及在XLand-Minigrid中研究了LLM如何协助人类完成复杂任务。

Conclusion: NiceWebRL作为一个研究工具，能够通过在线人类主体实验，促进类人AI、人机兼容AI和人机辅助AI的开发。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [156] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 该论文测量了AI服务在生产环境（谷歌的Gemini）中的环境影响（能源、碳、水）。研究发现Gemini文本提示的影响很小，并通过效率提升显著降低，强调了全面测量对未来改进的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI的变革力量不可否认，但随着用户采纳的加速，理解和减轻AI服务的环境影响的需求也日益增长。目前还没有研究在生产环境中测量AI服务的环境指标。

Method: 本文提出并执行了一套全面的方法，用于测量大规模AI生产环境中AI推理工作负载的能源使用、碳排放和水消耗。该方法考虑了AI服务基础设施的整个堆栈，包括活跃AI加速器功率、主机系统能源、闲置机器容量和数据中心能源开销。通过对谷歌服务Gemini AI助手的AI基础设施进行详细的仪器测量。

Result: 研究发现，Gemini Apps的文本提示中位数消耗0.24 Wh的能量，远低于许多公开估计。谷歌的软件效率努力和清洁能源采购使Gemini Apps文本提示中位数的能源消耗在一年内减少了33倍，碳足迹减少了44倍。中位数Gemini Apps文本提示的能耗低于观看九秒电视（0.24 Wh），用水量相当于五滴水（0.26 mL）。

Conclusion: 尽管这些影响与其他日常活动相比很低，但减少AI服务的环境影响仍需持续关注。为了实现这一目标，全面测量AI服务的环境指标对于准确比较模型以及正确激励整个AI服务堆栈的效率提升至关重要。

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [157] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 该研究提出了一个基于大型语言模型的实时响应评估框架，用于识别与AI代理的对话中的准社会关系线索，并在一项小型合成数据集上初步验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 与AI代理建立准社会关系对人类福祉有严重影响，但预防此类动态具有挑战性，因为准社会线索通常在私人对话中逐渐出现，且并非所有情感投入都有害。

Method: 通过改造一个最先进的语言模型，创建了一个简单的响应评估框架，实时评估对话中的准社会线索。构建了一个包含30个对话（准社会、奉承和中立）的小型合成数据集，并使用五阶段迭代评估进行测试。

Result: 在容错一致性规则下，成功识别了所有准社会对话，同时避免了假阳性，且通常在最初几次交流中就能检测到。

Conclusion: 初步证据表明，评估代理可以为预防准社会关系提供一个可行的解决方案。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [158] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: LGT利用多智能体大型语言模型和自然语言推理，通过文本梯度优化机器学习配置，优于传统方法并提高了可解释性。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的配置优化是一个关键瓶颈，传统方法缺乏可解释性和适应性，而现有自动化方法难以动态适应和进行语义推理。

Method: 本文引入了语言引导调优（Language-Guided Tuning, LGT），一个新颖的框架，该框架利用多智能体大型语言模型通过自然语言推理智能地优化配置。LGT采用文本梯度（一种定性反馈信号）来补充数值优化，并通过协调顾问、评估器和优化器三个专门代理，形成一个自我改进的反馈循环。

Result: 通过在六个不同数据集上的全面评估，LGT比传统优化方法取得了显著改进，在保持高可解释性的同时实现了性能提升。

Conclusion: LGT提供了一个有效且可解释的框架，通过使用语言引导的多智能体大型语言模型和文本梯度来优化机器学习配置。

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>
